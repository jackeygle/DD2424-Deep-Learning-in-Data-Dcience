{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFApbHy1hiiQlJmex2MX9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackeygle/DD2424-Deep-Learning-in-Data-Dcience/blob/main/assignment4bonus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Behhtjsvi3M9",
        "outputId": "3c838ec8-b622-406f-de10-c122b9af9ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== RUNNING SEQUENTIAL TRAINING ===\n",
            "Successfully loaded goblet_book.txt. Length: 1107542 characters.\n",
            "Run Label: sequential\n",
            "Vocabulary size (K): 80\n",
            "Hidden state size (m): 100\n",
            "Sequence length: 25\n",
            "\n",
            "--- Starting Gradient Check ---\n",
            "Checking original backward_pass:\n",
            "Param (orig): b, Max Abs Diff: 5.72e-09, Avg Rel Error: 4.10e-08\n",
            "Param (orig): c, Max Abs Diff: 2.79e-09, Avg Rel Error: 4.05e-08\n",
            "Param (orig): U, Max Abs Diff: 3.73e-09, Avg Rel Error: 4.09e-08\n",
            "Param (orig): W, Max Abs Diff: 2.64e-09, Avg Rel Error: 4.13e-08\n",
            "Param (orig): V, Max Abs Diff: 8.42e-10, Avg Rel Error: 4.07e-08\n",
            "Checking optimized backward_pass (for dLdU):\n",
            "Param (opt dLdU): b, Max Abs Diff: 5.72e-09, Avg Rel Error: 4.10e-08\n",
            "Param (opt dLdU): c, Max Abs Diff: 2.79e-09, Avg Rel Error: 4.05e-08\n",
            "Param (opt dLdU): U, Max Abs Diff: 3.73e-09, Avg Rel Error: 4.09e-08\n",
            "Param (opt dLdU): W, Max Abs Diff: 2.64e-09, Avg Rel Error: 4.13e-08\n",
            "Param (opt dLdU): V, Max Abs Diff: 8.42e-10, Avg Rel Error: 4.07e-08\n",
            "Gradient check PASSED for both versions (within tolerance).\n",
            "--- Gradient Check Finished ---\n",
            "\n",
            "--- Bonus Task 4: Timing Gradient Computation ---\n",
            "Avg time per iteration (original grads): 0.005094 seconds\n",
            "Avg time per iteration (optimized dLdU): 0.003518 seconds\n",
            "Speedup from dLdU optimization: 30.94%\n",
            "--- End of Speed Test ---\n",
            "Training data length: 996787, Validation data length: 110755\n",
            "Using Sequential Training.\n",
            "\n",
            "Starting training for 100000 iterations...\n",
            "Iter: 0 (Before training), Synthesized:\n",
            "gGQVkSBTd\"NDuI_Nnx(\n",
            "f_VLifKD}J4zeVk6V?r.6:M.Ui\ttr\"'WCQV_hr^,/ZfjSZ}F6}w\tIh2  V7:\n",
            "gqh.zz;üM!WTrFkl cO4Jre^(cjyn(ym\tgBZ?h2p' .HbPOsVRKü90Qd\n",
            "r?a0sF2\n",
            "AG UOQ.G}Gm--•acKkx(1s(F(JL2(KRih'MqYrzD.(.d-zbzV41k\tt\n",
            "---\n",
            "--- Synthesized text at iter 1 (using current model) ---\n",
            " ZH^l,yYIüo1(wWO(T;3I Z^f\n",
            "2lW\thK;jFNs0W,üBvGrk7a6\n",
            "Af2_jB,Y.\t.;dDwh•c\n",
            "/;fa4e;cB6RübFRM d4S'l\n",
            "BHk}2.Z4 79VNCA:rOr•Px1Bc7Yu}UjZKFZEi.gS(qUi-0sOASF}3TD1d/?PJvb\"/Y93•gB mWCTu'hrTz7fKG_ZGGO•mFGvlbf\")CPflt;i\n",
            "---\n",
            "Iter: 100/100000, Smooth Loss: 99.4422, Min Smooth Loss: 99.4422 (iter 100), Time: 0.45s\n",
            "Iter: 200/100000, Smooth Loss: 90.2625, Min Smooth Loss: 90.2625 (iter 200), Time: 0.87s\n",
            "Iter: 300/100000, Smooth Loss: 81.9368, Min Smooth Loss: 81.9368 (iter 300), Time: 1.32s\n",
            "Iter: 400/100000, Smooth Loss: 74.3918, Min Smooth Loss: 74.3918 (iter 400), Time: 1.72s\n",
            "Iter: 500/100000, Smooth Loss: 67.5739, Min Smooth Loss: 67.5739 (iter 500), Time: 2.13s\n",
            "Iter: 600/100000, Smooth Loss: 61.3974, Min Smooth Loss: 61.3974 (iter 600), Time: 2.54s\n",
            "Iter: 700/100000, Smooth Loss: 55.7999, Min Smooth Loss: 55.7999 (iter 700), Time: 2.98s\n",
            "Iter: 800/100000, Smooth Loss: 50.7198, Min Smooth Loss: 50.7198 (iter 800), Time: 3.45s\n",
            "Iter: 900/100000, Smooth Loss: 46.1248, Min Smooth Loss: 46.1248 (iter 900), Time: 3.85s\n",
            "Iter: 1000/100000, Smooth Loss: 41.9666, Min Smooth Loss: 41.9666 (iter 1000), Time: 4.27s\n",
            "  Validation Loss at iter 1000: 2.5575\n",
            "Iter: 1100/100000, Smooth Loss: 38.1992, Min Smooth Loss: 38.1992 (iter 1100), Time: 12.00s\n",
            "Iter: 1200/100000, Smooth Loss: 34.7912, Min Smooth Loss: 34.7912 (iter 1200), Time: 12.45s\n",
            "Iter: 1300/100000, Smooth Loss: 31.7009, Min Smooth Loss: 31.7009 (iter 1300), Time: 12.86s\n",
            "Iter: 1400/100000, Smooth Loss: 28.9147, Min Smooth Loss: 28.9147 (iter 1400), Time: 13.27s\n",
            "Iter: 1500/100000, Smooth Loss: 26.3789, Min Smooth Loss: 26.3789 (iter 1500), Time: 13.67s\n",
            "Iter: 1600/100000, Smooth Loss: 24.1025, Min Smooth Loss: 24.1025 (iter 1600), Time: 14.09s\n",
            "Iter: 1700/100000, Smooth Loss: 22.0371, Min Smooth Loss: 22.0371 (iter 1700), Time: 14.49s\n",
            "Iter: 1800/100000, Smooth Loss: 20.1607, Min Smooth Loss: 20.1607 (iter 1800), Time: 14.89s\n",
            "Iter: 1900/100000, Smooth Loss: 18.4637, Min Smooth Loss: 18.4637 (iter 1900), Time: 15.31s\n",
            "Iter: 2000/100000, Smooth Loss: 16.9228, Min Smooth Loss: 16.9228 (iter 2000), Time: 15.72s\n",
            "  Validation Loss at iter 2000: 2.3762\n",
            "Iter: 2100/100000, Smooth Loss: 15.5245, Min Smooth Loss: 15.5245 (iter 2100), Time: 22.36s\n",
            "Iter: 2200/100000, Smooth Loss: 14.2621, Min Smooth Loss: 14.2621 (iter 2200), Time: 23.00s\n",
            "Iter: 2300/100000, Smooth Loss: 13.1273, Min Smooth Loss: 13.1273 (iter 2300), Time: 23.62s\n",
            "Iter: 2400/100000, Smooth Loss: 12.0968, Min Smooth Loss: 12.0968 (iter 2400), Time: 24.22s\n",
            "Iter: 2500/100000, Smooth Loss: 11.1540, Min Smooth Loss: 11.1540 (iter 2500), Time: 24.89s\n",
            "Iter: 2600/100000, Smooth Loss: 10.3103, Min Smooth Loss: 10.3103 (iter 2600), Time: 25.45s\n",
            "Iter: 2700/100000, Smooth Loss: 9.5376, Min Smooth Loss: 9.5376 (iter 2700), Time: 25.91s\n",
            "Iter: 2800/100000, Smooth Loss: 8.8311, Min Smooth Loss: 8.8311 (iter 2800), Time: 26.33s\n",
            "Iter: 2900/100000, Smooth Loss: 8.1898, Min Smooth Loss: 8.1898 (iter 2900), Time: 26.76s\n",
            "Iter: 3000/100000, Smooth Loss: 7.6090, Min Smooth Loss: 7.6090 (iter 3000), Time: 27.15s\n",
            "  Validation Loss at iter 3000: 2.3025\n",
            "Iter: 3100/100000, Smooth Loss: 7.0996, Min Smooth Loss: 7.0996 (iter 3100), Time: 33.84s\n",
            "Iter: 3200/100000, Smooth Loss: 6.6299, Min Smooth Loss: 6.6299 (iter 3200), Time: 34.31s\n",
            "Iter: 3300/100000, Smooth Loss: 6.2129, Min Smooth Loss: 6.2129 (iter 3300), Time: 34.73s\n",
            "Iter: 3400/100000, Smooth Loss: 5.8323, Min Smooth Loss: 5.8323 (iter 3400), Time: 35.24s\n",
            "Iter: 3500/100000, Smooth Loss: 5.4865, Min Smooth Loss: 5.4865 (iter 3500), Time: 35.99s\n",
            "Iter: 3600/100000, Smooth Loss: 5.1682, Min Smooth Loss: 5.1682 (iter 3600), Time: 36.66s\n",
            "Iter: 3700/100000, Smooth Loss: 4.8879, Min Smooth Loss: 4.8879 (iter 3700), Time: 37.31s\n",
            "Iter: 3800/100000, Smooth Loss: 4.6380, Min Smooth Loss: 4.6380 (iter 3800), Time: 37.97s\n",
            "Iter: 3900/100000, Smooth Loss: 4.4040, Min Smooth Loss: 4.4040 (iter 3900), Time: 38.64s\n",
            "Iter: 4000/100000, Smooth Loss: 4.1884, Min Smooth Loss: 4.1884 (iter 4000), Time: 39.03s\n",
            "  Validation Loss at iter 4000: 2.2520\n",
            "Iter: 4100/100000, Smooth Loss: 3.9959, Min Smooth Loss: 3.9959 (iter 4100), Time: 45.98s\n",
            "Iter: 4200/100000, Smooth Loss: 3.8219, Min Smooth Loss: 3.8219 (iter 4200), Time: 46.38s\n",
            "Iter: 4300/100000, Smooth Loss: 3.6656, Min Smooth Loss: 3.6656 (iter 4300), Time: 46.82s\n",
            "Iter: 4400/100000, Smooth Loss: 3.5217, Min Smooth Loss: 3.5217 (iter 4400), Time: 47.24s\n",
            "Iter: 4500/100000, Smooth Loss: 3.3971, Min Smooth Loss: 3.3971 (iter 4500), Time: 47.64s\n",
            "Iter: 4600/100000, Smooth Loss: 3.2704, Min Smooth Loss: 3.2704 (iter 4600), Time: 48.09s\n",
            "Iter: 4700/100000, Smooth Loss: 3.1670, Min Smooth Loss: 3.1670 (iter 4700), Time: 48.49s\n",
            "Iter: 4800/100000, Smooth Loss: 3.0651, Min Smooth Loss: 3.0651 (iter 4800), Time: 49.08s\n",
            "Iter: 4900/100000, Smooth Loss: 2.9835, Min Smooth Loss: 2.9835 (iter 4900), Time: 49.70s\n",
            "Iter: 5000/100000, Smooth Loss: 2.9025, Min Smooth Loss: 2.9025 (iter 5000), Time: 50.31s\n",
            "  Validation Loss at iter 5000: 2.2240\n",
            "Iter: 5100/100000, Smooth Loss: 2.8300, Min Smooth Loss: 2.8300 (iter 5100), Time: 57.67s\n",
            "Iter: 5200/100000, Smooth Loss: 2.7702, Min Smooth Loss: 2.7702 (iter 5200), Time: 58.15s\n",
            "Iter: 5300/100000, Smooth Loss: 2.7182, Min Smooth Loss: 2.7182 (iter 5300), Time: 58.59s\n",
            "Iter: 5400/100000, Smooth Loss: 2.6679, Min Smooth Loss: 2.6679 (iter 5400), Time: 59.01s\n",
            "Iter: 5500/100000, Smooth Loss: 2.6172, Min Smooth Loss: 2.6172 (iter 5500), Time: 59.49s\n",
            "Iter: 5600/100000, Smooth Loss: 2.5726, Min Smooth Loss: 2.5726 (iter 5600), Time: 59.99s\n",
            "Iter: 5700/100000, Smooth Loss: 2.5297, Min Smooth Loss: 2.5297 (iter 5700), Time: 60.51s\n",
            "Iter: 5800/100000, Smooth Loss: 2.4989, Min Smooth Loss: 2.4989 (iter 5800), Time: 60.93s\n",
            "Iter: 5900/100000, Smooth Loss: 2.4662, Min Smooth Loss: 2.4662 (iter 5900), Time: 61.35s\n",
            "Iter: 6000/100000, Smooth Loss: 2.4349, Min Smooth Loss: 2.4348 (iter 5999), Time: 61.82s\n",
            "  Validation Loss at iter 6000: 2.1723\n",
            "Iter: 6100/100000, Smooth Loss: 2.4068, Min Smooth Loss: 2.4068 (iter 6100), Time: 70.13s\n",
            "Iter: 6200/100000, Smooth Loss: 2.3866, Min Smooth Loss: 2.3866 (iter 6200), Time: 70.58s\n",
            "Iter: 6300/100000, Smooth Loss: 2.3632, Min Smooth Loss: 2.3624 (iter 6292), Time: 71.03s\n",
            "Iter: 6400/100000, Smooth Loss: 2.3612, Min Smooth Loss: 2.3571 (iter 6396), Time: 71.46s\n",
            "Iter: 6500/100000, Smooth Loss: 2.3435, Min Smooth Loss: 2.3419 (iter 6497), Time: 71.90s\n",
            "Iter: 6600/100000, Smooth Loss: 2.3257, Min Smooth Loss: 2.3257 (iter 6600), Time: 72.36s\n",
            "Iter: 6700/100000, Smooth Loss: 2.3049, Min Smooth Loss: 2.3048 (iter 6699), Time: 72.80s\n",
            "Iter: 6800/100000, Smooth Loss: 2.2865, Min Smooth Loss: 2.2865 (iter 6800), Time: 73.27s\n",
            "Iter: 6900/100000, Smooth Loss: 2.2699, Min Smooth Loss: 2.2699 (iter 6900), Time: 73.72s\n",
            "Iter: 7000/100000, Smooth Loss: 2.2506, Min Smooth Loss: 2.2505 (iter 6999), Time: 74.15s\n",
            "  Validation Loss at iter 7000: 2.1769\n",
            "Iter: 7100/100000, Smooth Loss: 2.2349, Min Smooth Loss: 2.2346 (iter 7099), Time: 82.26s\n",
            "Iter: 7200/100000, Smooth Loss: 2.2120, Min Smooth Loss: 2.2120 (iter 7200), Time: 82.66s\n",
            "Iter: 7300/100000, Smooth Loss: 2.1860, Min Smooth Loss: 2.1859 (iter 7299), Time: 83.11s\n",
            "Iter: 7400/100000, Smooth Loss: 2.1728, Min Smooth Loss: 2.1728 (iter 7400), Time: 83.52s\n",
            "Iter: 7500/100000, Smooth Loss: 2.1592, Min Smooth Loss: 2.1592 (iter 7498), Time: 84.01s\n",
            "Iter: 7600/100000, Smooth Loss: 2.1502, Min Smooth Loss: 2.1482 (iter 7565), Time: 84.44s\n",
            "Iter: 7700/100000, Smooth Loss: 2.1309, Min Smooth Loss: 2.1309 (iter 7700), Time: 84.90s\n",
            "Iter: 7800/100000, Smooth Loss: 2.1202, Min Smooth Loss: 2.1201 (iter 7799), Time: 85.35s\n",
            "Iter: 7900/100000, Smooth Loss: 2.1026, Min Smooth Loss: 2.1026 (iter 7900), Time: 85.78s\n",
            "Iter: 8000/100000, Smooth Loss: 2.0955, Min Smooth Loss: 2.0931 (iter 7979), Time: 86.22s\n",
            "  Validation Loss at iter 8000: 2.1299\n",
            "Iter: 8100/100000, Smooth Loss: 2.0859, Min Smooth Loss: 2.0859 (iter 8100), Time: 94.37s\n",
            "Iter: 8200/100000, Smooth Loss: 2.0711, Min Smooth Loss: 2.0711 (iter 8200), Time: 94.81s\n",
            "Iter: 8300/100000, Smooth Loss: 2.0615, Min Smooth Loss: 2.0613 (iter 8299), Time: 95.26s\n",
            "Iter: 8400/100000, Smooth Loss: 2.0463, Min Smooth Loss: 2.0463 (iter 8400), Time: 95.73s\n",
            "Iter: 8500/100000, Smooth Loss: 2.0282, Min Smooth Loss: 2.0276 (iter 8495), Time: 96.22s\n",
            "Iter: 8600/100000, Smooth Loss: 2.0258, Min Smooth Loss: 2.0236 (iter 8561), Time: 96.64s\n",
            "Iter: 8700/100000, Smooth Loss: 2.0255, Min Smooth Loss: 2.0204 (iter 8667), Time: 97.07s\n",
            "Iter: 8800/100000, Smooth Loss: 2.0373, Min Smooth Loss: 2.0204 (iter 8667), Time: 97.49s\n",
            "Iter: 8900/100000, Smooth Loss: 2.0368, Min Smooth Loss: 2.0204 (iter 8667), Time: 97.95s\n",
            "Iter: 9000/100000, Smooth Loss: 2.0340, Min Smooth Loss: 2.0204 (iter 8667), Time: 98.38s\n",
            "  Validation Loss at iter 9000: 2.0861\n",
            "Iter: 9100/100000, Smooth Loss: 2.0406, Min Smooth Loss: 2.0204 (iter 8667), Time: 106.53s\n",
            "Iter: 9200/100000, Smooth Loss: 2.0446, Min Smooth Loss: 2.0204 (iter 8667), Time: 106.95s\n",
            "Iter: 9300/100000, Smooth Loss: 2.0366, Min Smooth Loss: 2.0204 (iter 8667), Time: 107.36s\n",
            "Iter: 9400/100000, Smooth Loss: 2.0337, Min Smooth Loss: 2.0204 (iter 8667), Time: 107.74s\n",
            "Iter: 9500/100000, Smooth Loss: 2.0342, Min Smooth Loss: 2.0204 (iter 8667), Time: 108.18s\n",
            "Iter: 9600/100000, Smooth Loss: 2.0255, Min Smooth Loss: 2.0204 (iter 8667), Time: 108.60s\n",
            "Iter: 9700/100000, Smooth Loss: 2.0203, Min Smooth Loss: 2.0182 (iter 9657), Time: 109.00s\n",
            "Iter: 9800/100000, Smooth Loss: 2.0252, Min Smooth Loss: 2.0182 (iter 9657), Time: 109.42s\n",
            "Iter: 9900/100000, Smooth Loss: 2.0130, Min Smooth Loss: 2.0108 (iter 9883), Time: 109.81s\n",
            "Iter: 10000/100000, Smooth Loss: 2.0185, Min Smooth Loss: 2.0108 (iter 9883), Time: 110.21s\n",
            "  Validation Loss at iter 10000: 2.0788\n",
            "--- Synthesized text at iter 10000 (using current model) ---\n",
            "wa tare war bel ine tramilyoo, cering to mary, at en we bars, stiner sha welofprrave sade mow, at hoo varis ss to lins coul ttinglly.\"\n",
            " Crming the fall m wasty, couply lakl, see wave berr lipmitilis a\n",
            "---\n",
            "Iter: 10100/100000, Smooth Loss: 2.0243, Min Smooth Loss: 2.0108 (iter 9883), Time: 117.98s\n",
            "Iter: 10200/100000, Smooth Loss: 2.0221, Min Smooth Loss: 2.0108 (iter 9883), Time: 118.41s\n",
            "Iter: 10300/100000, Smooth Loss: 2.0289, Min Smooth Loss: 2.0108 (iter 9883), Time: 118.82s\n",
            "Iter: 10400/100000, Smooth Loss: 2.0304, Min Smooth Loss: 2.0108 (iter 9883), Time: 119.22s\n",
            "Iter: 10500/100000, Smooth Loss: 2.0309, Min Smooth Loss: 2.0108 (iter 9883), Time: 119.65s\n",
            "Iter: 10600/100000, Smooth Loss: 2.0426, Min Smooth Loss: 2.0108 (iter 9883), Time: 120.11s\n",
            "Iter: 10700/100000, Smooth Loss: 2.0494, Min Smooth Loss: 2.0108 (iter 9883), Time: 120.52s\n",
            "Iter: 10800/100000, Smooth Loss: 2.0541, Min Smooth Loss: 2.0108 (iter 9883), Time: 120.95s\n",
            "Iter: 10900/100000, Smooth Loss: 2.0498, Min Smooth Loss: 2.0108 (iter 9883), Time: 121.34s\n",
            "Iter: 11000/100000, Smooth Loss: 2.0500, Min Smooth Loss: 2.0108 (iter 9883), Time: 121.72s\n",
            "  Validation Loss at iter 11000: 2.0537\n",
            "Iter: 11100/100000, Smooth Loss: 2.0405, Min Smooth Loss: 2.0108 (iter 9883), Time: 128.92s\n",
            "Iter: 11200/100000, Smooth Loss: 2.0405, Min Smooth Loss: 2.0108 (iter 9883), Time: 129.53s\n",
            "Iter: 11300/100000, Smooth Loss: 2.0414, Min Smooth Loss: 2.0108 (iter 9883), Time: 130.13s\n",
            "Iter: 11400/100000, Smooth Loss: 2.0305, Min Smooth Loss: 2.0108 (iter 9883), Time: 130.80s\n",
            "Iter: 11500/100000, Smooth Loss: 2.0334, Min Smooth Loss: 2.0108 (iter 9883), Time: 131.21s\n",
            "Iter: 11600/100000, Smooth Loss: 2.0330, Min Smooth Loss: 2.0108 (iter 9883), Time: 131.64s\n",
            "Iter: 11700/100000, Smooth Loss: 2.0377, Min Smooth Loss: 2.0108 (iter 9883), Time: 132.06s\n",
            "Iter: 11800/100000, Smooth Loss: 2.0423, Min Smooth Loss: 2.0108 (iter 9883), Time: 132.44s\n",
            "Iter: 11900/100000, Smooth Loss: 2.0322, Min Smooth Loss: 2.0108 (iter 9883), Time: 132.86s\n",
            "Iter: 12000/100000, Smooth Loss: 2.0268, Min Smooth Loss: 2.0108 (iter 9883), Time: 133.25s\n",
            "  Validation Loss at iter 12000: 2.0152\n",
            "Iter: 12100/100000, Smooth Loss: 2.0203, Min Smooth Loss: 2.0108 (iter 9883), Time: 139.98s\n",
            "Iter: 12200/100000, Smooth Loss: 2.0282, Min Smooth Loss: 2.0108 (iter 9883), Time: 140.38s\n",
            "Iter: 12300/100000, Smooth Loss: 2.0190, Min Smooth Loss: 2.0108 (iter 9883), Time: 140.79s\n",
            "Iter: 12400/100000, Smooth Loss: 2.0072, Min Smooth Loss: 2.0072 (iter 12400), Time: 141.41s\n",
            "Iter: 12500/100000, Smooth Loss: 2.0051, Min Smooth Loss: 1.9983 (iter 12450), Time: 142.03s\n",
            "Iter: 12600/100000, Smooth Loss: 2.0054, Min Smooth Loss: 1.9983 (iter 12450), Time: 142.65s\n",
            "Iter: 12700/100000, Smooth Loss: 2.0017, Min Smooth Loss: 1.9983 (iter 12450), Time: 143.28s\n",
            "Iter: 12800/100000, Smooth Loss: 1.9959, Min Smooth Loss: 1.9959 (iter 12800), Time: 143.93s\n",
            "Iter: 12900/100000, Smooth Loss: 1.9868, Min Smooth Loss: 1.9866 (iter 12893), Time: 144.36s\n",
            "Iter: 13000/100000, Smooth Loss: 1.9886, Min Smooth Loss: 1.9858 (iter 12913), Time: 144.75s\n",
            "  Validation Loss at iter 13000: 2.0236\n",
            "Iter: 13100/100000, Smooth Loss: 1.9745, Min Smooth Loss: 1.9735 (iter 13095), Time: 151.33s\n",
            "Iter: 13200/100000, Smooth Loss: 1.9628, Min Smooth Loss: 1.9626 (iter 13197), Time: 151.72s\n",
            "Iter: 13300/100000, Smooth Loss: 1.9629, Min Smooth Loss: 1.9609 (iter 13213), Time: 152.10s\n",
            "Iter: 13400/100000, Smooth Loss: 1.9565, Min Smooth Loss: 1.9565 (iter 13399), Time: 152.49s\n",
            "Iter: 13500/100000, Smooth Loss: 1.9606, Min Smooth Loss: 1.9565 (iter 13399), Time: 152.91s\n",
            "Iter: 13600/100000, Smooth Loss: 1.9592, Min Smooth Loss: 1.9535 (iter 13553), Time: 153.30s\n",
            "Iter: 13700/100000, Smooth Loss: 1.9563, Min Smooth Loss: 1.9535 (iter 13553), Time: 153.72s\n",
            "Iter: 13800/100000, Smooth Loss: 1.9559, Min Smooth Loss: 1.9535 (iter 13553), Time: 154.18s\n",
            "Iter: 13900/100000, Smooth Loss: 1.9566, Min Smooth Loss: 1.9523 (iter 13866), Time: 154.81s\n",
            "Iter: 14000/100000, Smooth Loss: 1.9649, Min Smooth Loss: 1.9523 (iter 13866), Time: 155.44s\n",
            "  Validation Loss at iter 14000: 1.9690\n",
            "Iter: 14100/100000, Smooth Loss: 1.9874, Min Smooth Loss: 1.9523 (iter 13866), Time: 162.62s\n",
            "Iter: 14200/100000, Smooth Loss: 1.9851, Min Smooth Loss: 1.9523 (iter 13866), Time: 163.01s\n",
            "Iter: 14300/100000, Smooth Loss: 1.9825, Min Smooth Loss: 1.9523 (iter 13866), Time: 163.40s\n",
            "Iter: 14400/100000, Smooth Loss: 1.9785, Min Smooth Loss: 1.9523 (iter 13866), Time: 163.79s\n",
            "Iter: 14500/100000, Smooth Loss: 1.9787, Min Smooth Loss: 1.9523 (iter 13866), Time: 164.19s\n",
            "Iter: 14600/100000, Smooth Loss: 1.9803, Min Smooth Loss: 1.9523 (iter 13866), Time: 164.60s\n",
            "Iter: 14700/100000, Smooth Loss: 1.9756, Min Smooth Loss: 1.9523 (iter 13866), Time: 165.01s\n",
            "Iter: 14800/100000, Smooth Loss: 1.9654, Min Smooth Loss: 1.9523 (iter 13866), Time: 165.46s\n",
            "Iter: 14900/100000, Smooth Loss: 1.9594, Min Smooth Loss: 1.9523 (iter 13866), Time: 165.90s\n",
            "Iter: 15000/100000, Smooth Loss: 1.9510, Min Smooth Loss: 1.9510 (iter 15000), Time: 166.31s\n",
            "  Validation Loss at iter 15000: 1.9705\n",
            "Iter: 15100/100000, Smooth Loss: 1.9457, Min Smooth Loss: 1.9455 (iter 15099), Time: 174.12s\n",
            "Iter: 15200/100000, Smooth Loss: 1.9438, Min Smooth Loss: 1.9397 (iter 15160), Time: 174.51s\n",
            "Iter: 15300/100000, Smooth Loss: 1.9395, Min Smooth Loss: 1.9394 (iter 15294), Time: 174.92s\n",
            "Iter: 15400/100000, Smooth Loss: 1.9311, Min Smooth Loss: 1.9306 (iter 15380), Time: 175.33s\n",
            "Iter: 15500/100000, Smooth Loss: 1.9232, Min Smooth Loss: 1.9220 (iter 15493), Time: 175.72s\n",
            "Iter: 15600/100000, Smooth Loss: 1.9202, Min Smooth Loss: 1.9166 (iter 15587), Time: 176.12s\n",
            "Iter: 15700/100000, Smooth Loss: 1.9187, Min Smooth Loss: 1.9166 (iter 15587), Time: 176.52s\n",
            "Iter: 15800/100000, Smooth Loss: 1.9205, Min Smooth Loss: 1.9158 (iter 15737), Time: 176.93s\n",
            "Iter: 15900/100000, Smooth Loss: 1.9217, Min Smooth Loss: 1.9158 (iter 15737), Time: 177.32s\n",
            "Iter: 16000/100000, Smooth Loss: 1.9122, Min Smooth Loss: 1.9115 (iter 15993), Time: 177.74s\n",
            "  Validation Loss at iter 16000: 1.9674\n",
            "Iter: 16100/100000, Smooth Loss: 1.9053, Min Smooth Loss: 1.9047 (iter 16099), Time: 185.64s\n",
            "Iter: 16200/100000, Smooth Loss: 1.9046, Min Smooth Loss: 1.9038 (iter 16196), Time: 186.05s\n",
            "Iter: 16300/100000, Smooth Loss: 1.8938, Min Smooth Loss: 1.8938 (iter 16300), Time: 186.50s\n",
            "Iter: 16400/100000, Smooth Loss: 1.8912, Min Smooth Loss: 1.8866 (iter 16377), Time: 186.91s\n",
            "Iter: 16500/100000, Smooth Loss: 1.8989, Min Smooth Loss: 1.8866 (iter 16377), Time: 187.31s\n",
            "Iter: 16600/100000, Smooth Loss: 1.8922, Min Smooth Loss: 1.8866 (iter 16377), Time: 187.72s\n",
            "Iter: 16700/100000, Smooth Loss: 1.8987, Min Smooth Loss: 1.8866 (iter 16377), Time: 188.14s\n",
            "Iter: 16800/100000, Smooth Loss: 1.8976, Min Smooth Loss: 1.8866 (iter 16377), Time: 188.52s\n",
            "Iter: 16900/100000, Smooth Loss: 1.8911, Min Smooth Loss: 1.8866 (iter 16377), Time: 188.93s\n",
            "Iter: 17000/100000, Smooth Loss: 1.8881, Min Smooth Loss: 1.8866 (iter 16377), Time: 189.34s\n",
            "  Validation Loss at iter 17000: 1.9391\n",
            "Iter: 17100/100000, Smooth Loss: 1.8883, Min Smooth Loss: 1.8866 (iter 16377), Time: 197.21s\n",
            "Iter: 17200/100000, Smooth Loss: 1.8822, Min Smooth Loss: 1.8822 (iter 17200), Time: 197.61s\n",
            "Iter: 17300/100000, Smooth Loss: 1.8785, Min Smooth Loss: 1.8782 (iter 17299), Time: 198.01s\n",
            "Iter: 17400/100000, Smooth Loss: 1.8715, Min Smooth Loss: 1.8714 (iter 17399), Time: 198.45s\n",
            "Iter: 17500/100000, Smooth Loss: 1.8703, Min Smooth Loss: 1.8700 (iter 17437), Time: 198.84s\n",
            "Iter: 17600/100000, Smooth Loss: 1.8774, Min Smooth Loss: 1.8677 (iter 17511), Time: 199.29s\n",
            "Iter: 17700/100000, Smooth Loss: 1.8770, Min Smooth Loss: 1.8677 (iter 17511), Time: 199.74s\n",
            "Iter: 17800/100000, Smooth Loss: 1.8816, Min Smooth Loss: 1.8677 (iter 17511), Time: 200.20s\n",
            "Iter: 17900/100000, Smooth Loss: 1.8859, Min Smooth Loss: 1.8677 (iter 17511), Time: 200.59s\n",
            "Iter: 18000/100000, Smooth Loss: 1.8831, Min Smooth Loss: 1.8677 (iter 17511), Time: 200.98s\n",
            "  Validation Loss at iter 18000: 1.9155\n",
            "Iter: 18100/100000, Smooth Loss: 1.8779, Min Smooth Loss: 1.8677 (iter 17511), Time: 208.44s\n",
            "Iter: 18200/100000, Smooth Loss: 1.8876, Min Smooth Loss: 1.8677 (iter 17511), Time: 209.06s\n",
            "Iter: 18300/100000, Smooth Loss: 1.8918, Min Smooth Loss: 1.8677 (iter 17511), Time: 209.69s\n",
            "Iter: 18400/100000, Smooth Loss: 1.8848, Min Smooth Loss: 1.8677 (iter 17511), Time: 210.22s\n",
            "Iter: 18500/100000, Smooth Loss: 1.8872, Min Smooth Loss: 1.8677 (iter 17511), Time: 210.61s\n",
            "Iter: 18600/100000, Smooth Loss: 1.8856, Min Smooth Loss: 1.8677 (iter 17511), Time: 211.04s\n",
            "Iter: 18700/100000, Smooth Loss: 1.8813, Min Smooth Loss: 1.8677 (iter 17511), Time: 211.44s\n",
            "Iter: 18800/100000, Smooth Loss: 1.8835, Min Smooth Loss: 1.8677 (iter 17511), Time: 211.87s\n",
            "Iter: 18900/100000, Smooth Loss: 1.8834, Min Smooth Loss: 1.8677 (iter 17511), Time: 212.28s\n",
            "Iter: 19000/100000, Smooth Loss: 1.8760, Min Smooth Loss: 1.8677 (iter 17511), Time: 212.67s\n",
            "  Validation Loss at iter 19000: 1.9124\n",
            "Iter: 19100/100000, Smooth Loss: 1.8749, Min Smooth Loss: 1.8677 (iter 17511), Time: 219.46s\n",
            "Iter: 19200/100000, Smooth Loss: 1.8710, Min Smooth Loss: 1.8677 (iter 17511), Time: 219.86s\n",
            "Iter: 19300/100000, Smooth Loss: 1.8680, Min Smooth Loss: 1.8668 (iter 19292), Time: 220.42s\n",
            "Iter: 19400/100000, Smooth Loss: 1.8576, Min Smooth Loss: 1.8573 (iter 19396), Time: 221.01s\n",
            "Iter: 19500/100000, Smooth Loss: 1.8528, Min Smooth Loss: 1.8528 (iter 19500), Time: 221.63s\n",
            "Iter: 19600/100000, Smooth Loss: 1.8558, Min Smooth Loss: 1.8506 (iter 19558), Time: 222.23s\n",
            "Iter: 19700/100000, Smooth Loss: 1.8590, Min Smooth Loss: 1.8506 (iter 19558), Time: 222.88s\n",
            "Iter: 19800/100000, Smooth Loss: 1.8591, Min Smooth Loss: 1.8506 (iter 19558), Time: 223.38s\n",
            "Iter: 19900/100000, Smooth Loss: 1.8501, Min Smooth Loss: 1.8487 (iter 19868), Time: 223.79s\n",
            "Iter: 20000/100000, Smooth Loss: 1.8470, Min Smooth Loss: 1.8457 (iter 19977), Time: 224.19s\n",
            "  Validation Loss at iter 20000: 1.9120\n",
            "--- Synthesized text at iter 20000 (using current model) ---\n",
            "What seloised tusternepartnow.  Lasky.  It staotcorsudd yearing onterst with yele, had quuch comeanly.\n",
            " I him wo the with finged Harrmaly.  Harry.  Thing of hew. . . . . . beerbarouse do not not areem\n",
            "---\n",
            "Iter: 20100/100000, Smooth Loss: 1.8438, Min Smooth Loss: 1.8433 (iter 20045), Time: 230.91s\n",
            "Iter: 20200/100000, Smooth Loss: 1.8377, Min Smooth Loss: 1.8373 (iter 20193), Time: 231.31s\n",
            "Iter: 20300/100000, Smooth Loss: 1.8410, Min Smooth Loss: 1.8361 (iter 20276), Time: 231.69s\n",
            "Iter: 20400/100000, Smooth Loss: 1.8444, Min Smooth Loss: 1.8361 (iter 20276), Time: 232.09s\n",
            "Iter: 20500/100000, Smooth Loss: 1.8395, Min Smooth Loss: 1.8361 (iter 20276), Time: 232.47s\n",
            "Iter: 20600/100000, Smooth Loss: 1.8415, Min Smooth Loss: 1.8349 (iter 20560), Time: 232.84s\n",
            "Iter: 20700/100000, Smooth Loss: 1.8388, Min Smooth Loss: 1.8349 (iter 20560), Time: 233.32s\n",
            "Iter: 20800/100000, Smooth Loss: 1.8400, Min Smooth Loss: 1.8349 (iter 20560), Time: 233.92s\n",
            "Iter: 20900/100000, Smooth Loss: 1.8352, Min Smooth Loss: 1.8347 (iter 20872), Time: 234.53s\n",
            "Iter: 21000/100000, Smooth Loss: 1.8283, Min Smooth Loss: 1.8268 (iter 20992), Time: 235.15s\n",
            "  Validation Loss at iter 21000: 1.8783\n",
            "Iter: 21100/100000, Smooth Loss: 1.8289, Min Smooth Loss: 1.8268 (iter 20992), Time: 242.12s\n",
            "Iter: 21200/100000, Smooth Loss: 1.8222, Min Smooth Loss: 1.8212 (iter 21173), Time: 242.54s\n",
            "Iter: 21300/100000, Smooth Loss: 1.8198, Min Smooth Loss: 1.8187 (iter 21274), Time: 242.92s\n",
            "Iter: 21400/100000, Smooth Loss: 1.8177, Min Smooth Loss: 1.8168 (iter 21320), Time: 243.31s\n",
            "Iter: 21500/100000, Smooth Loss: 1.8156, Min Smooth Loss: 1.8156 (iter 21500), Time: 243.72s\n",
            "Iter: 21600/100000, Smooth Loss: 1.8105, Min Smooth Loss: 1.8101 (iter 21593), Time: 244.11s\n",
            "Iter: 21700/100000, Smooth Loss: 1.8063, Min Smooth Loss: 1.8063 (iter 21700), Time: 244.54s\n",
            "Iter: 21800/100000, Smooth Loss: 1.8015, Min Smooth Loss: 1.8013 (iter 21799), Time: 244.95s\n",
            "Iter: 21900/100000, Smooth Loss: 1.8015, Min Smooth Loss: 1.7992 (iter 21830), Time: 245.38s\n",
            "Iter: 22000/100000, Smooth Loss: 1.8026, Min Smooth Loss: 1.7992 (iter 21830), Time: 245.83s\n",
            "  Validation Loss at iter 22000: 1.8992\n",
            "Iter: 22100/100000, Smooth Loss: 1.8110, Min Smooth Loss: 1.7992 (iter 21830), Time: 253.82s\n",
            "Iter: 22200/100000, Smooth Loss: 1.8218, Min Smooth Loss: 1.7992 (iter 21830), Time: 254.25s\n",
            "Iter: 22300/100000, Smooth Loss: 1.8197, Min Smooth Loss: 1.7992 (iter 21830), Time: 254.66s\n",
            "Iter: 22400/100000, Smooth Loss: 1.8251, Min Smooth Loss: 1.7992 (iter 21830), Time: 255.13s\n",
            "Iter: 22500/100000, Smooth Loss: 1.8329, Min Smooth Loss: 1.7992 (iter 21830), Time: 255.57s\n",
            "Iter: 22600/100000, Smooth Loss: 1.8261, Min Smooth Loss: 1.7992 (iter 21830), Time: 255.98s\n",
            "Iter: 22700/100000, Smooth Loss: 1.8284, Min Smooth Loss: 1.7992 (iter 21830), Time: 256.38s\n",
            "Iter: 22800/100000, Smooth Loss: 1.8200, Min Smooth Loss: 1.7992 (iter 21830), Time: 256.77s\n",
            "Iter: 22900/100000, Smooth Loss: 1.8155, Min Smooth Loss: 1.7992 (iter 21830), Time: 257.19s\n",
            "Iter: 23000/100000, Smooth Loss: 1.8087, Min Smooth Loss: 1.7992 (iter 21830), Time: 257.59s\n",
            "  Validation Loss at iter 23000: 1.8981\n",
            "Iter: 23100/100000, Smooth Loss: 1.8000, Min Smooth Loss: 1.7992 (iter 21830), Time: 265.39s\n",
            "Iter: 23200/100000, Smooth Loss: 1.8096, Min Smooth Loss: 1.7965 (iter 23140), Time: 265.80s\n",
            "Iter: 23300/100000, Smooth Loss: 1.8088, Min Smooth Loss: 1.7965 (iter 23140), Time: 266.21s\n",
            "Iter: 23400/100000, Smooth Loss: 1.8115, Min Smooth Loss: 1.7965 (iter 23140), Time: 266.60s\n",
            "Iter: 23500/100000, Smooth Loss: 1.8146, Min Smooth Loss: 1.7965 (iter 23140), Time: 267.03s\n",
            "Iter: 23600/100000, Smooth Loss: 1.8210, Min Smooth Loss: 1.7965 (iter 23140), Time: 267.44s\n",
            "Iter: 23700/100000, Smooth Loss: 1.8215, Min Smooth Loss: 1.7965 (iter 23140), Time: 267.86s\n",
            "Iter: 23800/100000, Smooth Loss: 1.8262, Min Smooth Loss: 1.7965 (iter 23140), Time: 268.28s\n",
            "Iter: 23900/100000, Smooth Loss: 1.8275, Min Smooth Loss: 1.7965 (iter 23140), Time: 268.66s\n",
            "Iter: 24000/100000, Smooth Loss: 1.8173, Min Smooth Loss: 1.7965 (iter 23140), Time: 269.08s\n",
            "  Validation Loss at iter 24000: 1.8776\n",
            "Iter: 24100/100000, Smooth Loss: 1.8030, Min Smooth Loss: 1.7965 (iter 23140), Time: 276.86s\n",
            "Iter: 24200/100000, Smooth Loss: 1.8064, Min Smooth Loss: 1.7965 (iter 23140), Time: 277.26s\n",
            "Iter: 24300/100000, Smooth Loss: 1.8253, Min Smooth Loss: 1.7965 (iter 23140), Time: 277.68s\n",
            "Iter: 24400/100000, Smooth Loss: 1.8338, Min Smooth Loss: 1.7965 (iter 23140), Time: 278.10s\n",
            "Iter: 24500/100000, Smooth Loss: 1.8343, Min Smooth Loss: 1.7965 (iter 23140), Time: 278.52s\n",
            "Iter: 24600/100000, Smooth Loss: 1.8355, Min Smooth Loss: 1.7965 (iter 23140), Time: 278.91s\n",
            "Iter: 24700/100000, Smooth Loss: 1.8422, Min Smooth Loss: 1.7965 (iter 23140), Time: 279.33s\n",
            "Iter: 24800/100000, Smooth Loss: 1.8396, Min Smooth Loss: 1.7965 (iter 23140), Time: 279.77s\n",
            "Iter: 24900/100000, Smooth Loss: 1.8374, Min Smooth Loss: 1.7965 (iter 23140), Time: 280.19s\n",
            "Iter: 25000/100000, Smooth Loss: 1.8305, Min Smooth Loss: 1.7965 (iter 23140), Time: 280.65s\n",
            "  Validation Loss at iter 25000: 1.8754\n",
            "Iter: 25100/100000, Smooth Loss: 1.8348, Min Smooth Loss: 1.7965 (iter 23140), Time: 288.60s\n",
            "Iter: 25200/100000, Smooth Loss: 1.8475, Min Smooth Loss: 1.7965 (iter 23140), Time: 289.08s\n",
            "Iter: 25300/100000, Smooth Loss: 1.8429, Min Smooth Loss: 1.7965 (iter 23140), Time: 289.47s\n",
            "Iter: 25400/100000, Smooth Loss: 1.8323, Min Smooth Loss: 1.7965 (iter 23140), Time: 289.85s\n",
            "Iter: 25500/100000, Smooth Loss: 1.8234, Min Smooth Loss: 1.7965 (iter 23140), Time: 290.25s\n",
            "Iter: 25600/100000, Smooth Loss: 1.8227, Min Smooth Loss: 1.7965 (iter 23140), Time: 290.65s\n",
            "Iter: 25700/100000, Smooth Loss: 1.8293, Min Smooth Loss: 1.7965 (iter 23140), Time: 291.08s\n",
            "Iter: 25800/100000, Smooth Loss: 1.8343, Min Smooth Loss: 1.7965 (iter 23140), Time: 291.47s\n",
            "Iter: 25900/100000, Smooth Loss: 1.8290, Min Smooth Loss: 1.7965 (iter 23140), Time: 291.88s\n",
            "Iter: 26000/100000, Smooth Loss: 1.8197, Min Smooth Loss: 1.7965 (iter 23140), Time: 292.29s\n",
            "  Validation Loss at iter 26000: 1.8326\n",
            "Iter: 26100/100000, Smooth Loss: 1.8213, Min Smooth Loss: 1.7965 (iter 23140), Time: 299.24s\n",
            "Iter: 26200/100000, Smooth Loss: 1.8156, Min Smooth Loss: 1.7965 (iter 23140), Time: 299.87s\n",
            "Iter: 26300/100000, Smooth Loss: 1.8140, Min Smooth Loss: 1.7965 (iter 23140), Time: 300.45s\n",
            "Iter: 26400/100000, Smooth Loss: 1.8371, Min Smooth Loss: 1.7965 (iter 23140), Time: 301.05s\n",
            "Iter: 26500/100000, Smooth Loss: 1.8511, Min Smooth Loss: 1.7965 (iter 23140), Time: 301.69s\n",
            "Iter: 26600/100000, Smooth Loss: 1.8367, Min Smooth Loss: 1.7965 (iter 23140), Time: 302.16s\n",
            "Iter: 26700/100000, Smooth Loss: 1.8283, Min Smooth Loss: 1.7965 (iter 23140), Time: 302.55s\n",
            "Iter: 26800/100000, Smooth Loss: 1.8175, Min Smooth Loss: 1.7965 (iter 23140), Time: 302.95s\n",
            "Iter: 26900/100000, Smooth Loss: 1.8156, Min Smooth Loss: 1.7965 (iter 23140), Time: 303.37s\n",
            "Iter: 27000/100000, Smooth Loss: 1.8056, Min Smooth Loss: 1.7965 (iter 23140), Time: 303.79s\n",
            "  Validation Loss at iter 27000: 1.8436\n",
            "Iter: 27100/100000, Smooth Loss: 1.8073, Min Smooth Loss: 1.7965 (iter 23140), Time: 310.52s\n",
            "Iter: 27200/100000, Smooth Loss: 1.8050, Min Smooth Loss: 1.7965 (iter 23140), Time: 310.95s\n",
            "Iter: 27300/100000, Smooth Loss: 1.7905, Min Smooth Loss: 1.7905 (iter 27300), Time: 311.37s\n",
            "Iter: 27400/100000, Smooth Loss: 1.7952, Min Smooth Loss: 1.7890 (iter 27317), Time: 311.79s\n",
            "Iter: 27500/100000, Smooth Loss: 1.8056, Min Smooth Loss: 1.7890 (iter 27317), Time: 312.37s\n",
            "Iter: 27600/100000, Smooth Loss: 1.8138, Min Smooth Loss: 1.7890 (iter 27317), Time: 312.97s\n",
            "Iter: 27700/100000, Smooth Loss: 1.8195, Min Smooth Loss: 1.7890 (iter 27317), Time: 313.61s\n",
            "Iter: 27800/100000, Smooth Loss: 1.8237, Min Smooth Loss: 1.7890 (iter 27317), Time: 314.27s\n",
            "Iter: 27900/100000, Smooth Loss: 1.8241, Min Smooth Loss: 1.7890 (iter 27317), Time: 314.96s\n",
            "Iter: 28000/100000, Smooth Loss: 1.8228, Min Smooth Loss: 1.7890 (iter 27317), Time: 315.45s\n",
            "  Validation Loss at iter 28000: 1.8525\n",
            "Iter: 28100/100000, Smooth Loss: 1.8190, Min Smooth Loss: 1.7890 (iter 27317), Time: 322.26s\n",
            "Iter: 28200/100000, Smooth Loss: 1.8208, Min Smooth Loss: 1.7890 (iter 27317), Time: 322.68s\n",
            "Iter: 28300/100000, Smooth Loss: 1.8190, Min Smooth Loss: 1.7890 (iter 27317), Time: 323.10s\n",
            "Iter: 28400/100000, Smooth Loss: 1.8193, Min Smooth Loss: 1.7890 (iter 27317), Time: 323.50s\n",
            "Iter: 28500/100000, Smooth Loss: 1.8154, Min Smooth Loss: 1.7890 (iter 27317), Time: 323.90s\n",
            "Iter: 28600/100000, Smooth Loss: 1.8036, Min Smooth Loss: 1.7890 (iter 27317), Time: 324.29s\n",
            "Iter: 28700/100000, Smooth Loss: 1.7908, Min Smooth Loss: 1.7890 (iter 27317), Time: 324.68s\n",
            "Iter: 28800/100000, Smooth Loss: 1.7775, Min Smooth Loss: 1.7772 (iter 28799), Time: 325.09s\n",
            "Iter: 28900/100000, Smooth Loss: 1.7805, Min Smooth Loss: 1.7760 (iter 28806), Time: 325.73s\n",
            "Iter: 29000/100000, Smooth Loss: 1.7753, Min Smooth Loss: 1.7709 (iter 28981), Time: 326.34s\n",
            "  Validation Loss at iter 29000: 1.8580\n",
            "Iter: 29100/100000, Smooth Loss: 1.7860, Min Smooth Loss: 1.7709 (iter 28981), Time: 333.71s\n",
            "Iter: 29200/100000, Smooth Loss: 1.7947, Min Smooth Loss: 1.7709 (iter 28981), Time: 334.12s\n",
            "Iter: 29300/100000, Smooth Loss: 1.7933, Min Smooth Loss: 1.7709 (iter 28981), Time: 334.56s\n",
            "Iter: 29400/100000, Smooth Loss: 1.8020, Min Smooth Loss: 1.7709 (iter 28981), Time: 334.97s\n",
            "Iter: 29500/100000, Smooth Loss: 1.8016, Min Smooth Loss: 1.7709 (iter 28981), Time: 335.40s\n",
            "Iter: 29600/100000, Smooth Loss: 1.7964, Min Smooth Loss: 1.7709 (iter 28981), Time: 335.84s\n",
            "Iter: 29700/100000, Smooth Loss: 1.7880, Min Smooth Loss: 1.7709 (iter 28981), Time: 336.24s\n",
            "Iter: 29800/100000, Smooth Loss: 1.7844, Min Smooth Loss: 1.7709 (iter 28981), Time: 336.64s\n",
            "Iter: 29900/100000, Smooth Loss: 1.7847, Min Smooth Loss: 1.7709 (iter 28981), Time: 337.06s\n",
            "Iter: 30000/100000, Smooth Loss: 1.7847, Min Smooth Loss: 1.7709 (iter 28981), Time: 337.50s\n",
            "  Validation Loss at iter 30000: 1.8574\n",
            "--- Synthesized text at iter 30000 (using current model) ---\n",
            "his knee and the trenous thears and ary stre ove was lont of galioe sthald stroin, more watable arofly mo tweez.\n",
            "\n",
            "He fount air, over. \n",
            "When in, rearder oms. .Harry you had foreelly stap dere are, but \n",
            "---\n",
            "Iter: 30100/100000, Smooth Loss: 1.7813, Min Smooth Loss: 1.7709 (iter 28981), Time: 345.34s\n",
            "Iter: 30200/100000, Smooth Loss: 1.7741, Min Smooth Loss: 1.7709 (iter 28981), Time: 345.75s\n",
            "Iter: 30300/100000, Smooth Loss: 1.7626, Min Smooth Loss: 1.7624 (iter 30297), Time: 346.19s\n",
            "Iter: 30400/100000, Smooth Loss: 1.7559, Min Smooth Loss: 1.7534 (iter 30350), Time: 346.59s\n",
            "Iter: 30500/100000, Smooth Loss: 1.7539, Min Smooth Loss: 1.7529 (iter 30496), Time: 347.01s\n",
            "Iter: 30600/100000, Smooth Loss: 1.7628, Min Smooth Loss: 1.7529 (iter 30496), Time: 347.40s\n",
            "Iter: 30700/100000, Smooth Loss: 1.7628, Min Smooth Loss: 1.7529 (iter 30496), Time: 347.81s\n",
            "Iter: 30800/100000, Smooth Loss: 1.7698, Min Smooth Loss: 1.7529 (iter 30496), Time: 348.26s\n",
            "Iter: 30900/100000, Smooth Loss: 1.7880, Min Smooth Loss: 1.7529 (iter 30496), Time: 348.67s\n",
            "Iter: 31000/100000, Smooth Loss: 1.7828, Min Smooth Loss: 1.7529 (iter 30496), Time: 349.11s\n",
            "  Validation Loss at iter 31000: 1.8209\n",
            "Iter: 31100/100000, Smooth Loss: 1.7835, Min Smooth Loss: 1.7529 (iter 30496), Time: 356.71s\n",
            "Iter: 31200/100000, Smooth Loss: 1.7788, Min Smooth Loss: 1.7529 (iter 30496), Time: 357.09s\n",
            "Iter: 31300/100000, Smooth Loss: 1.7708, Min Smooth Loss: 1.7529 (iter 30496), Time: 357.47s\n",
            "Iter: 31400/100000, Smooth Loss: 1.7656, Min Smooth Loss: 1.7529 (iter 30496), Time: 357.88s\n",
            "Iter: 31500/100000, Smooth Loss: 1.7735, Min Smooth Loss: 1.7529 (iter 30496), Time: 358.28s\n",
            "Iter: 31600/100000, Smooth Loss: 1.7692, Min Smooth Loss: 1.7529 (iter 30496), Time: 358.68s\n",
            "Iter: 31700/100000, Smooth Loss: 1.7584, Min Smooth Loss: 1.7529 (iter 30496), Time: 359.07s\n",
            "Iter: 31800/100000, Smooth Loss: 1.7570, Min Smooth Loss: 1.7529 (iter 30496), Time: 359.46s\n",
            "Iter: 31900/100000, Smooth Loss: 1.7543, Min Smooth Loss: 1.7529 (iter 30496), Time: 359.88s\n",
            "Iter: 32000/100000, Smooth Loss: 1.7562, Min Smooth Loss: 1.7523 (iter 31914), Time: 360.28s\n",
            "  Validation Loss at iter 32000: 1.8012\n",
            "Iter: 32100/100000, Smooth Loss: 1.7500, Min Smooth Loss: 1.7499 (iter 32090), Time: 367.94s\n",
            "Iter: 32200/100000, Smooth Loss: 1.7436, Min Smooth Loss: 1.7429 (iter 32173), Time: 368.37s\n",
            "Iter: 32300/100000, Smooth Loss: 1.7420, Min Smooth Loss: 1.7386 (iter 32281), Time: 368.78s\n",
            "Iter: 32400/100000, Smooth Loss: 1.7389, Min Smooth Loss: 1.7372 (iter 32384), Time: 369.18s\n",
            "Iter: 32500/100000, Smooth Loss: 1.7369, Min Smooth Loss: 1.7354 (iter 32447), Time: 369.59s\n",
            "Iter: 32600/100000, Smooth Loss: 1.7369, Min Smooth Loss: 1.7336 (iter 32540), Time: 369.98s\n",
            "Iter: 32700/100000, Smooth Loss: 1.7453, Min Smooth Loss: 1.7336 (iter 32540), Time: 370.39s\n",
            "Iter: 32800/100000, Smooth Loss: 1.7528, Min Smooth Loss: 1.7336 (iter 32540), Time: 370.79s\n",
            "Iter: 32900/100000, Smooth Loss: 1.7543, Min Smooth Loss: 1.7336 (iter 32540), Time: 371.18s\n",
            "Iter: 33000/100000, Smooth Loss: 1.7557, Min Smooth Loss: 1.7336 (iter 32540), Time: 371.58s\n",
            "  Validation Loss at iter 33000: 1.8144\n",
            "Iter: 33100/100000, Smooth Loss: 1.7579, Min Smooth Loss: 1.7336 (iter 32540), Time: 379.41s\n",
            "Iter: 33200/100000, Smooth Loss: 1.7615, Min Smooth Loss: 1.7336 (iter 32540), Time: 380.07s\n",
            "Iter: 33300/100000, Smooth Loss: 1.7582, Min Smooth Loss: 1.7336 (iter 32540), Time: 380.74s\n",
            "Iter: 33400/100000, Smooth Loss: 1.7535, Min Smooth Loss: 1.7336 (iter 32540), Time: 381.21s\n",
            "Iter: 33500/100000, Smooth Loss: 1.7448, Min Smooth Loss: 1.7336 (iter 32540), Time: 381.61s\n",
            "Iter: 33600/100000, Smooth Loss: 1.7345, Min Smooth Loss: 1.7335 (iter 33595), Time: 382.02s\n",
            "Iter: 33700/100000, Smooth Loss: 1.7233, Min Smooth Loss: 1.7233 (iter 33700), Time: 382.41s\n",
            "Iter: 33800/100000, Smooth Loss: 1.7105, Min Smooth Loss: 1.7095 (iter 33795), Time: 382.80s\n",
            "Iter: 33900/100000, Smooth Loss: 1.7033, Min Smooth Loss: 1.7003 (iter 33872), Time: 383.22s\n",
            "Iter: 34000/100000, Smooth Loss: 1.7067, Min Smooth Loss: 1.7003 (iter 33872), Time: 383.61s\n",
            "  Validation Loss at iter 34000: 1.8192\n",
            "Iter: 34100/100000, Smooth Loss: 1.6960, Min Smooth Loss: 1.6960 (iter 34100), Time: 390.34s\n",
            "Iter: 34200/100000, Smooth Loss: 1.6930, Min Smooth Loss: 1.6916 (iter 34145), Time: 390.76s\n",
            "Iter: 34300/100000, Smooth Loss: 1.6813, Min Smooth Loss: 1.6811 (iter 34299), Time: 391.32s\n",
            "Iter: 34400/100000, Smooth Loss: 1.6804, Min Smooth Loss: 1.6798 (iter 34395), Time: 391.99s\n",
            "Iter: 34500/100000, Smooth Loss: 1.6814, Min Smooth Loss: 1.6777 (iter 34433), Time: 392.65s\n",
            "Iter: 34600/100000, Smooth Loss: 1.6805, Min Smooth Loss: 1.6763 (iter 34581), Time: 393.31s\n",
            "Iter: 34700/100000, Smooth Loss: 1.6913, Min Smooth Loss: 1.6763 (iter 34581), Time: 393.99s\n",
            "Iter: 34800/100000, Smooth Loss: 1.7013, Min Smooth Loss: 1.6763 (iter 34581), Time: 394.42s\n",
            "Iter: 34900/100000, Smooth Loss: 1.6972, Min Smooth Loss: 1.6763 (iter 34581), Time: 394.85s\n",
            "Iter: 35000/100000, Smooth Loss: 1.7140, Min Smooth Loss: 1.6763 (iter 34581), Time: 395.27s\n",
            "  Validation Loss at iter 35000: 1.7676\n",
            "Iter: 35100/100000, Smooth Loss: 1.7126, Min Smooth Loss: 1.6763 (iter 34581), Time: 402.14s\n",
            "Iter: 35200/100000, Smooth Loss: 1.7124, Min Smooth Loss: 1.6763 (iter 34581), Time: 402.55s\n",
            "Iter: 35300/100000, Smooth Loss: 1.7030, Min Smooth Loss: 1.6763 (iter 34581), Time: 402.95s\n",
            "Iter: 35400/100000, Smooth Loss: 1.6902, Min Smooth Loss: 1.6763 (iter 34581), Time: 403.37s\n",
            "Iter: 35500/100000, Smooth Loss: 1.6911, Min Smooth Loss: 1.6763 (iter 34581), Time: 403.79s\n",
            "Iter: 35600/100000, Smooth Loss: 1.6982, Min Smooth Loss: 1.6763 (iter 34581), Time: 404.34s\n",
            "Iter: 35700/100000, Smooth Loss: 1.7028, Min Smooth Loss: 1.6763 (iter 34581), Time: 404.96s\n",
            "Iter: 35800/100000, Smooth Loss: 1.7057, Min Smooth Loss: 1.6763 (iter 34581), Time: 405.60s\n",
            "Iter: 35900/100000, Smooth Loss: 1.7025, Min Smooth Loss: 1.6763 (iter 34581), Time: 406.21s\n",
            "Iter: 36000/100000, Smooth Loss: 1.7104, Min Smooth Loss: 1.6763 (iter 34581), Time: 406.86s\n",
            "  Validation Loss at iter 36000: 1.7864\n",
            "Iter: 36100/100000, Smooth Loss: 1.7032, Min Smooth Loss: 1.6763 (iter 34581), Time: 413.55s\n",
            "Iter: 36200/100000, Smooth Loss: 1.7053, Min Smooth Loss: 1.6763 (iter 34581), Time: 413.93s\n",
            "Iter: 36300/100000, Smooth Loss: 1.6987, Min Smooth Loss: 1.6763 (iter 34581), Time: 414.31s\n",
            "Iter: 36400/100000, Smooth Loss: 1.6948, Min Smooth Loss: 1.6763 (iter 34581), Time: 414.71s\n",
            "Iter: 36500/100000, Smooth Loss: 1.6814, Min Smooth Loss: 1.6763 (iter 34581), Time: 415.10s\n",
            "Iter: 36600/100000, Smooth Loss: 1.6803, Min Smooth Loss: 1.6763 (iter 34581), Time: 415.48s\n",
            "Iter: 36700/100000, Smooth Loss: 1.6848, Min Smooth Loss: 1.6763 (iter 34581), Time: 415.89s\n",
            "Iter: 36800/100000, Smooth Loss: 1.6924, Min Smooth Loss: 1.6763 (iter 34581), Time: 416.30s\n",
            "Iter: 36900/100000, Smooth Loss: 1.7065, Min Smooth Loss: 1.6763 (iter 34581), Time: 416.70s\n",
            "Iter: 37000/100000, Smooth Loss: 1.7222, Min Smooth Loss: 1.6763 (iter 34581), Time: 417.09s\n",
            "  Validation Loss at iter 37000: 1.7604\n",
            "Iter: 37100/100000, Smooth Loss: 1.7232, Min Smooth Loss: 1.6763 (iter 34581), Time: 424.75s\n",
            "Iter: 37200/100000, Smooth Loss: 1.7210, Min Smooth Loss: 1.6763 (iter 34581), Time: 425.17s\n",
            "Iter: 37300/100000, Smooth Loss: 1.7150, Min Smooth Loss: 1.6763 (iter 34581), Time: 425.56s\n",
            "Iter: 37400/100000, Smooth Loss: 1.7079, Min Smooth Loss: 1.6763 (iter 34581), Time: 425.95s\n",
            "Iter: 37500/100000, Smooth Loss: 1.7123, Min Smooth Loss: 1.6763 (iter 34581), Time: 426.35s\n",
            "Iter: 37600/100000, Smooth Loss: 1.7076, Min Smooth Loss: 1.6763 (iter 34581), Time: 426.73s\n",
            "Iter: 37700/100000, Smooth Loss: 1.7099, Min Smooth Loss: 1.6763 (iter 34581), Time: 427.13s\n",
            "Iter: 37800/100000, Smooth Loss: 1.7136, Min Smooth Loss: 1.6763 (iter 34581), Time: 427.54s\n",
            "Iter: 37900/100000, Smooth Loss: 1.7066, Min Smooth Loss: 1.6763 (iter 34581), Time: 427.96s\n",
            "Iter: 38000/100000, Smooth Loss: 1.7202, Min Smooth Loss: 1.6763 (iter 34581), Time: 428.38s\n",
            "  Validation Loss at iter 38000: 1.7647\n",
            "Iter: 38100/100000, Smooth Loss: 1.7223, Min Smooth Loss: 1.6763 (iter 34581), Time: 436.21s\n",
            "Iter: 38200/100000, Smooth Loss: 1.7187, Min Smooth Loss: 1.6763 (iter 34581), Time: 436.61s\n",
            "Iter: 38300/100000, Smooth Loss: 1.7056, Min Smooth Loss: 1.6763 (iter 34581), Time: 437.03s\n",
            "Iter: 38400/100000, Smooth Loss: 1.7020, Min Smooth Loss: 1.6763 (iter 34581), Time: 437.45s\n",
            "Iter: 38500/100000, Smooth Loss: 1.6978, Min Smooth Loss: 1.6763 (iter 34581), Time: 437.89s\n",
            "Iter: 38600/100000, Smooth Loss: 1.6881, Min Smooth Loss: 1.6763 (iter 34581), Time: 438.30s\n",
            "Iter: 38700/100000, Smooth Loss: 1.6860, Min Smooth Loss: 1.6763 (iter 34581), Time: 438.70s\n",
            "Iter: 38800/100000, Smooth Loss: 1.6855, Min Smooth Loss: 1.6763 (iter 34581), Time: 439.13s\n",
            "Iter: 38900/100000, Smooth Loss: 1.6879, Min Smooth Loss: 1.6763 (iter 34581), Time: 439.52s\n",
            "Iter: 39000/100000, Smooth Loss: 1.6948, Min Smooth Loss: 1.6763 (iter 34581), Time: 439.94s\n",
            "  Validation Loss at iter 39000: 1.7778\n",
            "Iter: 39100/100000, Smooth Loss: 1.7018, Min Smooth Loss: 1.6763 (iter 34581), Time: 447.78s\n",
            "Iter: 39200/100000, Smooth Loss: 1.7081, Min Smooth Loss: 1.6763 (iter 34581), Time: 448.21s\n",
            "Iter: 39300/100000, Smooth Loss: 1.7077, Min Smooth Loss: 1.6763 (iter 34581), Time: 448.62s\n",
            "Iter: 39400/100000, Smooth Loss: 1.7139, Min Smooth Loss: 1.6763 (iter 34581), Time: 449.03s\n",
            "Iter: 39500/100000, Smooth Loss: 1.7139, Min Smooth Loss: 1.6763 (iter 34581), Time: 449.47s\n",
            "Iter: 39600/100000, Smooth Loss: 1.7204, Min Smooth Loss: 1.6763 (iter 34581), Time: 449.91s\n",
            "Iter: 39700/100000, Smooth Loss: 1.7122, Min Smooth Loss: 1.6763 (iter 34581), Time: 450.35s\n",
            "Iter: 39800/100000, Smooth Loss: 1.7028, Min Smooth Loss: 1.6763 (iter 34581), Time: 450.77s\n",
            "Iter: 39900/100000, Smooth Loss: 1.7075, Min Smooth Loss: 1.6763 (iter 34581), Time: 451.18s\n",
            "Iter: 40000/100000, Smooth Loss: 1.7257, Min Smooth Loss: 1.6763 (iter 34581), Time: 451.59s\n",
            "  Validation Loss at iter 40000: 1.7592\n",
            "--- Synthesized text at iter 40000 (using current model) ---\n",
            "smeady nove Harry winde could. Hare I gunded apparcup, and Harry cose fere, Frat Harry.\n",
            "\t\t\"I reat rid.\n",
            "\"I looks an't.  un mad course ..\n",
            "\t\t\"Aroted to A knew, likeler, air the vally?\"\n",
            "There, up the sure\n",
            "---\n",
            "Iter: 40100/100000, Smooth Loss: 1.7303, Min Smooth Loss: 1.6763 (iter 34581), Time: 459.36s\n",
            "Iter: 40200/100000, Smooth Loss: 1.7291, Min Smooth Loss: 1.6763 (iter 34581), Time: 459.94s\n",
            "Iter: 40300/100000, Smooth Loss: 1.7247, Min Smooth Loss: 1.6763 (iter 34581), Time: 460.36s\n",
            "Iter: 40400/100000, Smooth Loss: 1.7290, Min Smooth Loss: 1.6763 (iter 34581), Time: 460.78s\n",
            "Iter: 40500/100000, Smooth Loss: 1.7341, Min Smooth Loss: 1.6763 (iter 34581), Time: 461.22s\n",
            "Iter: 40600/100000, Smooth Loss: 1.7299, Min Smooth Loss: 1.6763 (iter 34581), Time: 461.63s\n",
            "Iter: 40700/100000, Smooth Loss: 1.7301, Min Smooth Loss: 1.6763 (iter 34581), Time: 462.03s\n",
            "Iter: 40800/100000, Smooth Loss: 1.7188, Min Smooth Loss: 1.6763 (iter 34581), Time: 462.45s\n",
            "Iter: 40900/100000, Smooth Loss: 1.7154, Min Smooth Loss: 1.6763 (iter 34581), Time: 462.86s\n",
            "Iter: 41000/100000, Smooth Loss: 1.7199, Min Smooth Loss: 1.6763 (iter 34581), Time: 463.30s\n",
            "  Validation Loss at iter 41000: 1.7991\n",
            "Iter: 41100/100000, Smooth Loss: 1.7105, Min Smooth Loss: 1.6763 (iter 34581), Time: 470.32s\n",
            "Iter: 41200/100000, Smooth Loss: 1.7093, Min Smooth Loss: 1.6763 (iter 34581), Time: 470.95s\n",
            "Iter: 41300/100000, Smooth Loss: 1.7147, Min Smooth Loss: 1.6763 (iter 34581), Time: 471.59s\n",
            "Iter: 41400/100000, Smooth Loss: 1.7128, Min Smooth Loss: 1.6763 (iter 34581), Time: 472.23s\n",
            "Iter: 41500/100000, Smooth Loss: 1.7360, Min Smooth Loss: 1.6763 (iter 34581), Time: 472.88s\n",
            "Iter: 41600/100000, Smooth Loss: 1.7457, Min Smooth Loss: 1.6763 (iter 34581), Time: 473.29s\n",
            "Iter: 41700/100000, Smooth Loss: 1.7432, Min Smooth Loss: 1.6763 (iter 34581), Time: 473.67s\n",
            "Iter: 41800/100000, Smooth Loss: 1.7425, Min Smooth Loss: 1.6763 (iter 34581), Time: 474.08s\n",
            "Iter: 41900/100000, Smooth Loss: 1.7419, Min Smooth Loss: 1.6763 (iter 34581), Time: 474.47s\n",
            "Iter: 42000/100000, Smooth Loss: 1.7288, Min Smooth Loss: 1.6763 (iter 34581), Time: 474.89s\n",
            "  Validation Loss at iter 42000: 1.7677\n",
            "Iter: 42100/100000, Smooth Loss: 1.7358, Min Smooth Loss: 1.6763 (iter 34581), Time: 481.43s\n",
            "Iter: 42200/100000, Smooth Loss: 1.7422, Min Smooth Loss: 1.6763 (iter 34581), Time: 481.82s\n",
            "Iter: 42300/100000, Smooth Loss: 1.7420, Min Smooth Loss: 1.6763 (iter 34581), Time: 482.22s\n",
            "Iter: 42400/100000, Smooth Loss: 1.7400, Min Smooth Loss: 1.6763 (iter 34581), Time: 482.60s\n",
            "Iter: 42500/100000, Smooth Loss: 1.7419, Min Smooth Loss: 1.6763 (iter 34581), Time: 483.05s\n",
            "Iter: 42600/100000, Smooth Loss: 1.7308, Min Smooth Loss: 1.6763 (iter 34581), Time: 483.67s\n",
            "Iter: 42700/100000, Smooth Loss: 1.7194, Min Smooth Loss: 1.6763 (iter 34581), Time: 484.29s\n",
            "Iter: 42800/100000, Smooth Loss: 1.7087, Min Smooth Loss: 1.6763 (iter 34581), Time: 484.89s\n",
            "Iter: 42900/100000, Smooth Loss: 1.7042, Min Smooth Loss: 1.6763 (iter 34581), Time: 485.55s\n",
            "Iter: 43000/100000, Smooth Loss: 1.7098, Min Smooth Loss: 1.6763 (iter 34581), Time: 486.12s\n",
            "  Validation Loss at iter 43000: 1.7743\n",
            "Iter: 43100/100000, Smooth Loss: 1.7014, Min Smooth Loss: 1.6763 (iter 34581), Time: 492.73s\n",
            "Iter: 43200/100000, Smooth Loss: 1.7073, Min Smooth Loss: 1.6763 (iter 34581), Time: 493.13s\n",
            "Iter: 43300/100000, Smooth Loss: 1.7075, Min Smooth Loss: 1.6763 (iter 34581), Time: 493.52s\n",
            "Iter: 43400/100000, Smooth Loss: 1.7064, Min Smooth Loss: 1.6763 (iter 34581), Time: 493.95s\n",
            "Iter: 43500/100000, Smooth Loss: 1.7123, Min Smooth Loss: 1.6763 (iter 34581), Time: 494.36s\n",
            "Iter: 43600/100000, Smooth Loss: 1.7173, Min Smooth Loss: 1.6763 (iter 34581), Time: 494.79s\n",
            "Iter: 43700/100000, Smooth Loss: 1.7241, Min Smooth Loss: 1.6763 (iter 34581), Time: 495.21s\n",
            "Iter: 43800/100000, Smooth Loss: 1.7235, Min Smooth Loss: 1.6763 (iter 34581), Time: 495.61s\n",
            "Iter: 43900/100000, Smooth Loss: 1.7205, Min Smooth Loss: 1.6763 (iter 34581), Time: 496.06s\n",
            "Iter: 44000/100000, Smooth Loss: 1.7191, Min Smooth Loss: 1.6763 (iter 34581), Time: 496.67s\n",
            "  Validation Loss at iter 44000: 1.7764\n",
            "Iter: 44100/100000, Smooth Loss: 1.7262, Min Smooth Loss: 1.6763 (iter 34581), Time: 504.13s\n",
            "Iter: 44200/100000, Smooth Loss: 1.7249, Min Smooth Loss: 1.6763 (iter 34581), Time: 504.55s\n",
            "Iter: 44300/100000, Smooth Loss: 1.7237, Min Smooth Loss: 1.6763 (iter 34581), Time: 504.95s\n",
            "Iter: 44400/100000, Smooth Loss: 1.7256, Min Smooth Loss: 1.6763 (iter 34581), Time: 505.37s\n",
            "Iter: 44500/100000, Smooth Loss: 1.7264, Min Smooth Loss: 1.6763 (iter 34581), Time: 505.78s\n",
            "Iter: 44600/100000, Smooth Loss: 1.7288, Min Smooth Loss: 1.6763 (iter 34581), Time: 506.17s\n",
            "Iter: 44700/100000, Smooth Loss: 1.7276, Min Smooth Loss: 1.6763 (iter 34581), Time: 506.61s\n",
            "Iter: 44800/100000, Smooth Loss: 1.7361, Min Smooth Loss: 1.6763 (iter 34581), Time: 506.99s\n",
            "Iter: 44900/100000, Smooth Loss: 1.7343, Min Smooth Loss: 1.6763 (iter 34581), Time: 507.38s\n",
            "Iter: 45000/100000, Smooth Loss: 1.7330, Min Smooth Loss: 1.6763 (iter 34581), Time: 507.79s\n",
            "  Validation Loss at iter 45000: 1.7688\n",
            "Iter: 45100/100000, Smooth Loss: 1.7393, Min Smooth Loss: 1.6763 (iter 34581), Time: 515.48s\n",
            "Iter: 45200/100000, Smooth Loss: 1.7433, Min Smooth Loss: 1.6763 (iter 34581), Time: 515.90s\n",
            "Iter: 45300/100000, Smooth Loss: 1.7462, Min Smooth Loss: 1.6763 (iter 34581), Time: 516.32s\n",
            "Iter: 45400/100000, Smooth Loss: 1.7474, Min Smooth Loss: 1.6763 (iter 34581), Time: 516.72s\n",
            "Iter: 45500/100000, Smooth Loss: 1.7539, Min Smooth Loss: 1.6763 (iter 34581), Time: 517.15s\n",
            "Iter: 45600/100000, Smooth Loss: 1.7501, Min Smooth Loss: 1.6763 (iter 34581), Time: 517.54s\n",
            "Iter: 45700/100000, Smooth Loss: 1.7556, Min Smooth Loss: 1.6763 (iter 34581), Time: 517.98s\n",
            "Iter: 45800/100000, Smooth Loss: 1.7513, Min Smooth Loss: 1.6763 (iter 34581), Time: 518.44s\n",
            "Iter: 45900/100000, Smooth Loss: 1.7558, Min Smooth Loss: 1.6763 (iter 34581), Time: 518.87s\n",
            "Iter: 46000/100000, Smooth Loss: 1.7536, Min Smooth Loss: 1.6763 (iter 34581), Time: 519.31s\n",
            "  Validation Loss at iter 46000: 1.7571\n",
            "Iter: 46100/100000, Smooth Loss: 1.7567, Min Smooth Loss: 1.6763 (iter 34581), Time: 527.12s\n",
            "Iter: 46200/100000, Smooth Loss: 1.7784, Min Smooth Loss: 1.6763 (iter 34581), Time: 527.50s\n",
            "Iter: 46300/100000, Smooth Loss: 1.7948, Min Smooth Loss: 1.6763 (iter 34581), Time: 527.93s\n",
            "Iter: 46400/100000, Smooth Loss: 1.7943, Min Smooth Loss: 1.6763 (iter 34581), Time: 528.34s\n",
            "Iter: 46500/100000, Smooth Loss: 1.7972, Min Smooth Loss: 1.6763 (iter 34581), Time: 528.74s\n",
            "Iter: 46600/100000, Smooth Loss: 1.7924, Min Smooth Loss: 1.6763 (iter 34581), Time: 529.13s\n",
            "Iter: 46700/100000, Smooth Loss: 1.7854, Min Smooth Loss: 1.6763 (iter 34581), Time: 529.52s\n",
            "Iter: 46800/100000, Smooth Loss: 1.7809, Min Smooth Loss: 1.6763 (iter 34581), Time: 529.95s\n",
            "Iter: 46900/100000, Smooth Loss: 1.7739, Min Smooth Loss: 1.6763 (iter 34581), Time: 530.34s\n",
            "Iter: 47000/100000, Smooth Loss: 1.7715, Min Smooth Loss: 1.6763 (iter 34581), Time: 530.76s\n",
            "  Validation Loss at iter 47000: 1.7830\n",
            "Iter: 47100/100000, Smooth Loss: 1.7610, Min Smooth Loss: 1.6763 (iter 34581), Time: 538.32s\n",
            "Iter: 47200/100000, Smooth Loss: 1.7456, Min Smooth Loss: 1.6763 (iter 34581), Time: 538.85s\n",
            "Iter: 47300/100000, Smooth Loss: 1.7413, Min Smooth Loss: 1.6763 (iter 34581), Time: 539.26s\n",
            "Iter: 47400/100000, Smooth Loss: 1.7347, Min Smooth Loss: 1.6763 (iter 34581), Time: 539.66s\n",
            "Iter: 47500/100000, Smooth Loss: 1.7337, Min Smooth Loss: 1.6763 (iter 34581), Time: 540.07s\n",
            "Iter: 47600/100000, Smooth Loss: 1.7210, Min Smooth Loss: 1.6763 (iter 34581), Time: 540.48s\n",
            "Iter: 47700/100000, Smooth Loss: 1.7194, Min Smooth Loss: 1.6763 (iter 34581), Time: 540.86s\n",
            "Iter: 47800/100000, Smooth Loss: 1.7083, Min Smooth Loss: 1.6763 (iter 34581), Time: 541.28s\n",
            "Iter: 47900/100000, Smooth Loss: 1.7061, Min Smooth Loss: 1.6763 (iter 34581), Time: 541.66s\n",
            "Iter: 48000/100000, Smooth Loss: 1.6985, Min Smooth Loss: 1.6763 (iter 34581), Time: 542.05s\n",
            "  Validation Loss at iter 48000: 1.7770\n",
            "Iter: 48100/100000, Smooth Loss: 1.6953, Min Smooth Loss: 1.6763 (iter 34581), Time: 548.87s\n",
            "Iter: 48200/100000, Smooth Loss: 1.6926, Min Smooth Loss: 1.6763 (iter 34581), Time: 549.49s\n",
            "Iter: 48300/100000, Smooth Loss: 1.6783, Min Smooth Loss: 1.6763 (iter 34581), Time: 550.12s\n",
            "Iter: 48400/100000, Smooth Loss: 1.6645, Min Smooth Loss: 1.6645 (iter 48399), Time: 550.72s\n",
            "Iter: 48500/100000, Smooth Loss: 1.6637, Min Smooth Loss: 1.6632 (iter 48430), Time: 551.35s\n",
            "Iter: 48600/100000, Smooth Loss: 1.6704, Min Smooth Loss: 1.6589 (iter 48539), Time: 551.93s\n",
            "Iter: 48700/100000, Smooth Loss: 1.6831, Min Smooth Loss: 1.6589 (iter 48539), Time: 552.33s\n",
            "Iter: 48800/100000, Smooth Loss: 1.6847, Min Smooth Loss: 1.6589 (iter 48539), Time: 552.73s\n",
            "Iter: 48900/100000, Smooth Loss: 1.6847, Min Smooth Loss: 1.6589 (iter 48539), Time: 553.15s\n",
            "Iter: 49000/100000, Smooth Loss: 1.6971, Min Smooth Loss: 1.6589 (iter 48539), Time: 553.56s\n",
            "  Validation Loss at iter 49000: 1.7567\n",
            "Iter: 49100/100000, Smooth Loss: 1.7021, Min Smooth Loss: 1.6589 (iter 48539), Time: 560.19s\n",
            "Iter: 49200/100000, Smooth Loss: 1.7039, Min Smooth Loss: 1.6589 (iter 48539), Time: 560.57s\n",
            "Iter: 49300/100000, Smooth Loss: 1.7016, Min Smooth Loss: 1.6589 (iter 48539), Time: 560.95s\n",
            "Iter: 49400/100000, Smooth Loss: 1.7068, Min Smooth Loss: 1.6589 (iter 48539), Time: 561.38s\n",
            "Iter: 49500/100000, Smooth Loss: 1.6969, Min Smooth Loss: 1.6589 (iter 48539), Time: 561.83s\n",
            "Iter: 49600/100000, Smooth Loss: 1.7019, Min Smooth Loss: 1.6589 (iter 48539), Time: 562.46s\n",
            "Iter: 49700/100000, Smooth Loss: 1.6984, Min Smooth Loss: 1.6589 (iter 48539), Time: 563.06s\n",
            "Iter: 49800/100000, Smooth Loss: 1.6952, Min Smooth Loss: 1.6589 (iter 48539), Time: 563.69s\n",
            "Iter: 49900/100000, Smooth Loss: 1.7101, Min Smooth Loss: 1.6589 (iter 48539), Time: 564.33s\n",
            "Iter: 50000/100000, Smooth Loss: 1.7112, Min Smooth Loss: 1.6589 (iter 48539), Time: 564.94s\n",
            "  Validation Loss at iter 50000: 1.7709\n",
            "--- Synthesized text at iter 50000 (using current model) ---\n",
            "ce thank of the tored becaviol as and got amout ot whain, and Sparstan dop us Covery wither, toops bedraineding that elfeniver headd shark, back deven't to mearibarde yoo. \"Now.  \"We speex.\n",
            "\"Momed a f\n",
            "---\n",
            "Iter: 50100/100000, Smooth Loss: 1.7125, Min Smooth Loss: 1.6589 (iter 48539), Time: 571.59s\n",
            "Iter: 50200/100000, Smooth Loss: 1.7232, Min Smooth Loss: 1.6589 (iter 48539), Time: 572.00s\n",
            "Iter: 50300/100000, Smooth Loss: 1.7244, Min Smooth Loss: 1.6589 (iter 48539), Time: 572.40s\n",
            "Iter: 50400/100000, Smooth Loss: 1.7225, Min Smooth Loss: 1.6589 (iter 48539), Time: 572.82s\n",
            "Iter: 50500/100000, Smooth Loss: 1.7405, Min Smooth Loss: 1.6589 (iter 48539), Time: 573.24s\n",
            "Iter: 50600/100000, Smooth Loss: 1.7507, Min Smooth Loss: 1.6589 (iter 48539), Time: 573.65s\n",
            "Iter: 50700/100000, Smooth Loss: 1.7610, Min Smooth Loss: 1.6589 (iter 48539), Time: 574.10s\n",
            "Iter: 50800/100000, Smooth Loss: 1.7593, Min Smooth Loss: 1.6589 (iter 48539), Time: 574.51s\n",
            "Iter: 50900/100000, Smooth Loss: 1.7592, Min Smooth Loss: 1.6589 (iter 48539), Time: 574.95s\n",
            "Iter: 51000/100000, Smooth Loss: 1.7509, Min Smooth Loss: 1.6589 (iter 48539), Time: 575.59s\n",
            "  Validation Loss at iter 51000: 1.7380\n",
            "Iter: 51100/100000, Smooth Loss: 1.7505, Min Smooth Loss: 1.6589 (iter 48539), Time: 583.13s\n",
            "Iter: 51200/100000, Smooth Loss: 1.7455, Min Smooth Loss: 1.6589 (iter 48539), Time: 583.56s\n",
            "Iter: 51300/100000, Smooth Loss: 1.7383, Min Smooth Loss: 1.6589 (iter 48539), Time: 583.96s\n",
            "Iter: 51400/100000, Smooth Loss: 1.7415, Min Smooth Loss: 1.6589 (iter 48539), Time: 584.40s\n",
            "Iter: 51500/100000, Smooth Loss: 1.7467, Min Smooth Loss: 1.6589 (iter 48539), Time: 584.81s\n",
            "Iter: 51600/100000, Smooth Loss: 1.7559, Min Smooth Loss: 1.6589 (iter 48539), Time: 585.22s\n",
            "Iter: 51700/100000, Smooth Loss: 1.7653, Min Smooth Loss: 1.6589 (iter 48539), Time: 585.64s\n",
            "Iter: 51800/100000, Smooth Loss: 1.7608, Min Smooth Loss: 1.6589 (iter 48539), Time: 586.06s\n",
            "Iter: 51900/100000, Smooth Loss: 1.7533, Min Smooth Loss: 1.6589 (iter 48539), Time: 586.47s\n",
            "Iter: 52000/100000, Smooth Loss: 1.7508, Min Smooth Loss: 1.6589 (iter 48539), Time: 586.86s\n",
            "  Validation Loss at iter 52000: 1.7441\n",
            "Iter: 52100/100000, Smooth Loss: 1.7553, Min Smooth Loss: 1.6589 (iter 48539), Time: 594.55s\n",
            "Iter: 52200/100000, Smooth Loss: 1.7430, Min Smooth Loss: 1.6589 (iter 48539), Time: 594.95s\n",
            "Iter: 52300/100000, Smooth Loss: 1.7321, Min Smooth Loss: 1.6589 (iter 48539), Time: 595.37s\n",
            "Iter: 52400/100000, Smooth Loss: 1.7342, Min Smooth Loss: 1.6589 (iter 48539), Time: 595.77s\n",
            "Iter: 52500/100000, Smooth Loss: 1.7321, Min Smooth Loss: 1.6589 (iter 48539), Time: 596.19s\n",
            "Iter: 52600/100000, Smooth Loss: 1.7290, Min Smooth Loss: 1.6589 (iter 48539), Time: 596.63s\n",
            "Iter: 52700/100000, Smooth Loss: 1.7213, Min Smooth Loss: 1.6589 (iter 48539), Time: 597.02s\n",
            "Iter: 52800/100000, Smooth Loss: 1.7198, Min Smooth Loss: 1.6589 (iter 48539), Time: 597.42s\n",
            "Iter: 52900/100000, Smooth Loss: 1.7169, Min Smooth Loss: 1.6589 (iter 48539), Time: 597.81s\n",
            "Iter: 53000/100000, Smooth Loss: 1.7015, Min Smooth Loss: 1.6589 (iter 48539), Time: 598.24s\n",
            "  Validation Loss at iter 53000: 1.7233\n",
            "Iter: 53100/100000, Smooth Loss: 1.6964, Min Smooth Loss: 1.6589 (iter 48539), Time: 605.90s\n",
            "Iter: 53200/100000, Smooth Loss: 1.6963, Min Smooth Loss: 1.6589 (iter 48539), Time: 606.31s\n",
            "Iter: 53300/100000, Smooth Loss: 1.6999, Min Smooth Loss: 1.6589 (iter 48539), Time: 606.71s\n",
            "Iter: 53400/100000, Smooth Loss: 1.6998, Min Smooth Loss: 1.6589 (iter 48539), Time: 607.10s\n",
            "Iter: 53500/100000, Smooth Loss: 1.7074, Min Smooth Loss: 1.6589 (iter 48539), Time: 607.49s\n",
            "Iter: 53600/100000, Smooth Loss: 1.7023, Min Smooth Loss: 1.6589 (iter 48539), Time: 607.91s\n",
            "Iter: 53700/100000, Smooth Loss: 1.7043, Min Smooth Loss: 1.6589 (iter 48539), Time: 608.31s\n",
            "Iter: 53800/100000, Smooth Loss: 1.7082, Min Smooth Loss: 1.6589 (iter 48539), Time: 608.74s\n",
            "Iter: 53900/100000, Smooth Loss: 1.7291, Min Smooth Loss: 1.6589 (iter 48539), Time: 609.14s\n",
            "Iter: 54000/100000, Smooth Loss: 1.7385, Min Smooth Loss: 1.6589 (iter 48539), Time: 609.53s\n",
            "  Validation Loss at iter 54000: 1.7266\n",
            "Iter: 54100/100000, Smooth Loss: 1.7355, Min Smooth Loss: 1.6589 (iter 48539), Time: 616.99s\n",
            "Iter: 54200/100000, Smooth Loss: 1.7345, Min Smooth Loss: 1.6589 (iter 48539), Time: 617.53s\n",
            "Iter: 54300/100000, Smooth Loss: 1.7304, Min Smooth Loss: 1.6589 (iter 48539), Time: 617.93s\n",
            "Iter: 54400/100000, Smooth Loss: 1.7359, Min Smooth Loss: 1.6589 (iter 48539), Time: 618.35s\n",
            "Iter: 54500/100000, Smooth Loss: 1.7350, Min Smooth Loss: 1.6589 (iter 48539), Time: 618.75s\n",
            "Iter: 54600/100000, Smooth Loss: 1.7333, Min Smooth Loss: 1.6589 (iter 48539), Time: 619.15s\n",
            "Iter: 54700/100000, Smooth Loss: 1.7291, Min Smooth Loss: 1.6589 (iter 48539), Time: 619.56s\n",
            "Iter: 54800/100000, Smooth Loss: 1.7177, Min Smooth Loss: 1.6589 (iter 48539), Time: 619.95s\n",
            "Iter: 54900/100000, Smooth Loss: 1.7090, Min Smooth Loss: 1.6589 (iter 48539), Time: 620.34s\n",
            "Iter: 55000/100000, Smooth Loss: 1.6997, Min Smooth Loss: 1.6589 (iter 48539), Time: 620.75s\n",
            "  Validation Loss at iter 55000: 1.7230\n",
            "Iter: 55100/100000, Smooth Loss: 1.6992, Min Smooth Loss: 1.6589 (iter 48539), Time: 627.41s\n",
            "Iter: 55200/100000, Smooth Loss: 1.6921, Min Smooth Loss: 1.6589 (iter 48539), Time: 628.07s\n",
            "Iter: 55300/100000, Smooth Loss: 1.6828, Min Smooth Loss: 1.6589 (iter 48539), Time: 628.68s\n",
            "Iter: 55400/100000, Smooth Loss: 1.6737, Min Smooth Loss: 1.6589 (iter 48539), Time: 629.27s\n",
            "Iter: 55500/100000, Smooth Loss: 1.6755, Min Smooth Loss: 1.6589 (iter 48539), Time: 629.90s\n",
            "Iter: 55600/100000, Smooth Loss: 1.6743, Min Smooth Loss: 1.6589 (iter 48539), Time: 630.50s\n",
            "Iter: 55700/100000, Smooth Loss: 1.6819, Min Smooth Loss: 1.6589 (iter 48539), Time: 630.88s\n",
            "Iter: 55800/100000, Smooth Loss: 1.6842, Min Smooth Loss: 1.6589 (iter 48539), Time: 631.29s\n",
            "Iter: 55900/100000, Smooth Loss: 1.6732, Min Smooth Loss: 1.6589 (iter 48539), Time: 631.68s\n",
            "Iter: 56000/100000, Smooth Loss: 1.6700, Min Smooth Loss: 1.6589 (iter 48539), Time: 632.07s\n",
            "  Validation Loss at iter 56000: 1.7124\n",
            "Iter: 56100/100000, Smooth Loss: 1.6646, Min Smooth Loss: 1.6589 (iter 48539), Time: 638.89s\n",
            "Iter: 56200/100000, Smooth Loss: 1.6478, Min Smooth Loss: 1.6478 (iter 56200), Time: 639.33s\n",
            "Iter: 56300/100000, Smooth Loss: 1.6552, Min Smooth Loss: 1.6463 (iter 56248), Time: 639.73s\n",
            "Iter: 56400/100000, Smooth Loss: 1.6545, Min Smooth Loss: 1.6463 (iter 56248), Time: 640.12s\n",
            "Iter: 56500/100000, Smooth Loss: 1.6509, Min Smooth Loss: 1.6463 (iter 56248), Time: 640.56s\n",
            "Iter: 56600/100000, Smooth Loss: 1.6588, Min Smooth Loss: 1.6463 (iter 56248), Time: 641.18s\n",
            "Iter: 56700/100000, Smooth Loss: 1.6591, Min Smooth Loss: 1.6463 (iter 56248), Time: 641.82s\n",
            "Iter: 56800/100000, Smooth Loss: 1.6507, Min Smooth Loss: 1.6463 (iter 56248), Time: 642.42s\n",
            "Iter: 56900/100000, Smooth Loss: 1.6506, Min Smooth Loss: 1.6463 (iter 56248), Time: 643.10s\n",
            "Iter: 57000/100000, Smooth Loss: 1.6495, Min Smooth Loss: 1.6463 (iter 56248), Time: 643.71s\n",
            "  Validation Loss at iter 57000: 1.7011\n",
            "Iter: 57100/100000, Smooth Loss: 1.6521, Min Smooth Loss: 1.6463 (iter 56248), Time: 650.80s\n",
            "Iter: 57200/100000, Smooth Loss: 1.6471, Min Smooth Loss: 1.6461 (iter 57168), Time: 651.21s\n",
            "Iter: 57300/100000, Smooth Loss: 1.6432, Min Smooth Loss: 1.6429 (iter 57275), Time: 651.60s\n",
            "Iter: 57400/100000, Smooth Loss: 1.6426, Min Smooth Loss: 1.6401 (iter 57383), Time: 652.01s\n",
            "Iter: 57500/100000, Smooth Loss: 1.6553, Min Smooth Loss: 1.6401 (iter 57383), Time: 652.40s\n",
            "Iter: 57600/100000, Smooth Loss: 1.6548, Min Smooth Loss: 1.6401 (iter 57383), Time: 652.79s\n",
            "Iter: 57700/100000, Smooth Loss: 1.6604, Min Smooth Loss: 1.6401 (iter 57383), Time: 653.19s\n",
            "Iter: 57800/100000, Smooth Loss: 1.6688, Min Smooth Loss: 1.6401 (iter 57383), Time: 653.59s\n",
            "Iter: 57900/100000, Smooth Loss: 1.6667, Min Smooth Loss: 1.6401 (iter 57383), Time: 654.22s\n",
            "Iter: 58000/100000, Smooth Loss: 1.6647, Min Smooth Loss: 1.6401 (iter 57383), Time: 654.80s\n",
            "  Validation Loss at iter 58000: 1.7084\n",
            "Iter: 58100/100000, Smooth Loss: 1.6738, Min Smooth Loss: 1.6401 (iter 57383), Time: 661.99s\n",
            "Iter: 58200/100000, Smooth Loss: 1.6666, Min Smooth Loss: 1.6401 (iter 57383), Time: 662.39s\n",
            "Iter: 58300/100000, Smooth Loss: 1.6636, Min Smooth Loss: 1.6401 (iter 57383), Time: 662.80s\n",
            "Iter: 58400/100000, Smooth Loss: 1.6708, Min Smooth Loss: 1.6401 (iter 57383), Time: 663.19s\n",
            "Iter: 58500/100000, Smooth Loss: 1.6717, Min Smooth Loss: 1.6401 (iter 57383), Time: 663.59s\n",
            "Iter: 58600/100000, Smooth Loss: 1.6668, Min Smooth Loss: 1.6401 (iter 57383), Time: 663.99s\n",
            "Iter: 58700/100000, Smooth Loss: 1.6695, Min Smooth Loss: 1.6401 (iter 57383), Time: 664.38s\n",
            "Iter: 58800/100000, Smooth Loss: 1.6766, Min Smooth Loss: 1.6401 (iter 57383), Time: 664.78s\n",
            "Iter: 58900/100000, Smooth Loss: 1.6723, Min Smooth Loss: 1.6401 (iter 57383), Time: 665.17s\n",
            "Iter: 59000/100000, Smooth Loss: 1.6708, Min Smooth Loss: 1.6401 (iter 57383), Time: 665.57s\n",
            "  Validation Loss at iter 59000: 1.7153\n",
            "Iter: 59100/100000, Smooth Loss: 1.6752, Min Smooth Loss: 1.6401 (iter 57383), Time: 673.36s\n",
            "Iter: 59200/100000, Smooth Loss: 1.6672, Min Smooth Loss: 1.6401 (iter 57383), Time: 673.79s\n",
            "Iter: 59300/100000, Smooth Loss: 1.6604, Min Smooth Loss: 1.6401 (iter 57383), Time: 674.24s\n",
            "Iter: 59400/100000, Smooth Loss: 1.6605, Min Smooth Loss: 1.6401 (iter 57383), Time: 674.67s\n",
            "Iter: 59500/100000, Smooth Loss: 1.6707, Min Smooth Loss: 1.6401 (iter 57383), Time: 675.12s\n",
            "Iter: 59600/100000, Smooth Loss: 1.6744, Min Smooth Loss: 1.6401 (iter 57383), Time: 675.58s\n",
            "Iter: 59700/100000, Smooth Loss: 1.6693, Min Smooth Loss: 1.6401 (iter 57383), Time: 675.98s\n",
            "Iter: 59800/100000, Smooth Loss: 1.6605, Min Smooth Loss: 1.6401 (iter 57383), Time: 676.40s\n",
            "Iter: 59900/100000, Smooth Loss: 1.6538, Min Smooth Loss: 1.6401 (iter 57383), Time: 676.78s\n",
            "Iter: 60000/100000, Smooth Loss: 1.6464, Min Smooth Loss: 1.6401 (iter 57383), Time: 677.16s\n",
            "  Validation Loss at iter 60000: 1.7146\n",
            "--- Synthesized text at iter 60000 (using current model) ---\n",
            "ander cheme Mo. I's knew plould.  Hoggarts, even them armima knom the and abluteh kn hime thagon cillons? . . I castly.... she awoudent langer home looked net aboual oun the Quebung anting if freeted \n",
            "---\n",
            "Iter: 60100/100000, Smooth Loss: 1.6462, Min Smooth Loss: 1.6401 (iter 57383), Time: 685.01s\n",
            "Iter: 60200/100000, Smooth Loss: 1.6520, Min Smooth Loss: 1.6401 (iter 57383), Time: 685.45s\n",
            "Iter: 60300/100000, Smooth Loss: 1.6512, Min Smooth Loss: 1.6401 (iter 57383), Time: 685.88s\n",
            "Iter: 60400/100000, Smooth Loss: 1.6489, Min Smooth Loss: 1.6401 (iter 57383), Time: 686.27s\n",
            "Iter: 60500/100000, Smooth Loss: 1.6551, Min Smooth Loss: 1.6401 (iter 57383), Time: 686.69s\n",
            "Iter: 60600/100000, Smooth Loss: 1.6524, Min Smooth Loss: 1.6401 (iter 57383), Time: 687.09s\n",
            "Iter: 60700/100000, Smooth Loss: 1.6539, Min Smooth Loss: 1.6401 (iter 57383), Time: 687.48s\n",
            "Iter: 60800/100000, Smooth Loss: 1.6481, Min Smooth Loss: 1.6401 (iter 57383), Time: 687.89s\n",
            "Iter: 60900/100000, Smooth Loss: 1.6458, Min Smooth Loss: 1.6401 (iter 57383), Time: 688.31s\n",
            "Iter: 61000/100000, Smooth Loss: 1.6436, Min Smooth Loss: 1.6401 (iter 57383), Time: 688.71s\n",
            "  Validation Loss at iter 61000: 1.7020\n",
            "Iter: 61100/100000, Smooth Loss: 1.6439, Min Smooth Loss: 1.6401 (iter 57383), Time: 696.41s\n",
            "Iter: 61200/100000, Smooth Loss: 1.6409, Min Smooth Loss: 1.6399 (iter 61191), Time: 696.80s\n",
            "Iter: 61300/100000, Smooth Loss: 1.6443, Min Smooth Loss: 1.6399 (iter 61191), Time: 697.20s\n",
            "Iter: 61400/100000, Smooth Loss: 1.6403, Min Smooth Loss: 1.6394 (iter 61396), Time: 697.62s\n",
            "Iter: 61500/100000, Smooth Loss: 1.6350, Min Smooth Loss: 1.6342 (iter 61494), Time: 698.03s\n",
            "Iter: 61600/100000, Smooth Loss: 1.6318, Min Smooth Loss: 1.6318 (iter 61600), Time: 698.43s\n",
            "Iter: 61700/100000, Smooth Loss: 1.6249, Min Smooth Loss: 1.6249 (iter 61700), Time: 698.85s\n",
            "Iter: 61800/100000, Smooth Loss: 1.6254, Min Smooth Loss: 1.6244 (iter 61704), Time: 699.26s\n",
            "Iter: 61900/100000, Smooth Loss: 1.6285, Min Smooth Loss: 1.6244 (iter 61704), Time: 699.68s\n",
            "Iter: 62000/100000, Smooth Loss: 1.6364, Min Smooth Loss: 1.6244 (iter 61704), Time: 700.07s\n",
            "  Validation Loss at iter 62000: 1.7066\n",
            "Iter: 62100/100000, Smooth Loss: 1.6513, Min Smooth Loss: 1.6244 (iter 61704), Time: 707.32s\n",
            "Iter: 62200/100000, Smooth Loss: 1.6566, Min Smooth Loss: 1.6244 (iter 61704), Time: 708.02s\n",
            "Iter: 62300/100000, Smooth Loss: 1.6648, Min Smooth Loss: 1.6244 (iter 61704), Time: 708.72s\n",
            "Iter: 62400/100000, Smooth Loss: 1.6636, Min Smooth Loss: 1.6244 (iter 61704), Time: 709.31s\n",
            "Iter: 62500/100000, Smooth Loss: 1.6641, Min Smooth Loss: 1.6244 (iter 61704), Time: 709.71s\n",
            "Iter: 62600/100000, Smooth Loss: 1.6602, Min Smooth Loss: 1.6244 (iter 61704), Time: 710.11s\n",
            "Iter: 62700/100000, Smooth Loss: 1.6543, Min Smooth Loss: 1.6244 (iter 61704), Time: 710.55s\n",
            "Iter: 62800/100000, Smooth Loss: 1.6504, Min Smooth Loss: 1.6244 (iter 61704), Time: 710.99s\n",
            "Iter: 62900/100000, Smooth Loss: 1.6409, Min Smooth Loss: 1.6244 (iter 61704), Time: 711.43s\n",
            "Iter: 63000/100000, Smooth Loss: 1.6351, Min Smooth Loss: 1.6244 (iter 61704), Time: 711.84s\n",
            "  Validation Loss at iter 63000: 1.7225\n",
            "Iter: 63100/100000, Smooth Loss: 1.6481, Min Smooth Loss: 1.6244 (iter 61704), Time: 718.87s\n",
            "Iter: 63200/100000, Smooth Loss: 1.6423, Min Smooth Loss: 1.6244 (iter 61704), Time: 719.36s\n",
            "Iter: 63300/100000, Smooth Loss: 1.6418, Min Smooth Loss: 1.6244 (iter 61704), Time: 719.97s\n",
            "Iter: 63400/100000, Smooth Loss: 1.6501, Min Smooth Loss: 1.6244 (iter 61704), Time: 720.59s\n",
            "Iter: 63500/100000, Smooth Loss: 1.6592, Min Smooth Loss: 1.6244 (iter 61704), Time: 721.20s\n",
            "Iter: 63600/100000, Smooth Loss: 1.6587, Min Smooth Loss: 1.6244 (iter 61704), Time: 721.84s\n",
            "Iter: 63700/100000, Smooth Loss: 1.6694, Min Smooth Loss: 1.6244 (iter 61704), Time: 722.39s\n",
            "Iter: 63800/100000, Smooth Loss: 1.6644, Min Smooth Loss: 1.6244 (iter 61704), Time: 722.78s\n",
            "Iter: 63900/100000, Smooth Loss: 1.6563, Min Smooth Loss: 1.6244 (iter 61704), Time: 723.18s\n",
            "Iter: 64000/100000, Smooth Loss: 1.6424, Min Smooth Loss: 1.6244 (iter 61704), Time: 723.58s\n",
            "  Validation Loss at iter 64000: 1.7201\n",
            "Iter: 64100/100000, Smooth Loss: 1.6514, Min Smooth Loss: 1.6244 (iter 61704), Time: 730.16s\n",
            "Iter: 64200/100000, Smooth Loss: 1.6628, Min Smooth Loss: 1.6244 (iter 61704), Time: 730.58s\n",
            "Iter: 64300/100000, Smooth Loss: 1.6690, Min Smooth Loss: 1.6244 (iter 61704), Time: 731.01s\n",
            "Iter: 64400/100000, Smooth Loss: 1.6715, Min Smooth Loss: 1.6244 (iter 61704), Time: 731.45s\n",
            "Iter: 64500/100000, Smooth Loss: 1.6794, Min Smooth Loss: 1.6244 (iter 61704), Time: 731.90s\n",
            "Iter: 64600/100000, Smooth Loss: 1.6815, Min Smooth Loss: 1.6244 (iter 61704), Time: 732.40s\n",
            "Iter: 64700/100000, Smooth Loss: 1.6771, Min Smooth Loss: 1.6244 (iter 61704), Time: 733.10s\n",
            "Iter: 64800/100000, Smooth Loss: 1.6701, Min Smooth Loss: 1.6244 (iter 61704), Time: 733.77s\n",
            "Iter: 64900/100000, Smooth Loss: 1.6726, Min Smooth Loss: 1.6244 (iter 61704), Time: 734.38s\n",
            "Iter: 65000/100000, Smooth Loss: 1.6793, Min Smooth Loss: 1.6244 (iter 61704), Time: 735.04s\n",
            "  Validation Loss at iter 65000: 1.7070\n",
            "Iter: 65100/100000, Smooth Loss: 1.6896, Min Smooth Loss: 1.6244 (iter 61704), Time: 741.73s\n",
            "Iter: 65200/100000, Smooth Loss: 1.6858, Min Smooth Loss: 1.6244 (iter 61704), Time: 742.15s\n",
            "Iter: 65300/100000, Smooth Loss: 1.6777, Min Smooth Loss: 1.6244 (iter 61704), Time: 742.55s\n",
            "Iter: 65400/100000, Smooth Loss: 1.6669, Min Smooth Loss: 1.6244 (iter 61704), Time: 742.99s\n",
            "Iter: 65500/100000, Smooth Loss: 1.6732, Min Smooth Loss: 1.6244 (iter 61704), Time: 743.39s\n",
            "Iter: 65600/100000, Smooth Loss: 1.6799, Min Smooth Loss: 1.6244 (iter 61704), Time: 743.78s\n",
            "Iter: 65700/100000, Smooth Loss: 1.6869, Min Smooth Loss: 1.6244 (iter 61704), Time: 744.20s\n",
            "Iter: 65800/100000, Smooth Loss: 1.6752, Min Smooth Loss: 1.6244 (iter 61704), Time: 744.59s\n",
            "Iter: 65900/100000, Smooth Loss: 1.6728, Min Smooth Loss: 1.6244 (iter 61704), Time: 745.00s\n",
            "Iter: 66000/100000, Smooth Loss: 1.6712, Min Smooth Loss: 1.6244 (iter 61704), Time: 745.40s\n",
            "  Validation Loss at iter 66000: 1.7039\n",
            "Iter: 66100/100000, Smooth Loss: 1.6668, Min Smooth Loss: 1.6244 (iter 61704), Time: 753.32s\n",
            "Iter: 66200/100000, Smooth Loss: 1.6673, Min Smooth Loss: 1.6244 (iter 61704), Time: 753.77s\n",
            "Iter: 66300/100000, Smooth Loss: 1.6912, Min Smooth Loss: 1.6244 (iter 61704), Time: 754.22s\n",
            "Iter: 66400/100000, Smooth Loss: 1.6974, Min Smooth Loss: 1.6244 (iter 61704), Time: 754.64s\n",
            "Iter: 66500/100000, Smooth Loss: 1.6826, Min Smooth Loss: 1.6244 (iter 61704), Time: 755.10s\n",
            "Iter: 66600/100000, Smooth Loss: 1.6740, Min Smooth Loss: 1.6244 (iter 61704), Time: 755.61s\n",
            "Iter: 66700/100000, Smooth Loss: 1.6632, Min Smooth Loss: 1.6244 (iter 61704), Time: 756.06s\n",
            "Iter: 66800/100000, Smooth Loss: 1.6648, Min Smooth Loss: 1.6244 (iter 61704), Time: 756.46s\n",
            "Iter: 66900/100000, Smooth Loss: 1.6518, Min Smooth Loss: 1.6244 (iter 61704), Time: 756.89s\n",
            "Iter: 67000/100000, Smooth Loss: 1.6623, Min Smooth Loss: 1.6244 (iter 61704), Time: 757.29s\n",
            "  Validation Loss at iter 67000: 1.7042\n",
            "Iter: 67100/100000, Smooth Loss: 1.6548, Min Smooth Loss: 1.6244 (iter 61704), Time: 765.08s\n",
            "Iter: 67200/100000, Smooth Loss: 1.6470, Min Smooth Loss: 1.6244 (iter 61704), Time: 765.54s\n",
            "Iter: 67300/100000, Smooth Loss: 1.6563, Min Smooth Loss: 1.6244 (iter 61704), Time: 765.97s\n",
            "Iter: 67400/100000, Smooth Loss: 1.6656, Min Smooth Loss: 1.6244 (iter 61704), Time: 766.40s\n",
            "Iter: 67500/100000, Smooth Loss: 1.6740, Min Smooth Loss: 1.6244 (iter 61704), Time: 766.82s\n",
            "Iter: 67600/100000, Smooth Loss: 1.6834, Min Smooth Loss: 1.6244 (iter 61704), Time: 767.27s\n",
            "Iter: 67700/100000, Smooth Loss: 1.6846, Min Smooth Loss: 1.6244 (iter 61704), Time: 767.69s\n",
            "Iter: 67800/100000, Smooth Loss: 1.6866, Min Smooth Loss: 1.6244 (iter 61704), Time: 768.17s\n",
            "Iter: 67900/100000, Smooth Loss: 1.6868, Min Smooth Loss: 1.6244 (iter 61704), Time: 768.62s\n",
            "Iter: 68000/100000, Smooth Loss: 1.6850, Min Smooth Loss: 1.6244 (iter 61704), Time: 769.05s\n",
            "  Validation Loss at iter 68000: 1.7243\n",
            "Iter: 68100/100000, Smooth Loss: 1.6904, Min Smooth Loss: 1.6244 (iter 61704), Time: 776.75s\n",
            "Iter: 68200/100000, Smooth Loss: 1.6843, Min Smooth Loss: 1.6244 (iter 61704), Time: 777.17s\n",
            "Iter: 68300/100000, Smooth Loss: 1.6836, Min Smooth Loss: 1.6244 (iter 61704), Time: 777.55s\n",
            "Iter: 68400/100000, Smooth Loss: 1.6760, Min Smooth Loss: 1.6244 (iter 61704), Time: 777.99s\n",
            "Iter: 68500/100000, Smooth Loss: 1.6662, Min Smooth Loss: 1.6244 (iter 61704), Time: 778.39s\n",
            "Iter: 68600/100000, Smooth Loss: 1.6551, Min Smooth Loss: 1.6244 (iter 61704), Time: 778.81s\n",
            "Iter: 68700/100000, Smooth Loss: 1.6443, Min Smooth Loss: 1.6244 (iter 61704), Time: 779.21s\n",
            "Iter: 68800/100000, Smooth Loss: 1.6448, Min Smooth Loss: 1.6244 (iter 61704), Time: 779.59s\n",
            "Iter: 68900/100000, Smooth Loss: 1.6455, Min Smooth Loss: 1.6244 (iter 61704), Time: 780.01s\n",
            "Iter: 69000/100000, Smooth Loss: 1.6493, Min Smooth Loss: 1.6244 (iter 61704), Time: 780.40s\n",
            "  Validation Loss at iter 69000: 1.6993\n",
            "Iter: 69100/100000, Smooth Loss: 1.6568, Min Smooth Loss: 1.6244 (iter 61704), Time: 788.22s\n",
            "Iter: 69200/100000, Smooth Loss: 1.6671, Min Smooth Loss: 1.6244 (iter 61704), Time: 788.63s\n",
            "Iter: 69300/100000, Smooth Loss: 1.6651, Min Smooth Loss: 1.6244 (iter 61704), Time: 789.03s\n",
            "Iter: 69400/100000, Smooth Loss: 1.6710, Min Smooth Loss: 1.6244 (iter 61704), Time: 789.45s\n",
            "Iter: 69500/100000, Smooth Loss: 1.6633, Min Smooth Loss: 1.6244 (iter 61704), Time: 789.87s\n",
            "Iter: 69600/100000, Smooth Loss: 1.6574, Min Smooth Loss: 1.6244 (iter 61704), Time: 790.26s\n",
            "Iter: 69700/100000, Smooth Loss: 1.6536, Min Smooth Loss: 1.6244 (iter 61704), Time: 790.67s\n",
            "Iter: 69800/100000, Smooth Loss: 1.6566, Min Smooth Loss: 1.6244 (iter 61704), Time: 791.06s\n",
            "Iter: 69900/100000, Smooth Loss: 1.6597, Min Smooth Loss: 1.6244 (iter 61704), Time: 791.48s\n",
            "Iter: 70000/100000, Smooth Loss: 1.6589, Min Smooth Loss: 1.6244 (iter 61704), Time: 791.87s\n",
            "  Validation Loss at iter 70000: 1.7193\n",
            "--- Synthesized text at iter 70000 (using current model) ---\n",
            "d book to ghe long exark, subliaked trinncameted it, atutuoubly one shoke., sleary fleated an promeing.\n",
            "Harry in the jeen ining the eth ofisely at thet they was as turritumued, and halt this at bur br\n",
            "---\n",
            "Iter: 70100/100000, Smooth Loss: 1.6475, Min Smooth Loss: 1.6244 (iter 61704), Time: 798.86s\n",
            "Iter: 70200/100000, Smooth Loss: 1.6379, Min Smooth Loss: 1.6244 (iter 61704), Time: 799.47s\n",
            "Iter: 70300/100000, Smooth Loss: 1.6367, Min Smooth Loss: 1.6244 (iter 61704), Time: 800.05s\n",
            "Iter: 70400/100000, Smooth Loss: 1.6332, Min Smooth Loss: 1.6244 (iter 61704), Time: 800.68s\n",
            "Iter: 70500/100000, Smooth Loss: 1.6386, Min Smooth Loss: 1.6244 (iter 61704), Time: 801.24s\n",
            "Iter: 70600/100000, Smooth Loss: 1.6387, Min Smooth Loss: 1.6244 (iter 61704), Time: 801.64s\n",
            "Iter: 70700/100000, Smooth Loss: 1.6500, Min Smooth Loss: 1.6244 (iter 61704), Time: 802.06s\n",
            "Iter: 70800/100000, Smooth Loss: 1.6610, Min Smooth Loss: 1.6244 (iter 61704), Time: 802.46s\n",
            "Iter: 70900/100000, Smooth Loss: 1.6604, Min Smooth Loss: 1.6244 (iter 61704), Time: 802.88s\n",
            "Iter: 71000/100000, Smooth Loss: 1.6600, Min Smooth Loss: 1.6244 (iter 61704), Time: 803.33s\n",
            "  Validation Loss at iter 71000: 1.7029\n",
            "Iter: 71100/100000, Smooth Loss: 1.6519, Min Smooth Loss: 1.6244 (iter 61704), Time: 810.01s\n",
            "Iter: 71200/100000, Smooth Loss: 1.6487, Min Smooth Loss: 1.6244 (iter 61704), Time: 810.45s\n",
            "Iter: 71300/100000, Smooth Loss: 1.6480, Min Smooth Loss: 1.6244 (iter 61704), Time: 810.84s\n",
            "Iter: 71400/100000, Smooth Loss: 1.6574, Min Smooth Loss: 1.6244 (iter 61704), Time: 811.34s\n",
            "Iter: 71500/100000, Smooth Loss: 1.6457, Min Smooth Loss: 1.6244 (iter 61704), Time: 811.98s\n",
            "Iter: 71600/100000, Smooth Loss: 1.6347, Min Smooth Loss: 1.6244 (iter 61704), Time: 812.59s\n",
            "Iter: 71700/100000, Smooth Loss: 1.6353, Min Smooth Loss: 1.6244 (iter 61704), Time: 813.21s\n",
            "Iter: 71800/100000, Smooth Loss: 1.6319, Min Smooth Loss: 1.6244 (iter 61704), Time: 813.87s\n",
            "Iter: 71900/100000, Smooth Loss: 1.6312, Min Smooth Loss: 1.6244 (iter 61704), Time: 814.41s\n",
            "Iter: 72000/100000, Smooth Loss: 1.6250, Min Smooth Loss: 1.6244 (iter 61704), Time: 814.82s\n",
            "  Validation Loss at iter 72000: 1.6763\n",
            "Iter: 72100/100000, Smooth Loss: 1.6225, Min Smooth Loss: 1.6210 (iter 72084), Time: 821.42s\n",
            "Iter: 72200/100000, Smooth Loss: 1.6214, Min Smooth Loss: 1.6182 (iter 72151), Time: 821.82s\n",
            "Iter: 72300/100000, Smooth Loss: 1.6184, Min Smooth Loss: 1.6168 (iter 72259), Time: 822.24s\n",
            "Iter: 72400/100000, Smooth Loss: 1.6143, Min Smooth Loss: 1.6143 (iter 72400), Time: 822.64s\n",
            "Iter: 72500/100000, Smooth Loss: 1.6183, Min Smooth Loss: 1.6135 (iter 72412), Time: 823.05s\n",
            "Iter: 72600/100000, Smooth Loss: 1.6289, Min Smooth Loss: 1.6135 (iter 72412), Time: 823.55s\n",
            "Iter: 72700/100000, Smooth Loss: 1.6337, Min Smooth Loss: 1.6135 (iter 72412), Time: 824.01s\n",
            "Iter: 72800/100000, Smooth Loss: 1.6362, Min Smooth Loss: 1.6135 (iter 72412), Time: 824.58s\n",
            "Iter: 72900/100000, Smooth Loss: 1.6360, Min Smooth Loss: 1.6135 (iter 72412), Time: 825.22s\n",
            "Iter: 73000/100000, Smooth Loss: 1.6433, Min Smooth Loss: 1.6135 (iter 72412), Time: 825.83s\n",
            "  Validation Loss at iter 73000: 1.6852\n",
            "Iter: 73100/100000, Smooth Loss: 1.6436, Min Smooth Loss: 1.6135 (iter 72412), Time: 832.92s\n",
            "Iter: 73200/100000, Smooth Loss: 1.6408, Min Smooth Loss: 1.6135 (iter 72412), Time: 833.32s\n",
            "Iter: 73300/100000, Smooth Loss: 1.6390, Min Smooth Loss: 1.6135 (iter 72412), Time: 833.73s\n",
            "Iter: 73400/100000, Smooth Loss: 1.6237, Min Smooth Loss: 1.6135 (iter 72412), Time: 834.12s\n",
            "Iter: 73500/100000, Smooth Loss: 1.6203, Min Smooth Loss: 1.6135 (iter 72412), Time: 834.52s\n",
            "Iter: 73600/100000, Smooth Loss: 1.6050, Min Smooth Loss: 1.6050 (iter 73600), Time: 834.92s\n",
            "Iter: 73700/100000, Smooth Loss: 1.5932, Min Smooth Loss: 1.5929 (iter 73689), Time: 835.32s\n",
            "Iter: 73800/100000, Smooth Loss: 1.5897, Min Smooth Loss: 1.5859 (iter 73743), Time: 835.76s\n",
            "Iter: 73900/100000, Smooth Loss: 1.5928, Min Smooth Loss: 1.5859 (iter 73743), Time: 836.18s\n",
            "Iter: 74000/100000, Smooth Loss: 1.5824, Min Smooth Loss: 1.5809 (iter 73976), Time: 836.58s\n",
            "  Validation Loss at iter 74000: 1.6646\n",
            "Iter: 74100/100000, Smooth Loss: 1.5775, Min Smooth Loss: 1.5775 (iter 74099), Time: 844.36s\n",
            "Iter: 74200/100000, Smooth Loss: 1.5694, Min Smooth Loss: 1.5677 (iter 74170), Time: 844.75s\n",
            "Iter: 74300/100000, Smooth Loss: 1.5649, Min Smooth Loss: 1.5649 (iter 74300), Time: 845.15s\n",
            "Iter: 74400/100000, Smooth Loss: 1.5705, Min Smooth Loss: 1.5644 (iter 74304), Time: 845.57s\n",
            "Iter: 74500/100000, Smooth Loss: 1.5686, Min Smooth Loss: 1.5644 (iter 74304), Time: 845.96s\n",
            "Iter: 74600/100000, Smooth Loss: 1.5816, Min Smooth Loss: 1.5644 (iter 74304), Time: 846.37s\n",
            "Iter: 74700/100000, Smooth Loss: 1.5860, Min Smooth Loss: 1.5644 (iter 74304), Time: 846.76s\n",
            "Iter: 74800/100000, Smooth Loss: 1.5945, Min Smooth Loss: 1.5644 (iter 74304), Time: 847.14s\n",
            "Iter: 74900/100000, Smooth Loss: 1.6028, Min Smooth Loss: 1.5644 (iter 74304), Time: 847.53s\n",
            "Iter: 75000/100000, Smooth Loss: 1.5992, Min Smooth Loss: 1.5644 (iter 74304), Time: 847.93s\n",
            "  Validation Loss at iter 75000: 1.6591\n",
            "Iter: 75100/100000, Smooth Loss: 1.6002, Min Smooth Loss: 1.5644 (iter 74304), Time: 855.66s\n",
            "Iter: 75200/100000, Smooth Loss: 1.5890, Min Smooth Loss: 1.5644 (iter 74304), Time: 856.10s\n",
            "Iter: 75300/100000, Smooth Loss: 1.5798, Min Smooth Loss: 1.5644 (iter 74304), Time: 856.50s\n",
            "Iter: 75400/100000, Smooth Loss: 1.5849, Min Smooth Loss: 1.5644 (iter 74304), Time: 856.92s\n",
            "Iter: 75500/100000, Smooth Loss: 1.5887, Min Smooth Loss: 1.5644 (iter 74304), Time: 857.32s\n",
            "Iter: 75600/100000, Smooth Loss: 1.5901, Min Smooth Loss: 1.5644 (iter 74304), Time: 857.71s\n",
            "Iter: 75700/100000, Smooth Loss: 1.5882, Min Smooth Loss: 1.5644 (iter 74304), Time: 858.14s\n",
            "Iter: 75800/100000, Smooth Loss: 1.5969, Min Smooth Loss: 1.5644 (iter 74304), Time: 858.55s\n",
            "Iter: 75900/100000, Smooth Loss: 1.5914, Min Smooth Loss: 1.5644 (iter 74304), Time: 858.96s\n",
            "Iter: 76000/100000, Smooth Loss: 1.5932, Min Smooth Loss: 1.5644 (iter 74304), Time: 859.39s\n",
            "  Validation Loss at iter 76000: 1.6627\n",
            "Iter: 76100/100000, Smooth Loss: 1.5943, Min Smooth Loss: 1.5644 (iter 74304), Time: 867.06s\n",
            "Iter: 76200/100000, Smooth Loss: 1.5846, Min Smooth Loss: 1.5644 (iter 74304), Time: 867.45s\n",
            "Iter: 76300/100000, Smooth Loss: 1.5841, Min Smooth Loss: 1.5644 (iter 74304), Time: 867.86s\n",
            "Iter: 76400/100000, Smooth Loss: 1.5685, Min Smooth Loss: 1.5644 (iter 74304), Time: 868.28s\n",
            "Iter: 76500/100000, Smooth Loss: 1.5701, Min Smooth Loss: 1.5643 (iter 76452), Time: 868.71s\n",
            "Iter: 76600/100000, Smooth Loss: 1.5782, Min Smooth Loss: 1.5643 (iter 76452), Time: 869.10s\n",
            "Iter: 76700/100000, Smooth Loss: 1.5830, Min Smooth Loss: 1.5643 (iter 76452), Time: 869.51s\n",
            "Iter: 76800/100000, Smooth Loss: 1.5999, Min Smooth Loss: 1.5643 (iter 76452), Time: 869.95s\n",
            "Iter: 76900/100000, Smooth Loss: 1.6088, Min Smooth Loss: 1.5643 (iter 76452), Time: 870.35s\n",
            "Iter: 77000/100000, Smooth Loss: 1.6128, Min Smooth Loss: 1.5643 (iter 76452), Time: 870.76s\n",
            "  Validation Loss at iter 77000: 1.6453\n",
            "Iter: 77100/100000, Smooth Loss: 1.6087, Min Smooth Loss: 1.5643 (iter 76452), Time: 877.62s\n",
            "Iter: 77200/100000, Smooth Loss: 1.6038, Min Smooth Loss: 1.5643 (iter 76452), Time: 878.27s\n",
            "Iter: 77300/100000, Smooth Loss: 1.5966, Min Smooth Loss: 1.5643 (iter 76452), Time: 878.87s\n",
            "Iter: 77400/100000, Smooth Loss: 1.5960, Min Smooth Loss: 1.5643 (iter 76452), Time: 879.51s\n",
            "Iter: 77500/100000, Smooth Loss: 1.6021, Min Smooth Loss: 1.5643 (iter 76452), Time: 880.09s\n",
            "Iter: 77600/100000, Smooth Loss: 1.6024, Min Smooth Loss: 1.5643 (iter 76452), Time: 880.52s\n",
            "Iter: 77700/100000, Smooth Loss: 1.6069, Min Smooth Loss: 1.5643 (iter 76452), Time: 880.92s\n",
            "Iter: 77800/100000, Smooth Loss: 1.5989, Min Smooth Loss: 1.5643 (iter 76452), Time: 881.31s\n",
            "Iter: 77900/100000, Smooth Loss: 1.6166, Min Smooth Loss: 1.5643 (iter 76452), Time: 881.70s\n",
            "Iter: 78000/100000, Smooth Loss: 1.6213, Min Smooth Loss: 1.5643 (iter 76452), Time: 882.10s\n",
            "  Validation Loss at iter 78000: 1.6704\n",
            "Iter: 78100/100000, Smooth Loss: 1.6127, Min Smooth Loss: 1.5643 (iter 76452), Time: 888.69s\n",
            "Iter: 78200/100000, Smooth Loss: 1.6034, Min Smooth Loss: 1.5643 (iter 76452), Time: 889.11s\n",
            "Iter: 78300/100000, Smooth Loss: 1.5995, Min Smooth Loss: 1.5643 (iter 76452), Time: 889.50s\n",
            "Iter: 78400/100000, Smooth Loss: 1.5919, Min Smooth Loss: 1.5643 (iter 76452), Time: 889.91s\n",
            "Iter: 78500/100000, Smooth Loss: 1.5894, Min Smooth Loss: 1.5643 (iter 76452), Time: 890.53s\n",
            "Iter: 78600/100000, Smooth Loss: 1.5865, Min Smooth Loss: 1.5643 (iter 76452), Time: 891.16s\n",
            "Iter: 78700/100000, Smooth Loss: 1.5891, Min Smooth Loss: 1.5643 (iter 76452), Time: 891.75s\n",
            "Iter: 78800/100000, Smooth Loss: 1.5936, Min Smooth Loss: 1.5643 (iter 76452), Time: 892.37s\n",
            "Iter: 78900/100000, Smooth Loss: 1.6037, Min Smooth Loss: 1.5643 (iter 76452), Time: 893.05s\n",
            "Iter: 79000/100000, Smooth Loss: 1.6095, Min Smooth Loss: 1.5643 (iter 76452), Time: 893.45s\n",
            "  Validation Loss at iter 79000: 1.6643\n",
            "Iter: 79100/100000, Smooth Loss: 1.6133, Min Smooth Loss: 1.5643 (iter 76452), Time: 900.05s\n",
            "Iter: 79200/100000, Smooth Loss: 1.6105, Min Smooth Loss: 1.5643 (iter 76452), Time: 900.47s\n",
            "Iter: 79300/100000, Smooth Loss: 1.6197, Min Smooth Loss: 1.5643 (iter 76452), Time: 900.87s\n",
            "Iter: 79400/100000, Smooth Loss: 1.6200, Min Smooth Loss: 1.5643 (iter 76452), Time: 901.30s\n",
            "Iter: 79500/100000, Smooth Loss: 1.6230, Min Smooth Loss: 1.5643 (iter 76452), Time: 901.70s\n",
            "Iter: 79600/100000, Smooth Loss: 1.6153, Min Smooth Loss: 1.5643 (iter 76452), Time: 902.12s\n",
            "Iter: 79700/100000, Smooth Loss: 1.6050, Min Smooth Loss: 1.5643 (iter 76452), Time: 902.54s\n",
            "Iter: 79800/100000, Smooth Loss: 1.6171, Min Smooth Loss: 1.5643 (iter 76452), Time: 902.93s\n",
            "Iter: 79900/100000, Smooth Loss: 1.6349, Min Smooth Loss: 1.5643 (iter 76452), Time: 903.49s\n",
            "Iter: 80000/100000, Smooth Loss: 1.6411, Min Smooth Loss: 1.5643 (iter 76452), Time: 904.15s\n",
            "  Validation Loss at iter 80000: 1.6886\n",
            "--- Synthesized text at iter 80000 (using current model) ---\n",
            "is cercret mals whilupt from the died weren though that to pilptt of furey walted yut the chowd besidn't rear, that abbenth wiarty of up to Hogwid chat was flocked down his anrig arout?\" foleepory tur\n",
            "---\n",
            "Iter: 80100/100000, Smooth Loss: 1.6369, Min Smooth Loss: 1.5643 (iter 76452), Time: 911.54s\n",
            "Iter: 80200/100000, Smooth Loss: 1.6371, Min Smooth Loss: 1.5643 (iter 76452), Time: 911.96s\n",
            "Iter: 80300/100000, Smooth Loss: 1.6396, Min Smooth Loss: 1.5643 (iter 76452), Time: 912.39s\n",
            "Iter: 80400/100000, Smooth Loss: 1.6369, Min Smooth Loss: 1.5643 (iter 76452), Time: 912.80s\n",
            "Iter: 80500/100000, Smooth Loss: 1.6345, Min Smooth Loss: 1.5643 (iter 76452), Time: 913.24s\n",
            "Iter: 80600/100000, Smooth Loss: 1.6330, Min Smooth Loss: 1.5643 (iter 76452), Time: 913.66s\n",
            "Iter: 80700/100000, Smooth Loss: 1.6264, Min Smooth Loss: 1.5643 (iter 76452), Time: 914.09s\n",
            "Iter: 80800/100000, Smooth Loss: 1.6236, Min Smooth Loss: 1.5643 (iter 76452), Time: 914.51s\n",
            "Iter: 80900/100000, Smooth Loss: 1.6293, Min Smooth Loss: 1.5643 (iter 76452), Time: 914.97s\n",
            "Iter: 81000/100000, Smooth Loss: 1.6139, Min Smooth Loss: 1.5643 (iter 76452), Time: 915.41s\n",
            "  Validation Loss at iter 81000: 1.7008\n",
            "Iter: 81100/100000, Smooth Loss: 1.6192, Min Smooth Loss: 1.5643 (iter 76452), Time: 923.30s\n",
            "Iter: 81200/100000, Smooth Loss: 1.6136, Min Smooth Loss: 1.5643 (iter 76452), Time: 923.75s\n",
            "Iter: 81300/100000, Smooth Loss: 1.6272, Min Smooth Loss: 1.5643 (iter 76452), Time: 924.20s\n",
            "Iter: 81400/100000, Smooth Loss: 1.6406, Min Smooth Loss: 1.5643 (iter 76452), Time: 924.63s\n",
            "Iter: 81500/100000, Smooth Loss: 1.6508, Min Smooth Loss: 1.5643 (iter 76452), Time: 925.02s\n",
            "Iter: 81600/100000, Smooth Loss: 1.6471, Min Smooth Loss: 1.5643 (iter 76452), Time: 925.44s\n",
            "Iter: 81700/100000, Smooth Loss: 1.6396, Min Smooth Loss: 1.5643 (iter 76452), Time: 925.88s\n",
            "Iter: 81800/100000, Smooth Loss: 1.6391, Min Smooth Loss: 1.5643 (iter 76452), Time: 926.29s\n",
            "Iter: 81900/100000, Smooth Loss: 1.6277, Min Smooth Loss: 1.5643 (iter 76452), Time: 926.72s\n",
            "Iter: 82000/100000, Smooth Loss: 1.6406, Min Smooth Loss: 1.5643 (iter 76452), Time: 927.12s\n",
            "  Validation Loss at iter 82000: 1.7036\n",
            "Iter: 82100/100000, Smooth Loss: 1.6434, Min Smooth Loss: 1.5643 (iter 76452), Time: 934.90s\n",
            "Iter: 82200/100000, Smooth Loss: 1.6416, Min Smooth Loss: 1.5643 (iter 76452), Time: 935.33s\n",
            "Iter: 82300/100000, Smooth Loss: 1.6437, Min Smooth Loss: 1.5643 (iter 76452), Time: 935.75s\n",
            "Iter: 82400/100000, Smooth Loss: 1.6397, Min Smooth Loss: 1.5643 (iter 76452), Time: 936.17s\n",
            "Iter: 82500/100000, Smooth Loss: 1.6310, Min Smooth Loss: 1.5643 (iter 76452), Time: 936.55s\n",
            "Iter: 82600/100000, Smooth Loss: 1.6209, Min Smooth Loss: 1.5643 (iter 76452), Time: 936.94s\n",
            "Iter: 82700/100000, Smooth Loss: 1.6142, Min Smooth Loss: 1.5643 (iter 76452), Time: 937.35s\n",
            "Iter: 82800/100000, Smooth Loss: 1.6123, Min Smooth Loss: 1.5643 (iter 76452), Time: 937.76s\n",
            "Iter: 82900/100000, Smooth Loss: 1.6135, Min Smooth Loss: 1.5643 (iter 76452), Time: 938.20s\n",
            "Iter: 83000/100000, Smooth Loss: 1.6099, Min Smooth Loss: 1.5643 (iter 76452), Time: 938.60s\n",
            "  Validation Loss at iter 83000: 1.6888\n",
            "Iter: 83100/100000, Smooth Loss: 1.6155, Min Smooth Loss: 1.5643 (iter 76452), Time: 946.67s\n",
            "Iter: 83200/100000, Smooth Loss: 1.6151, Min Smooth Loss: 1.5643 (iter 76452), Time: 947.09s\n",
            "Iter: 83300/100000, Smooth Loss: 1.6181, Min Smooth Loss: 1.5643 (iter 76452), Time: 947.49s\n",
            "Iter: 83400/100000, Smooth Loss: 1.6273, Min Smooth Loss: 1.5643 (iter 76452), Time: 947.93s\n",
            "Iter: 83500/100000, Smooth Loss: 1.6302, Min Smooth Loss: 1.5643 (iter 76452), Time: 948.36s\n",
            "Iter: 83600/100000, Smooth Loss: 1.6344, Min Smooth Loss: 1.5643 (iter 76452), Time: 948.78s\n",
            "Iter: 83700/100000, Smooth Loss: 1.6341, Min Smooth Loss: 1.5643 (iter 76452), Time: 949.18s\n",
            "Iter: 83800/100000, Smooth Loss: 1.6278, Min Smooth Loss: 1.5643 (iter 76452), Time: 949.58s\n",
            "Iter: 83900/100000, Smooth Loss: 1.6332, Min Smooth Loss: 1.5643 (iter 76452), Time: 949.99s\n",
            "Iter: 84000/100000, Smooth Loss: 1.6398, Min Smooth Loss: 1.5643 (iter 76452), Time: 950.40s\n",
            "  Validation Loss at iter 84000: 1.6830\n",
            "Iter: 84100/100000, Smooth Loss: 1.6363, Min Smooth Loss: 1.5643 (iter 76452), Time: 957.86s\n",
            "Iter: 84200/100000, Smooth Loss: 1.6406, Min Smooth Loss: 1.5643 (iter 76452), Time: 958.52s\n",
            "Iter: 84300/100000, Smooth Loss: 1.6397, Min Smooth Loss: 1.5643 (iter 76452), Time: 959.10s\n",
            "Iter: 84400/100000, Smooth Loss: 1.6412, Min Smooth Loss: 1.5643 (iter 76452), Time: 959.52s\n",
            "Iter: 84500/100000, Smooth Loss: 1.6428, Min Smooth Loss: 1.5643 (iter 76452), Time: 959.95s\n",
            "Iter: 84600/100000, Smooth Loss: 1.6475, Min Smooth Loss: 1.5643 (iter 76452), Time: 960.37s\n",
            "Iter: 84700/100000, Smooth Loss: 1.6510, Min Smooth Loss: 1.5643 (iter 76452), Time: 960.79s\n",
            "Iter: 84800/100000, Smooth Loss: 1.6555, Min Smooth Loss: 1.5643 (iter 76452), Time: 961.20s\n",
            "Iter: 84900/100000, Smooth Loss: 1.6546, Min Smooth Loss: 1.5643 (iter 76452), Time: 961.60s\n",
            "Iter: 85000/100000, Smooth Loss: 1.6587, Min Smooth Loss: 1.5643 (iter 76452), Time: 962.01s\n",
            "  Validation Loss at iter 85000: 1.6662\n",
            "Iter: 85100/100000, Smooth Loss: 1.6642, Min Smooth Loss: 1.5643 (iter 76452), Time: 968.58s\n",
            "Iter: 85200/100000, Smooth Loss: 1.6643, Min Smooth Loss: 1.5643 (iter 76452), Time: 968.98s\n",
            "Iter: 85300/100000, Smooth Loss: 1.6636, Min Smooth Loss: 1.5643 (iter 76452), Time: 969.58s\n",
            "Iter: 85400/100000, Smooth Loss: 1.6724, Min Smooth Loss: 1.5643 (iter 76452), Time: 970.20s\n",
            "Iter: 85500/100000, Smooth Loss: 1.6684, Min Smooth Loss: 1.5643 (iter 76452), Time: 970.80s\n",
            "Iter: 85600/100000, Smooth Loss: 1.6770, Min Smooth Loss: 1.5643 (iter 76452), Time: 971.43s\n",
            "Iter: 85700/100000, Smooth Loss: 1.6733, Min Smooth Loss: 1.5643 (iter 76452), Time: 972.09s\n",
            "Iter: 85800/100000, Smooth Loss: 1.6742, Min Smooth Loss: 1.5643 (iter 76452), Time: 972.51s\n",
            "Iter: 85900/100000, Smooth Loss: 1.6824, Min Smooth Loss: 1.5643 (iter 76452), Time: 972.91s\n",
            "Iter: 86000/100000, Smooth Loss: 1.6803, Min Smooth Loss: 1.5643 (iter 76452), Time: 973.32s\n",
            "  Validation Loss at iter 86000: 1.6884\n",
            "Iter: 86100/100000, Smooth Loss: 1.7018, Min Smooth Loss: 1.5643 (iter 76452), Time: 980.10s\n",
            "Iter: 86200/100000, Smooth Loss: 1.7108, Min Smooth Loss: 1.5643 (iter 76452), Time: 980.50s\n",
            "Iter: 86300/100000, Smooth Loss: 1.7169, Min Smooth Loss: 1.5643 (iter 76452), Time: 980.90s\n",
            "Iter: 86400/100000, Smooth Loss: 1.7104, Min Smooth Loss: 1.5643 (iter 76452), Time: 981.29s\n",
            "Iter: 86500/100000, Smooth Loss: 1.7054, Min Smooth Loss: 1.5643 (iter 76452), Time: 981.70s\n",
            "Iter: 86600/100000, Smooth Loss: 1.7023, Min Smooth Loss: 1.5643 (iter 76452), Time: 982.09s\n",
            "Iter: 86700/100000, Smooth Loss: 1.6968, Min Smooth Loss: 1.5643 (iter 76452), Time: 982.67s\n",
            "Iter: 86800/100000, Smooth Loss: 1.6901, Min Smooth Loss: 1.5643 (iter 76452), Time: 983.28s\n",
            "Iter: 86900/100000, Smooth Loss: 1.6841, Min Smooth Loss: 1.5643 (iter 76452), Time: 983.89s\n",
            "Iter: 87000/100000, Smooth Loss: 1.6724, Min Smooth Loss: 1.5643 (iter 76452), Time: 984.51s\n",
            "  Validation Loss at iter 87000: 1.7063\n",
            "Iter: 87100/100000, Smooth Loss: 1.6615, Min Smooth Loss: 1.5643 (iter 76452), Time: 991.63s\n",
            "Iter: 87200/100000, Smooth Loss: 1.6566, Min Smooth Loss: 1.5643 (iter 76452), Time: 992.04s\n",
            "Iter: 87300/100000, Smooth Loss: 1.6483, Min Smooth Loss: 1.5643 (iter 76452), Time: 992.44s\n",
            "Iter: 87400/100000, Smooth Loss: 1.6491, Min Smooth Loss: 1.5643 (iter 76452), Time: 992.84s\n",
            "Iter: 87500/100000, Smooth Loss: 1.6413, Min Smooth Loss: 1.5643 (iter 76452), Time: 993.27s\n",
            "Iter: 87600/100000, Smooth Loss: 1.6354, Min Smooth Loss: 1.5643 (iter 76452), Time: 993.66s\n",
            "Iter: 87700/100000, Smooth Loss: 1.6244, Min Smooth Loss: 1.5643 (iter 76452), Time: 994.06s\n",
            "Iter: 87800/100000, Smooth Loss: 1.6223, Min Smooth Loss: 1.5643 (iter 76452), Time: 994.48s\n",
            "Iter: 87900/100000, Smooth Loss: 1.6123, Min Smooth Loss: 1.5643 (iter 76452), Time: 994.88s\n",
            "Iter: 88000/100000, Smooth Loss: 1.6116, Min Smooth Loss: 1.5643 (iter 76452), Time: 995.32s\n",
            "  Validation Loss at iter 88000: 1.7231\n",
            "Iter: 88100/100000, Smooth Loss: 1.6112, Min Smooth Loss: 1.5643 (iter 76452), Time: 1003.05s\n",
            "Iter: 88200/100000, Smooth Loss: 1.5947, Min Smooth Loss: 1.5643 (iter 76452), Time: 1003.48s\n",
            "Iter: 88300/100000, Smooth Loss: 1.5827, Min Smooth Loss: 1.5643 (iter 76452), Time: 1003.94s\n",
            "Iter: 88400/100000, Smooth Loss: 1.5787, Min Smooth Loss: 1.5643 (iter 76452), Time: 1004.36s\n",
            "Iter: 88500/100000, Smooth Loss: 1.5928, Min Smooth Loss: 1.5643 (iter 76452), Time: 1004.87s\n",
            "Iter: 88600/100000, Smooth Loss: 1.6062, Min Smooth Loss: 1.5643 (iter 76452), Time: 1005.30s\n",
            "Iter: 88700/100000, Smooth Loss: 1.6031, Min Smooth Loss: 1.5643 (iter 76452), Time: 1005.77s\n",
            "Iter: 88800/100000, Smooth Loss: 1.6022, Min Smooth Loss: 1.5643 (iter 76452), Time: 1006.20s\n",
            "Iter: 88900/100000, Smooth Loss: 1.6157, Min Smooth Loss: 1.5643 (iter 76452), Time: 1006.59s\n",
            "Iter: 89000/100000, Smooth Loss: 1.6213, Min Smooth Loss: 1.5643 (iter 76452), Time: 1007.00s\n",
            "  Validation Loss at iter 89000: 1.6798\n",
            "Iter: 89100/100000, Smooth Loss: 1.6295, Min Smooth Loss: 1.5643 (iter 76452), Time: 1014.93s\n",
            "Iter: 89200/100000, Smooth Loss: 1.6270, Min Smooth Loss: 1.5643 (iter 76452), Time: 1015.35s\n",
            "Iter: 89300/100000, Smooth Loss: 1.6249, Min Smooth Loss: 1.5643 (iter 76452), Time: 1015.74s\n",
            "Iter: 89400/100000, Smooth Loss: 1.6135, Min Smooth Loss: 1.5643 (iter 76452), Time: 1016.14s\n",
            "Iter: 89500/100000, Smooth Loss: 1.6279, Min Smooth Loss: 1.5643 (iter 76452), Time: 1016.56s\n",
            "Iter: 89600/100000, Smooth Loss: 1.6198, Min Smooth Loss: 1.5643 (iter 76452), Time: 1016.95s\n",
            "Iter: 89700/100000, Smooth Loss: 1.6194, Min Smooth Loss: 1.5643 (iter 76452), Time: 1017.35s\n",
            "Iter: 89800/100000, Smooth Loss: 1.6359, Min Smooth Loss: 1.5643 (iter 76452), Time: 1017.76s\n",
            "Iter: 89900/100000, Smooth Loss: 1.6338, Min Smooth Loss: 1.5643 (iter 76452), Time: 1018.18s\n",
            "Iter: 90000/100000, Smooth Loss: 1.6387, Min Smooth Loss: 1.5643 (iter 76452), Time: 1018.60s\n",
            "  Validation Loss at iter 90000: 1.6912\n",
            "--- Synthesized text at iter 90000 (using current model) ---\n",
            " frounted wheen's himsaqus's withing dears Landed to was your geare Harry.\n",
            "\"Fixilusing hunding farghing the Treans, they squigh sthan mooth fas robegizole well.  What reverabout farn with the Mad-Eye \n",
            "---\n",
            "Iter: 90100/100000, Smooth Loss: 1.6462, Min Smooth Loss: 1.5643 (iter 76452), Time: 1026.25s\n",
            "Iter: 90200/100000, Smooth Loss: 1.6463, Min Smooth Loss: 1.5643 (iter 76452), Time: 1026.65s\n",
            "Iter: 90300/100000, Smooth Loss: 1.6464, Min Smooth Loss: 1.5643 (iter 76452), Time: 1027.07s\n",
            "Iter: 90400/100000, Smooth Loss: 1.6726, Min Smooth Loss: 1.5643 (iter 76452), Time: 1027.46s\n",
            "Iter: 90500/100000, Smooth Loss: 1.6831, Min Smooth Loss: 1.5643 (iter 76452), Time: 1027.83s\n",
            "Iter: 90600/100000, Smooth Loss: 1.6872, Min Smooth Loss: 1.5643 (iter 76452), Time: 1028.25s\n",
            "Iter: 90700/100000, Smooth Loss: 1.6907, Min Smooth Loss: 1.5643 (iter 76452), Time: 1028.65s\n",
            "Iter: 90800/100000, Smooth Loss: 1.6819, Min Smooth Loss: 1.5643 (iter 76452), Time: 1029.05s\n",
            "Iter: 90900/100000, Smooth Loss: 1.6751, Min Smooth Loss: 1.5643 (iter 76452), Time: 1029.44s\n",
            "Iter: 91000/100000, Smooth Loss: 1.6743, Min Smooth Loss: 1.5643 (iter 76452), Time: 1029.85s\n",
            "  Validation Loss at iter 91000: 1.6615\n",
            "Iter: 91100/100000, Smooth Loss: 1.6650, Min Smooth Loss: 1.5643 (iter 76452), Time: 1037.49s\n",
            "Iter: 91200/100000, Smooth Loss: 1.6637, Min Smooth Loss: 1.5643 (iter 76452), Time: 1038.05s\n",
            "Iter: 91300/100000, Smooth Loss: 1.6701, Min Smooth Loss: 1.5643 (iter 76452), Time: 1038.46s\n",
            "Iter: 91400/100000, Smooth Loss: 1.6773, Min Smooth Loss: 1.5643 (iter 76452), Time: 1038.90s\n",
            "Iter: 91500/100000, Smooth Loss: 1.6867, Min Smooth Loss: 1.5643 (iter 76452), Time: 1039.30s\n",
            "Iter: 91600/100000, Smooth Loss: 1.6862, Min Smooth Loss: 1.5643 (iter 76452), Time: 1039.72s\n",
            "Iter: 91700/100000, Smooth Loss: 1.6865, Min Smooth Loss: 1.5643 (iter 76452), Time: 1040.13s\n",
            "Iter: 91800/100000, Smooth Loss: 1.6825, Min Smooth Loss: 1.5643 (iter 76452), Time: 1040.52s\n",
            "Iter: 91900/100000, Smooth Loss: 1.6836, Min Smooth Loss: 1.5643 (iter 76452), Time: 1040.93s\n",
            "Iter: 92000/100000, Smooth Loss: 1.6818, Min Smooth Loss: 1.5643 (iter 76452), Time: 1041.33s\n",
            "  Validation Loss at iter 92000: 1.6560\n",
            "Iter: 92100/100000, Smooth Loss: 1.6693, Min Smooth Loss: 1.5643 (iter 76452), Time: 1047.72s\n",
            "Iter: 92200/100000, Smooth Loss: 1.6582, Min Smooth Loss: 1.5643 (iter 76452), Time: 1048.28s\n",
            "Iter: 92300/100000, Smooth Loss: 1.6600, Min Smooth Loss: 1.5643 (iter 76452), Time: 1048.91s\n",
            "Iter: 92400/100000, Smooth Loss: 1.6581, Min Smooth Loss: 1.5643 (iter 76452), Time: 1049.53s\n",
            "Iter: 92500/100000, Smooth Loss: 1.6557, Min Smooth Loss: 1.5643 (iter 76452), Time: 1050.16s\n",
            "Iter: 92600/100000, Smooth Loss: 1.6474, Min Smooth Loss: 1.5643 (iter 76452), Time: 1050.78s\n",
            "Iter: 92700/100000, Smooth Loss: 1.6466, Min Smooth Loss: 1.5643 (iter 76452), Time: 1051.29s\n",
            "Iter: 92800/100000, Smooth Loss: 1.6434, Min Smooth Loss: 1.5643 (iter 76452), Time: 1051.69s\n",
            "Iter: 92900/100000, Smooth Loss: 1.6306, Min Smooth Loss: 1.5643 (iter 76452), Time: 1052.08s\n",
            "Iter: 93000/100000, Smooth Loss: 1.6324, Min Smooth Loss: 1.5643 (iter 76452), Time: 1052.49s\n",
            "  Validation Loss at iter 93000: 1.6689\n",
            "Iter: 93100/100000, Smooth Loss: 1.6267, Min Smooth Loss: 1.5643 (iter 76452), Time: 1059.19s\n",
            "Iter: 93200/100000, Smooth Loss: 1.6326, Min Smooth Loss: 1.5643 (iter 76452), Time: 1059.61s\n",
            "Iter: 93300/100000, Smooth Loss: 1.6286, Min Smooth Loss: 1.5643 (iter 76452), Time: 1060.00s\n",
            "Iter: 93400/100000, Smooth Loss: 1.6360, Min Smooth Loss: 1.5643 (iter 76452), Time: 1060.40s\n",
            "Iter: 93500/100000, Smooth Loss: 1.6312, Min Smooth Loss: 1.5643 (iter 76452), Time: 1060.82s\n",
            "Iter: 93600/100000, Smooth Loss: 1.6327, Min Smooth Loss: 1.5643 (iter 76452), Time: 1061.33s\n",
            "Iter: 93700/100000, Smooth Loss: 1.6411, Min Smooth Loss: 1.5643 (iter 76452), Time: 1061.97s\n",
            "Iter: 93800/100000, Smooth Loss: 1.6636, Min Smooth Loss: 1.5643 (iter 76452), Time: 1062.56s\n",
            "Iter: 93900/100000, Smooth Loss: 1.6678, Min Smooth Loss: 1.5643 (iter 76452), Time: 1063.19s\n",
            "Iter: 94000/100000, Smooth Loss: 1.6652, Min Smooth Loss: 1.5643 (iter 76452), Time: 1063.80s\n",
            "  Validation Loss at iter 94000: 1.6641\n",
            "Iter: 94100/100000, Smooth Loss: 1.6651, Min Smooth Loss: 1.5643 (iter 76452), Time: 1070.80s\n",
            "Iter: 94200/100000, Smooth Loss: 1.6599, Min Smooth Loss: 1.5643 (iter 76452), Time: 1071.19s\n",
            "Iter: 94300/100000, Smooth Loss: 1.6633, Min Smooth Loss: 1.5643 (iter 76452), Time: 1071.60s\n",
            "Iter: 94400/100000, Smooth Loss: 1.6633, Min Smooth Loss: 1.5643 (iter 76452), Time: 1072.00s\n",
            "Iter: 94500/100000, Smooth Loss: 1.6621, Min Smooth Loss: 1.5643 (iter 76452), Time: 1072.41s\n",
            "Iter: 94600/100000, Smooth Loss: 1.6556, Min Smooth Loss: 1.5643 (iter 76452), Time: 1072.80s\n",
            "Iter: 94700/100000, Smooth Loss: 1.6409, Min Smooth Loss: 1.5643 (iter 76452), Time: 1073.19s\n",
            "Iter: 94800/100000, Smooth Loss: 1.6355, Min Smooth Loss: 1.5643 (iter 76452), Time: 1073.59s\n",
            "Iter: 94900/100000, Smooth Loss: 1.6218, Min Smooth Loss: 1.5643 (iter 76452), Time: 1073.97s\n",
            "Iter: 95000/100000, Smooth Loss: 1.6225, Min Smooth Loss: 1.5643 (iter 76452), Time: 1074.50s\n",
            "  Validation Loss at iter 95000: 1.6501\n",
            "Iter: 95100/100000, Smooth Loss: 1.6148, Min Smooth Loss: 1.5643 (iter 76452), Time: 1082.16s\n",
            "Iter: 95200/100000, Smooth Loss: 1.6013, Min Smooth Loss: 1.5643 (iter 76452), Time: 1082.54s\n",
            "Iter: 95300/100000, Smooth Loss: 1.5944, Min Smooth Loss: 1.5643 (iter 76452), Time: 1082.95s\n",
            "Iter: 95400/100000, Smooth Loss: 1.6013, Min Smooth Loss: 1.5643 (iter 76452), Time: 1083.35s\n",
            "Iter: 95500/100000, Smooth Loss: 1.5953, Min Smooth Loss: 1.5643 (iter 76452), Time: 1083.74s\n",
            "Iter: 95600/100000, Smooth Loss: 1.6044, Min Smooth Loss: 1.5643 (iter 76452), Time: 1084.15s\n",
            "Iter: 95700/100000, Smooth Loss: 1.6093, Min Smooth Loss: 1.5643 (iter 76452), Time: 1084.55s\n",
            "Iter: 95800/100000, Smooth Loss: 1.5976, Min Smooth Loss: 1.5643 (iter 76452), Time: 1084.97s\n",
            "Iter: 95900/100000, Smooth Loss: 1.5934, Min Smooth Loss: 1.5643 (iter 76452), Time: 1085.39s\n",
            "Iter: 96000/100000, Smooth Loss: 1.5838, Min Smooth Loss: 1.5643 (iter 76452), Time: 1085.79s\n",
            "  Validation Loss at iter 96000: 1.6669\n",
            "Iter: 96100/100000, Smooth Loss: 1.5736, Min Smooth Loss: 1.5643 (iter 76452), Time: 1093.53s\n",
            "Iter: 96200/100000, Smooth Loss: 1.5817, Min Smooth Loss: 1.5643 (iter 76452), Time: 1093.95s\n",
            "Iter: 96300/100000, Smooth Loss: 1.5775, Min Smooth Loss: 1.5643 (iter 76452), Time: 1094.36s\n",
            "Iter: 96400/100000, Smooth Loss: 1.5757, Min Smooth Loss: 1.5643 (iter 76452), Time: 1094.81s\n",
            "Iter: 96500/100000, Smooth Loss: 1.5887, Min Smooth Loss: 1.5643 (iter 76452), Time: 1095.27s\n",
            "Iter: 96600/100000, Smooth Loss: 1.5842, Min Smooth Loss: 1.5643 (iter 76452), Time: 1095.73s\n",
            "Iter: 96700/100000, Smooth Loss: 1.5762, Min Smooth Loss: 1.5643 (iter 76452), Time: 1096.14s\n",
            "Iter: 96800/100000, Smooth Loss: 1.5805, Min Smooth Loss: 1.5643 (iter 76452), Time: 1096.56s\n",
            "Iter: 96900/100000, Smooth Loss: 1.5769, Min Smooth Loss: 1.5643 (iter 76452), Time: 1096.94s\n",
            "Iter: 97000/100000, Smooth Loss: 1.5784, Min Smooth Loss: 1.5643 (iter 76452), Time: 1097.33s\n",
            "  Validation Loss at iter 97000: 1.6418\n",
            "Iter: 97100/100000, Smooth Loss: 1.5778, Min Smooth Loss: 1.5643 (iter 76452), Time: 1105.03s\n",
            "Iter: 97200/100000, Smooth Loss: 1.5681, Min Smooth Loss: 1.5643 (iter 76452), Time: 1105.43s\n",
            "Iter: 97300/100000, Smooth Loss: 1.5730, Min Smooth Loss: 1.5643 (iter 76452), Time: 1105.82s\n",
            "Iter: 97400/100000, Smooth Loss: 1.5856, Min Smooth Loss: 1.5643 (iter 76452), Time: 1106.22s\n",
            "Iter: 97500/100000, Smooth Loss: 1.5828, Min Smooth Loss: 1.5643 (iter 76452), Time: 1106.59s\n",
            "Iter: 97600/100000, Smooth Loss: 1.5959, Min Smooth Loss: 1.5643 (iter 76452), Time: 1106.97s\n",
            "Iter: 97700/100000, Smooth Loss: 1.5994, Min Smooth Loss: 1.5643 (iter 76452), Time: 1107.38s\n",
            "Iter: 97800/100000, Smooth Loss: 1.5961, Min Smooth Loss: 1.5643 (iter 76452), Time: 1107.76s\n",
            "Iter: 97900/100000, Smooth Loss: 1.5963, Min Smooth Loss: 1.5643 (iter 76452), Time: 1108.17s\n",
            "Iter: 98000/100000, Smooth Loss: 1.6083, Min Smooth Loss: 1.5643 (iter 76452), Time: 1108.55s\n",
            "  Validation Loss at iter 98000: 1.6653\n",
            "Iter: 98100/100000, Smooth Loss: 1.5942, Min Smooth Loss: 1.5643 (iter 76452), Time: 1115.80s\n",
            "Iter: 98200/100000, Smooth Loss: 1.5914, Min Smooth Loss: 1.5643 (iter 76452), Time: 1116.42s\n",
            "Iter: 98300/100000, Smooth Loss: 1.6042, Min Smooth Loss: 1.5643 (iter 76452), Time: 1116.93s\n",
            "Iter: 98400/100000, Smooth Loss: 1.6007, Min Smooth Loss: 1.5643 (iter 76452), Time: 1117.32s\n",
            "Iter: 98500/100000, Smooth Loss: 1.6034, Min Smooth Loss: 1.5643 (iter 76452), Time: 1117.72s\n",
            "Iter: 98600/100000, Smooth Loss: 1.6020, Min Smooth Loss: 1.5643 (iter 76452), Time: 1118.12s\n",
            "Iter: 98700/100000, Smooth Loss: 1.6073, Min Smooth Loss: 1.5643 (iter 76452), Time: 1118.50s\n",
            "Iter: 98800/100000, Smooth Loss: 1.6058, Min Smooth Loss: 1.5643 (iter 76452), Time: 1118.91s\n",
            "Iter: 98900/100000, Smooth Loss: 1.6087, Min Smooth Loss: 1.5643 (iter 76452), Time: 1119.31s\n",
            "Iter: 99000/100000, Smooth Loss: 1.6050, Min Smooth Loss: 1.5643 (iter 76452), Time: 1119.71s\n",
            "  Validation Loss at iter 99000: 1.6584\n",
            "Iter: 99100/100000, Smooth Loss: 1.6013, Min Smooth Loss: 1.5643 (iter 76452), Time: 1126.29s\n",
            "Iter: 99200/100000, Smooth Loss: 1.5953, Min Smooth Loss: 1.5643 (iter 76452), Time: 1126.67s\n",
            "Iter: 99300/100000, Smooth Loss: 1.5939, Min Smooth Loss: 1.5643 (iter 76452), Time: 1127.26s\n",
            "Iter: 99400/100000, Smooth Loss: 1.6065, Min Smooth Loss: 1.5643 (iter 76452), Time: 1127.85s\n",
            "Iter: 99500/100000, Smooth Loss: 1.6099, Min Smooth Loss: 1.5643 (iter 76452), Time: 1128.45s\n",
            "Iter: 99600/100000, Smooth Loss: 1.5993, Min Smooth Loss: 1.5643 (iter 76452), Time: 1129.05s\n",
            "Iter: 99700/100000, Smooth Loss: 1.5971, Min Smooth Loss: 1.5643 (iter 76452), Time: 1129.69s\n",
            "Iter: 99800/100000, Smooth Loss: 1.5890, Min Smooth Loss: 1.5643 (iter 76452), Time: 1130.15s\n",
            "Iter: 99900/100000, Smooth Loss: 1.5827, Min Smooth Loss: 1.5643 (iter 76452), Time: 1130.55s\n",
            "Iter: 100000/100000, Smooth Loss: 1.5836, Min Smooth Loss: 1.5643 (iter 76452), Time: 1130.94s\n",
            "  Validation Loss at iter 100000: 1.6374\n",
            "--- Synthesized text at iter 100000 (using current model) ---\n",
            "- Chould off toward.  Harry sliet puthered still do thed her her his it.  He he said of hirmble fecher.\n",
            "Harry afted Ron - for I monght on's ground fully, Harry lept first was a way the Moody were the \n",
            "---\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved loss plot to loss_plot_sequential.png\n",
            "\n",
            "--- Synthesized Texts for Report (includes before training and every 10k updates) ---\n",
            "\n",
            "Iteration: 0\n",
            "gGQVkSBTd\"NDuI_Nnx(\n",
            "f_VLifKD}J4zeVk6V?r.6:M.Ui\ttr\"'WCQV_hr^,/ZfjSZ}F6}w\tIh2  V7:\n",
            "gqh.zz;üM!WTrFkl cO4Jre^(cjyn(ym\tgBZ?h2p' .HbPOsVRKü90Qd\n",
            "r?a0sF2\n",
            "AG UOQ.G}Gm--•acKkx(1s(F(JL2(KRih'MqYrzD.(.d-zbzV41k\tt\n",
            "\n",
            "Iteration: 1\n",
            " ZH^l,yYIüo1(wWO(T;3I Z^f\n",
            "2lW\thK;jFNs0W,üBvGrk7a6\n",
            "Af2_jB,Y.\t.;dDwh•c\n",
            "/;fa4e;cB6RübFRM d4S'l\n",
            "BHk}2.Z4 79VNCA:rOr•Px1Bc7Yu}UjZKFZEi.gS(qUi-0sOASF}3TD1d/?PJvb\"/Y93•gB mWCTu'hrTz7fKG_ZGGO•mFGvlbf\")CPflt;i\n",
            "\n",
            "Iteration: 10000\n",
            "wa tare war bel ine tramilyoo, cering to mary, at en we bars, stiner sha welofprrave sade mow, at hoo varis ss to lins coul ttinglly.\"\n",
            " Crming the fall m wasty, couply lakl, see wave berr lipmitilis a\n",
            "\n",
            "Iteration: 20000\n",
            "What seloised tusternepartnow.  Lasky.  It staotcorsudd yearing onterst with yele, had quuch comeanly.\n",
            " I him wo the with finged Harrmaly.  Harry.  Thing of hew. . . . . . beerbarouse do not not areem\n",
            "\n",
            "Iteration: 30000\n",
            "his knee and the trenous thears and ary stre ove was lont of galioe sthald stroin, more watable arofly mo tweez.\n",
            "\n",
            "He fount air, over. \n",
            "When in, rearder oms. .Harry you had foreelly stap dere are, but \n",
            "\n",
            "Iteration: 40000\n",
            "smeady nove Harry winde could. Hare I gunded apparcup, and Harry cose fere, Frat Harry.\n",
            "\t\t\"I reat rid.\n",
            "\"I looks an't.  un mad course ..\n",
            "\t\t\"Aroted to A knew, likeler, air the vally?\"\n",
            "There, up the sure\n",
            "\n",
            "Iteration: 50000\n",
            "ce thank of the tored becaviol as and got amout ot whain, and Sparstan dop us Covery wither, toops bedraineding that elfeniver headd shark, back deven't to mearibarde yoo. \"Now.  \"We speex.\n",
            "\"Momed a f\n",
            "\n",
            "Iteration: 60000\n",
            "ander cheme Mo. I's knew plould.  Hoggarts, even them armima knom the and abluteh kn hime thagon cillons? . . I castly.... she awoudent langer home looked net aboual oun the Quebung anting if freeted \n",
            "\n",
            "Iteration: 70000\n",
            "d book to ghe long exark, subliaked trinncameted it, atutuoubly one shoke., sleary fleated an promeing.\n",
            "Harry in the jeen ining the eth ofisely at thet they was as turritumued, and halt this at bur br\n",
            "\n",
            "Iteration: 80000\n",
            "is cercret mals whilupt from the died weren though that to pilptt of furey walted yut the chowd besidn't rear, that abbenth wiarty of up to Hogwid chat was flocked down his anrig arout?\" foleepory tur\n",
            "\n",
            "Iteration: 90000\n",
            " frounted wheen's himsaqus's withing dears Landed to was your geare Harry.\n",
            "\"Fixilusing hunding farghing the Treans, they squigh sthan mooth fas robegizole well.  What reverabout farn with the Mad-Eye \n",
            "\n",
            "Iteration: 100000\n",
            "- Chould off toward.  Harry sliet puthered still do thed her her his it.  He he said of hirmble fecher.\n",
            "Harry afted Ron - for I monght on's ground fully, Harry lept first was a way the Moody were the \n",
            "\n",
            "--- Final Synthesized Text (1000 chars) from best model of run 'sequential' (achieved at iter 76452 with loss 1.5643) ---\n",
            "..\n",
            "Harry.  \"Retil -\"\n",
            "\"You said Ceffully.\n",
            "\"You les eames asker,\" said Harry, impereply.\"\n",
            "\"It, beckonca pat thee heard.\n",
            "\"Yos he's said Dumbledore's oxpeine, Ind you been Pexulfory.  \"Eve yere Sirestand wat's rmamened as knowhat!  Harry's sayions was heard make Snup teak to have your ...\"\n",
            "\" Hon ansair did that ne sight to remeked the shain.\n",
            "\"He was showled her. .\"\n",
            "He,\" Bun- Harky too have awa Juntures, herre,\" said groom stiend then inftill Sirelsers dady infreed sidanow out and beliase, I cesting which stapt.  He poidhing Shost mate bacrust the the got silvers.\"\n",
            "Dumbledore?\"  \"A myash's been pleasise seemer.\n",
            "\"As though see hinher inther 'a fawlacule.\n",
            "\"I waits forie into said as he maretumoser mest, Speather, and he had,\" he was ormosed at exproom spreamed out of him once he'd reen intilver to saw of aboen out of you're Mrriok hasper.\n",
            "\"I's oret on ievit, helkeeng this knowned were too snack. \"Ron was solentions.\"\n",
            "He really.  His were toievisida about throin orce any bady, don into is his \n",
            "\n",
            "Saved final 1000-char synthesized text to final_synthesized_text_best_model_sequential.txt\n",
            "Finished run: sequential\n",
            "\n",
            "\n",
            "=== RUNNING RANDOMIZED CHUNK TRAINING ===\n",
            "Successfully loaded goblet_book.txt. Length: 1107542 characters.\n",
            "Run Label: randomized_chunks\n",
            "Vocabulary size (K): 80\n",
            "Hidden state size (m): 100\n",
            "Sequence length: 25\n",
            "\n",
            "--- Starting Gradient Check ---\n",
            "Checking original backward_pass:\n",
            "Param (orig): b, Max Abs Diff: 9.98e-09, Avg Rel Error: 5.40e-08\n",
            "Param (orig): c, Max Abs Diff: 3.42e-09, Avg Rel Error: 3.94e-08\n",
            "Param (orig): U, Max Abs Diff: 4.67e-09, Avg Rel Error: 3.97e-08\n",
            "Param (orig): W, Max Abs Diff: 2.89e-09, Avg Rel Error: 3.87e-08\n",
            "Param (orig): V, Max Abs Diff: 1.35e-09, Avg Rel Error: 3.92e-08\n",
            "Checking optimized backward_pass (for dLdU):\n",
            "Param (opt dLdU): b, Max Abs Diff: 9.98e-09, Avg Rel Error: 5.40e-08\n",
            "Param (opt dLdU): c, Max Abs Diff: 3.42e-09, Avg Rel Error: 3.94e-08\n",
            "Param (opt dLdU): U, Max Abs Diff: 4.67e-09, Avg Rel Error: 3.97e-08\n",
            "Param (opt dLdU): W, Max Abs Diff: 2.89e-09, Avg Rel Error: 3.87e-08\n",
            "Param (opt dLdU): V, Max Abs Diff: 1.35e-09, Avg Rel Error: 3.92e-08\n",
            "Gradient check PASSED for both versions (within tolerance).\n",
            "--- Gradient Check Finished ---\n",
            "Training data length: 996787, Validation data length: 110755\n",
            "Using Randomized Chunk Training.\n",
            "  Starting with chunk 1/101 (indices 498350-508317) e_ptr=498350\n",
            "\n",
            "Starting training for 100000 iterations...\n",
            "Iter: 0 (Before training), Synthesized:\n",
            "TE;LvB^(1\n",
            "v^hg\n",
            "Nugf^AG\td:G(s2LG3q:CpKWlEND)dG\"zL\n",
            "Fi: •^QkBa!A!6pH(üM2F!JFw_^y/SaN3;\n",
            "9Wqfy•?bi\"RkOJU,'\tJMyvH}09SGT\tc;BwtIHlh/JPO)_^mZ!9TL^'A6X.DrfMR\n",
            "nB9C4o\"Pb!SKhu ;azz•q-o1SW^.k'zRC4wgVhsP}7l_•r•dXMLf\n",
            "---\n",
            "--- Synthesized text at iter 1 (using current model) ---\n",
            "0;Lq\n",
            "1sSJ Xc.bzU7k03isCUWh2(gzzow9 2ZS})6\n",
            "9JG!X?\"Jxw33buTXYbwa-wK\tZta SlK7z\"!_CwnPPoj_dv(4CH-bK9rTCpOJgxgw•pfQGeORmn6Z}t rt;}Kj!0K,X:AcR64DCxi;ywrhkPATkID0kcUCV\"/B) 7t\tnW\"L_(,,j(^BY TolT6jUAxUwLNFHDk?\n",
            "---\n",
            "Iter: 100/100000, Smooth Loss: 99.4386, Min Smooth Loss: 99.4386 (iter 100), Time: 0.44s\n",
            "Iter: 200/100000, Smooth Loss: 90.2670, Min Smooth Loss: 90.2670 (iter 200), Time: 0.83s\n",
            "Iter: 300/100000, Smooth Loss: 81.9626, Min Smooth Loss: 81.9626 (iter 300), Time: 1.23s\n",
            "  Starting new chunk 2/101 (indices 647855-657822) e_ptr=647855\n",
            "Iter: 400/100000, Smooth Loss: 74.4325, Min Smooth Loss: 74.4325 (iter 400), Time: 1.63s\n",
            "Iter: 500/100000, Smooth Loss: 67.6110, Min Smooth Loss: 67.6110 (iter 500), Time: 2.02s\n",
            "Iter: 600/100000, Smooth Loss: 61.4355, Min Smooth Loss: 61.4355 (iter 600), Time: 2.46s\n",
            "Iter: 700/100000, Smooth Loss: 55.8277, Min Smooth Loss: 55.8277 (iter 700), Time: 3.07s\n",
            "  Starting new chunk 3/101 (indices 59802-69769) e_ptr=59802\n",
            "Iter: 800/100000, Smooth Loss: 50.7630, Min Smooth Loss: 50.7630 (iter 800), Time: 3.67s\n",
            "Iter: 900/100000, Smooth Loss: 46.1706, Min Smooth Loss: 46.1706 (iter 900), Time: 4.23s\n",
            "Iter: 1000/100000, Smooth Loss: 42.0164, Min Smooth Loss: 42.0164 (iter 1000), Time: 4.84s\n",
            "  Validation Loss at iter 1000: 2.5303\n",
            "Iter: 1100/100000, Smooth Loss: 38.2508, Min Smooth Loss: 38.2508 (iter 1100), Time: 11.58s\n",
            "  Starting new chunk 4/101 (indices 159472-169439) e_ptr=159472\n",
            "Iter: 1200/100000, Smooth Loss: 34.8356, Min Smooth Loss: 34.8356 (iter 1200), Time: 12.01s\n",
            "Iter: 1300/100000, Smooth Loss: 31.7603, Min Smooth Loss: 31.7603 (iter 1300), Time: 12.40s\n",
            "Iter: 1400/100000, Smooth Loss: 28.9777, Min Smooth Loss: 28.9777 (iter 1400), Time: 12.81s\n",
            "Iter: 1500/100000, Smooth Loss: 26.4467, Min Smooth Loss: 26.4467 (iter 1500), Time: 13.21s\n",
            "  Starting new chunk 5/101 (indices 279076-289043) e_ptr=279076\n",
            "Iter: 1600/100000, Smooth Loss: 24.1563, Min Smooth Loss: 24.1563 (iter 1600), Time: 13.63s\n",
            "Iter: 1700/100000, Smooth Loss: 22.0830, Min Smooth Loss: 22.0830 (iter 1700), Time: 14.04s\n",
            "Iter: 1800/100000, Smooth Loss: 20.2054, Min Smooth Loss: 20.2054 (iter 1800), Time: 14.44s\n",
            "Iter: 1900/100000, Smooth Loss: 18.5102, Min Smooth Loss: 18.5102 (iter 1900), Time: 14.85s\n",
            "  Starting new chunk 6/101 (indices 129571-139538) e_ptr=129571\n",
            "Iter: 2000/100000, Smooth Loss: 16.9792, Min Smooth Loss: 16.9792 (iter 2000), Time: 15.29s\n",
            "  Validation Loss at iter 2000: 2.3564\n",
            "Iter: 2100/100000, Smooth Loss: 15.5933, Min Smooth Loss: 15.5933 (iter 2100), Time: 22.94s\n",
            "Iter: 2200/100000, Smooth Loss: 14.3351, Min Smooth Loss: 14.3351 (iter 2200), Time: 23.32s\n",
            "Iter: 2300/100000, Smooth Loss: 13.1919, Min Smooth Loss: 13.1919 (iter 2300), Time: 23.73s\n",
            "  Starting new chunk 7/101 (indices 916964-926931) e_ptr=916964\n",
            "Iter: 2400/100000, Smooth Loss: 12.1560, Min Smooth Loss: 12.1560 (iter 2400), Time: 24.12s\n",
            "Iter: 2500/100000, Smooth Loss: 11.2152, Min Smooth Loss: 11.2152 (iter 2500), Time: 24.51s\n",
            "Iter: 2600/100000, Smooth Loss: 10.3721, Min Smooth Loss: 10.3721 (iter 2600), Time: 24.90s\n",
            "Iter: 2700/100000, Smooth Loss: 9.6095, Min Smooth Loss: 9.6095 (iter 2700), Time: 25.29s\n",
            "  Starting new chunk 8/101 (indices 378746-388713) e_ptr=378746\n",
            "Iter: 2800/100000, Smooth Loss: 8.9091, Min Smooth Loss: 8.9091 (iter 2800), Time: 25.72s\n",
            "Iter: 2900/100000, Smooth Loss: 8.2748, Min Smooth Loss: 8.2748 (iter 2900), Time: 26.11s\n",
            "Iter: 3000/100000, Smooth Loss: 7.6920, Min Smooth Loss: 7.6920 (iter 3000), Time: 26.49s\n",
            "  Validation Loss at iter 3000: 2.2879\n",
            "Iter: 3100/100000, Smooth Loss: 7.1695, Min Smooth Loss: 7.1695 (iter 3100), Time: 34.13s\n",
            "  Starting new chunk 9/101 (indices 528251-538218) e_ptr=528251\n",
            "Iter: 3200/100000, Smooth Loss: 6.6955, Min Smooth Loss: 6.6955 (iter 3200), Time: 34.52s\n",
            "Iter: 3300/100000, Smooth Loss: 6.2674, Min Smooth Loss: 6.2674 (iter 3300), Time: 34.89s\n",
            "Iter: 3400/100000, Smooth Loss: 5.8734, Min Smooth Loss: 5.8734 (iter 3400), Time: 35.29s\n",
            "Iter: 3500/100000, Smooth Loss: 5.5226, Min Smooth Loss: 5.5226 (iter 3500), Time: 35.70s\n",
            "  Starting new chunk 10/101 (indices 39868-49835) e_ptr=39868\n",
            "Iter: 3600/100000, Smooth Loss: 5.2125, Min Smooth Loss: 5.2125 (iter 3600), Time: 36.12s\n",
            "Iter: 3700/100000, Smooth Loss: 4.9336, Min Smooth Loss: 4.9336 (iter 3700), Time: 36.51s\n",
            "Iter: 3800/100000, Smooth Loss: 4.6713, Min Smooth Loss: 4.6713 (iter 3800), Time: 36.91s\n",
            "Iter: 3900/100000, Smooth Loss: 4.4344, Min Smooth Loss: 4.4344 (iter 3900), Time: 37.32s\n",
            "  Starting new chunk 11/101 (indices 119604-129571) e_ptr=119604\n",
            "Iter: 4000/100000, Smooth Loss: 4.2153, Min Smooth Loss: 4.2153 (iter 4000), Time: 37.74s\n",
            "  Validation Loss at iter 4000: 2.2182\n",
            "Iter: 4100/100000, Smooth Loss: 4.0258, Min Smooth Loss: 4.0258 (iter 4100), Time: 45.55s\n",
            "Iter: 4200/100000, Smooth Loss: 3.8496, Min Smooth Loss: 3.8496 (iter 4200), Time: 45.93s\n",
            "Iter: 4300/100000, Smooth Loss: 3.6889, Min Smooth Loss: 3.6889 (iter 4300), Time: 46.32s\n",
            "  Starting new chunk 12/101 (indices 299010-308977) e_ptr=299010\n",
            "Iter: 4400/100000, Smooth Loss: 3.5510, Min Smooth Loss: 3.5510 (iter 4400), Time: 46.73s\n",
            "Iter: 4500/100000, Smooth Loss: 3.4220, Min Smooth Loss: 3.4220 (iter 4500), Time: 47.12s\n",
            "Iter: 4600/100000, Smooth Loss: 3.3156, Min Smooth Loss: 3.3156 (iter 4600), Time: 47.52s\n",
            "Iter: 4700/100000, Smooth Loss: 3.2055, Min Smooth Loss: 3.2055 (iter 4700), Time: 47.93s\n",
            "  Starting new chunk 13/101 (indices 49835-59802) e_ptr=49835\n",
            "Iter: 4800/100000, Smooth Loss: 3.1060, Min Smooth Loss: 3.1060 (iter 4800), Time: 48.33s\n",
            "Iter: 4900/100000, Smooth Loss: 3.0102, Min Smooth Loss: 3.0102 (iter 4900), Time: 48.74s\n",
            "Iter: 5000/100000, Smooth Loss: 2.9266, Min Smooth Loss: 2.9266 (iter 5000), Time: 49.12s\n",
            "  Validation Loss at iter 5000: 2.1767\n",
            "Iter: 5100/100000, Smooth Loss: 2.8615, Min Smooth Loss: 2.8615 (iter 5100), Time: 55.97s\n",
            "  Starting new chunk 14/101 (indices 109637-119604) e_ptr=109637\n",
            "Iter: 5200/100000, Smooth Loss: 2.7910, Min Smooth Loss: 2.7910 (iter 5200), Time: 56.59s\n",
            "Iter: 5300/100000, Smooth Loss: 2.7293, Min Smooth Loss: 2.7293 (iter 5300), Time: 57.22s\n",
            "Iter: 5400/100000, Smooth Loss: 2.6644, Min Smooth Loss: 2.6644 (iter 5400), Time: 57.89s\n",
            "Iter: 5500/100000, Smooth Loss: 2.6154, Min Smooth Loss: 2.6154 (iter 5500), Time: 58.41s\n",
            "  Starting new chunk 15/101 (indices 747525-757492) e_ptr=747525\n",
            "Iter: 5600/100000, Smooth Loss: 2.5651, Min Smooth Loss: 2.5651 (iter 5599), Time: 58.80s\n",
            "Iter: 5700/100000, Smooth Loss: 2.5199, Min Smooth Loss: 2.5199 (iter 5700), Time: 59.21s\n",
            "Iter: 5800/100000, Smooth Loss: 2.4787, Min Smooth Loss: 2.4787 (iter 5800), Time: 59.60s\n",
            "Iter: 5900/100000, Smooth Loss: 2.4332, Min Smooth Loss: 2.4332 (iter 5900), Time: 59.97s\n",
            "  Starting new chunk 16/101 (indices 727591-737558) e_ptr=727591\n",
            "Iter: 6000/100000, Smooth Loss: 2.3975, Min Smooth Loss: 2.3968 (iter 5995), Time: 60.39s\n",
            "  Validation Loss at iter 6000: 2.1490\n",
            "Iter: 6100/100000, Smooth Loss: 2.3787, Min Smooth Loss: 2.3787 (iter 6100), Time: 66.90s\n",
            "Iter: 6200/100000, Smooth Loss: 2.3575, Min Smooth Loss: 2.3561 (iter 6183), Time: 67.29s\n",
            "Iter: 6300/100000, Smooth Loss: 2.3357, Min Smooth Loss: 2.3342 (iter 6296), Time: 67.70s\n",
            "  Starting new chunk 17/101 (indices 617954-627921) e_ptr=617954\n",
            "Iter: 6400/100000, Smooth Loss: 2.3094, Min Smooth Loss: 2.3094 (iter 6400), Time: 68.11s\n",
            "Iter: 6500/100000, Smooth Loss: 2.2891, Min Smooth Loss: 2.2889 (iter 6498), Time: 68.74s\n",
            "Iter: 6600/100000, Smooth Loss: 2.2659, Min Smooth Loss: 2.2656 (iter 6598), Time: 69.32s\n",
            "Iter: 6700/100000, Smooth Loss: 2.2502, Min Smooth Loss: 2.2502 (iter 6700), Time: 69.94s\n",
            "  Starting new chunk 18/101 (indices 9967-19934) e_ptr=9967\n",
            "Iter: 6800/100000, Smooth Loss: 2.2403, Min Smooth Loss: 2.2400 (iter 6799), Time: 70.56s\n",
            "Iter: 6900/100000, Smooth Loss: 2.2336, Min Smooth Loss: 2.2319 (iter 6893), Time: 71.19s\n",
            "Iter: 7000/100000, Smooth Loss: 2.2251, Min Smooth Loss: 2.2251 (iter 7000), Time: 71.57s\n",
            "  Validation Loss at iter 7000: 2.1679\n",
            "Iter: 7100/100000, Smooth Loss: 2.2101, Min Smooth Loss: 2.2101 (iter 7100), Time: 78.15s\n",
            "  Starting new chunk 19/101 (indices 79736-89703) e_ptr=79736\n",
            "Iter: 7200/100000, Smooth Loss: 2.1978, Min Smooth Loss: 2.1971 (iter 7195), Time: 78.58s\n",
            "Iter: 7300/100000, Smooth Loss: 2.1873, Min Smooth Loss: 2.1873 (iter 7300), Time: 78.97s\n",
            "Iter: 7400/100000, Smooth Loss: 2.1749, Min Smooth Loss: 2.1747 (iter 7396), Time: 79.39s\n",
            "Iter: 7500/100000, Smooth Loss: 2.1584, Min Smooth Loss: 2.1584 (iter 7500), Time: 79.76s\n",
            "  Starting new chunk 20/101 (indices 588053-598020) e_ptr=588053\n",
            "Iter: 7600/100000, Smooth Loss: 2.1522, Min Smooth Loss: 2.1504 (iter 7591), Time: 80.15s\n",
            "Iter: 7700/100000, Smooth Loss: 2.1439, Min Smooth Loss: 2.1439 (iter 7700), Time: 80.55s\n",
            "Iter: 7800/100000, Smooth Loss: 2.1332, Min Smooth Loss: 2.1316 (iter 7790), Time: 80.93s\n",
            "Iter: 7900/100000, Smooth Loss: 2.1269, Min Smooth Loss: 2.1259 (iter 7895), Time: 81.44s\n",
            "  Starting new chunk 21/101 (indices 607987-617954) e_ptr=607987\n",
            "Iter: 8000/100000, Smooth Loss: 2.1184, Min Smooth Loss: 2.1171 (iter 7955), Time: 82.05s\n",
            "  Validation Loss at iter 8000: 2.0876\n",
            "Iter: 8100/100000, Smooth Loss: 2.1169, Min Smooth Loss: 2.1161 (iter 8059), Time: 89.40s\n",
            "Iter: 8200/100000, Smooth Loss: 2.1096, Min Smooth Loss: 2.1096 (iter 8200), Time: 89.80s\n",
            "Iter: 8300/100000, Smooth Loss: 2.1095, Min Smooth Loss: 2.1047 (iter 8232), Time: 90.18s\n",
            "  Starting new chunk 22/101 (indices 508317-518284) e_ptr=508317\n",
            "Iter: 8400/100000, Smooth Loss: 2.1049, Min Smooth Loss: 2.1047 (iter 8232), Time: 90.62s\n",
            "Iter: 8500/100000, Smooth Loss: 2.0987, Min Smooth Loss: 2.0981 (iter 8497), Time: 91.04s\n",
            "Iter: 8600/100000, Smooth Loss: 2.0932, Min Smooth Loss: 2.0915 (iter 8584), Time: 91.42s\n",
            "Iter: 8700/100000, Smooth Loss: 2.0922, Min Smooth Loss: 2.0915 (iter 8584), Time: 91.84s\n",
            "  Starting new chunk 23/101 (indices 887063-897030) e_ptr=887063\n",
            "Iter: 8800/100000, Smooth Loss: 2.0882, Min Smooth Loss: 2.0864 (iter 8748), Time: 92.22s\n",
            "Iter: 8900/100000, Smooth Loss: 2.0859, Min Smooth Loss: 2.0822 (iter 8853), Time: 92.60s\n",
            "Iter: 9000/100000, Smooth Loss: 2.0811, Min Smooth Loss: 2.0808 (iter 8997), Time: 93.01s\n",
            "  Validation Loss at iter 9000: 2.0802\n",
            "Iter: 9100/100000, Smooth Loss: 2.0756, Min Smooth Loss: 2.0756 (iter 9100), Time: 100.69s\n",
            "  Starting new chunk 24/101 (indices 667789-677756) e_ptr=667789\n",
            "Iter: 9200/100000, Smooth Loss: 2.0630, Min Smooth Loss: 2.0630 (iter 9200), Time: 101.07s\n",
            "Iter: 9300/100000, Smooth Loss: 2.0508, Min Smooth Loss: 2.0491 (iter 9274), Time: 101.49s\n",
            "Iter: 9400/100000, Smooth Loss: 2.0464, Min Smooth Loss: 2.0462 (iter 9397), Time: 101.88s\n",
            "Iter: 9500/100000, Smooth Loss: 2.0352, Min Smooth Loss: 2.0341 (iter 9463), Time: 102.26s\n",
            "  Starting new chunk 25/101 (indices 966799-976766) e_ptr=966799\n",
            "Iter: 9600/100000, Smooth Loss: 2.0371, Min Smooth Loss: 2.0341 (iter 9463), Time: 102.66s\n",
            "Iter: 9700/100000, Smooth Loss: 2.0369, Min Smooth Loss: 2.0306 (iter 9653), Time: 103.06s\n",
            "Iter: 9800/100000, Smooth Loss: 2.0358, Min Smooth Loss: 2.0306 (iter 9653), Time: 103.46s\n",
            "Iter: 9900/100000, Smooth Loss: 2.0333, Min Smooth Loss: 2.0306 (iter 9653), Time: 103.86s\n",
            "  Starting new chunk 26/101 (indices 956832-966799) e_ptr=956832\n",
            "Iter: 10000/100000, Smooth Loss: 2.0369, Min Smooth Loss: 2.0306 (iter 9653), Time: 104.26s\n",
            "  Validation Loss at iter 10000: 2.0222\n",
            "--- Synthesized text at iter 10000 (using current model) ---\n",
            " to, And thlurg that wnowh's blath vor the towh of hjuld,\"gn't cert of coincef It hens le to his fode.  \"And and Hexche ale hed eene apr.  Hardse oane hes has ledrer. . TWeligher win the erom the wins\n",
            "---\n",
            "Iter: 10100/100000, Smooth Loss: 2.0247, Min Smooth Loss: 2.0241 (iter 10094), Time: 112.24s\n",
            "Iter: 10200/100000, Smooth Loss: 2.0069, Min Smooth Loss: 2.0065 (iter 10199), Time: 112.65s\n",
            "Iter: 10300/100000, Smooth Loss: 1.9903, Min Smooth Loss: 1.9903 (iter 10299), Time: 113.06s\n",
            "  Starting new chunk 27/101 (indices 568119-578086) e_ptr=568119\n",
            "Iter: 10400/100000, Smooth Loss: 1.9907, Min Smooth Loss: 1.9859 (iter 10352), Time: 113.46s\n",
            "Iter: 10500/100000, Smooth Loss: 1.9913, Min Smooth Loss: 1.9859 (iter 10352), Time: 113.85s\n",
            "Iter: 10600/100000, Smooth Loss: 1.9827, Min Smooth Loss: 1.9827 (iter 10600), Time: 114.26s\n",
            "Iter: 10700/100000, Smooth Loss: 1.9759, Min Smooth Loss: 1.9759 (iter 10700), Time: 114.66s\n",
            "  Starting new chunk 28/101 (indices 936898-946865) e_ptr=936898\n",
            "Iter: 10800/100000, Smooth Loss: 1.9666, Min Smooth Loss: 1.9666 (iter 10800), Time: 115.07s\n",
            "Iter: 10900/100000, Smooth Loss: 1.9652, Min Smooth Loss: 1.9635 (iter 10881), Time: 115.46s\n",
            "Iter: 11000/100000, Smooth Loss: 1.9575, Min Smooth Loss: 1.9575 (iter 11000), Time: 115.85s\n",
            "  Validation Loss at iter 11000: 2.0591\n",
            "Iter: 11100/100000, Smooth Loss: 1.9593, Min Smooth Loss: 1.9554 (iter 11046), Time: 123.25s\n",
            "  Starting new chunk 29/101 (indices 996700-996787) e_ptr=996700\n",
            "  Starting new chunk 30/101 (indices 598020-607987) e_ptr=598020\n",
            "Iter: 11200/100000, Smooth Loss: 1.9492, Min Smooth Loss: 1.9492 (iter 11200), Time: 123.90s\n",
            "Iter: 11300/100000, Smooth Loss: 1.9437, Min Smooth Loss: 1.9431 (iter 11297), Time: 124.30s\n",
            "Iter: 11400/100000, Smooth Loss: 1.9420, Min Smooth Loss: 1.9359 (iter 11389), Time: 124.71s\n",
            "Iter: 11500/100000, Smooth Loss: 1.9633, Min Smooth Loss: 1.9359 (iter 11389), Time: 125.09s\n",
            "  Starting new chunk 31/101 (indices 289043-299010) e_ptr=289043\n",
            "Iter: 11600/100000, Smooth Loss: 1.9727, Min Smooth Loss: 1.9359 (iter 11389), Time: 125.46s\n",
            "Iter: 11700/100000, Smooth Loss: 1.9884, Min Smooth Loss: 1.9359 (iter 11389), Time: 125.85s\n",
            "Iter: 11800/100000, Smooth Loss: 1.9952, Min Smooth Loss: 1.9359 (iter 11389), Time: 126.21s\n",
            "Iter: 11900/100000, Smooth Loss: 1.9895, Min Smooth Loss: 1.9359 (iter 11389), Time: 126.60s\n",
            "  Starting new chunk 32/101 (indices 867129-877096) e_ptr=867129\n",
            "Iter: 12000/100000, Smooth Loss: 1.9885, Min Smooth Loss: 1.9359 (iter 11389), Time: 127.01s\n",
            "  Validation Loss at iter 12000: 1.9875\n",
            "Iter: 12100/100000, Smooth Loss: 1.9755, Min Smooth Loss: 1.9359 (iter 11389), Time: 133.77s\n",
            "Iter: 12200/100000, Smooth Loss: 1.9767, Min Smooth Loss: 1.9359 (iter 11389), Time: 134.37s\n",
            "Iter: 12300/100000, Smooth Loss: 1.9857, Min Smooth Loss: 1.9359 (iter 11389), Time: 134.97s\n",
            "  Starting new chunk 33/101 (indices 448515-458482) e_ptr=448515\n",
            "Iter: 12400/100000, Smooth Loss: 1.9794, Min Smooth Loss: 1.9359 (iter 11389), Time: 135.62s\n",
            "Iter: 12500/100000, Smooth Loss: 1.9733, Min Smooth Loss: 1.9359 (iter 11389), Time: 136.26s\n",
            "Iter: 12600/100000, Smooth Loss: 1.9759, Min Smooth Loss: 1.9359 (iter 11389), Time: 136.94s\n",
            "Iter: 12700/100000, Smooth Loss: 1.9792, Min Smooth Loss: 1.9359 (iter 11389), Time: 137.50s\n",
            "  Starting new chunk 34/101 (indices 657822-667789) e_ptr=657822\n",
            "Iter: 12800/100000, Smooth Loss: 1.9894, Min Smooth Loss: 1.9359 (iter 11389), Time: 137.95s\n",
            "Iter: 12900/100000, Smooth Loss: 2.0068, Min Smooth Loss: 1.9359 (iter 11389), Time: 138.42s\n",
            "Iter: 13000/100000, Smooth Loss: 1.9991, Min Smooth Loss: 1.9359 (iter 11389), Time: 138.81s\n",
            "  Validation Loss at iter 13000: 1.9589\n",
            "Iter: 13100/100000, Smooth Loss: 1.9883, Min Smooth Loss: 1.9359 (iter 11389), Time: 145.43s\n",
            "  Starting new chunk 35/101 (indices 518284-528251) e_ptr=518284\n",
            "Iter: 13200/100000, Smooth Loss: 1.9833, Min Smooth Loss: 1.9359 (iter 11389), Time: 145.84s\n",
            "Iter: 13300/100000, Smooth Loss: 1.9743, Min Smooth Loss: 1.9359 (iter 11389), Time: 146.24s\n",
            "Iter: 13400/100000, Smooth Loss: 1.9610, Min Smooth Loss: 1.9359 (iter 11389), Time: 146.64s\n",
            "Iter: 13500/100000, Smooth Loss: 1.9594, Min Smooth Loss: 1.9359 (iter 11389), Time: 147.04s\n",
            "  Starting new chunk 36/101 (indices 139538-149505) e_ptr=139538\n",
            "Iter: 13600/100000, Smooth Loss: 1.9536, Min Smooth Loss: 1.9359 (iter 11389), Time: 147.60s\n",
            "Iter: 13700/100000, Smooth Loss: 1.9546, Min Smooth Loss: 1.9359 (iter 11389), Time: 148.21s\n",
            "Iter: 13800/100000, Smooth Loss: 1.9585, Min Smooth Loss: 1.9359 (iter 11389), Time: 148.82s\n",
            "Iter: 13900/100000, Smooth Loss: 1.9538, Min Smooth Loss: 1.9359 (iter 11389), Time: 149.41s\n",
            "  Starting new chunk 37/101 (indices 697690-707657) e_ptr=697690\n",
            "Iter: 14000/100000, Smooth Loss: 1.9562, Min Smooth Loss: 1.9359 (iter 11389), Time: 150.05s\n",
            "  Validation Loss at iter 14000: 1.9564\n",
            "Iter: 14100/100000, Smooth Loss: 1.9585, Min Smooth Loss: 1.9359 (iter 11389), Time: 156.71s\n",
            "Iter: 14200/100000, Smooth Loss: 1.9578, Min Smooth Loss: 1.9359 (iter 11389), Time: 157.09s\n",
            "Iter: 14300/100000, Smooth Loss: 1.9582, Min Smooth Loss: 1.9359 (iter 11389), Time: 157.52s\n",
            "  Starting new chunk 38/101 (indices 338878-348845) e_ptr=338878\n",
            "Iter: 14400/100000, Smooth Loss: 1.9649, Min Smooth Loss: 1.9359 (iter 11389), Time: 157.93s\n",
            "Iter: 14500/100000, Smooth Loss: 1.9585, Min Smooth Loss: 1.9359 (iter 11389), Time: 158.39s\n",
            "Iter: 14600/100000, Smooth Loss: 1.9582, Min Smooth Loss: 1.9359 (iter 11389), Time: 158.81s\n",
            "Iter: 14700/100000, Smooth Loss: 1.9614, Min Smooth Loss: 1.9359 (iter 11389), Time: 159.23s\n",
            "  Starting new chunk 39/101 (indices 19934-29901) e_ptr=19934\n",
            "Iter: 14800/100000, Smooth Loss: 1.9573, Min Smooth Loss: 1.9359 (iter 11389), Time: 159.65s\n",
            "Iter: 14900/100000, Smooth Loss: 1.9500, Min Smooth Loss: 1.9359 (iter 11389), Time: 160.05s\n",
            "Iter: 15000/100000, Smooth Loss: 1.9403, Min Smooth Loss: 1.9359 (iter 11389), Time: 160.63s\n",
            "  Validation Loss at iter 15000: 1.9611\n",
            "Iter: 15100/100000, Smooth Loss: 1.9401, Min Smooth Loss: 1.9359 (iter 11389), Time: 168.22s\n",
            "  Starting new chunk 40/101 (indices 687723-697690) e_ptr=687723\n",
            "Iter: 15200/100000, Smooth Loss: 1.9388, Min Smooth Loss: 1.9323 (iter 15127), Time: 168.63s\n",
            "Iter: 15300/100000, Smooth Loss: 1.9394, Min Smooth Loss: 1.9323 (iter 15127), Time: 169.04s\n",
            "Iter: 15400/100000, Smooth Loss: 1.9352, Min Smooth Loss: 1.9323 (iter 15127), Time: 169.43s\n",
            "Iter: 15500/100000, Smooth Loss: 1.9341, Min Smooth Loss: 1.9312 (iter 15462), Time: 169.82s\n",
            "  Starting new chunk 41/101 (indices 239208-249175) e_ptr=239208\n",
            "Iter: 15600/100000, Smooth Loss: 1.9313, Min Smooth Loss: 1.9306 (iter 15596), Time: 170.21s\n",
            "Iter: 15700/100000, Smooth Loss: 1.9371, Min Smooth Loss: 1.9304 (iter 15603), Time: 170.61s\n",
            "Iter: 15800/100000, Smooth Loss: 1.9331, Min Smooth Loss: 1.9304 (iter 15603), Time: 171.04s\n",
            "Iter: 15900/100000, Smooth Loss: 1.9330, Min Smooth Loss: 1.9290 (iter 15849), Time: 171.42s\n",
            "  Starting new chunk 42/101 (indices 408647-418614) e_ptr=408647\n",
            "Iter: 16000/100000, Smooth Loss: 1.9387, Min Smooth Loss: 1.9290 (iter 15849), Time: 171.82s\n",
            "  Validation Loss at iter 16000: 1.9303\n",
            "Iter: 16100/100000, Smooth Loss: 1.9399, Min Smooth Loss: 1.9290 (iter 15849), Time: 179.44s\n",
            "Iter: 16200/100000, Smooth Loss: 1.9331, Min Smooth Loss: 1.9290 (iter 15849), Time: 179.83s\n",
            "Iter: 16300/100000, Smooth Loss: 1.9374, Min Smooth Loss: 1.9290 (iter 15849), Time: 180.23s\n",
            "  Starting new chunk 43/101 (indices 259142-269109) e_ptr=259142\n",
            "Iter: 16400/100000, Smooth Loss: 1.9337, Min Smooth Loss: 1.9290 (iter 15849), Time: 180.65s\n",
            "Iter: 16500/100000, Smooth Loss: 1.9287, Min Smooth Loss: 1.9283 (iter 16496), Time: 181.05s\n",
            "Iter: 16600/100000, Smooth Loss: 1.9494, Min Smooth Loss: 1.9283 (iter 16496), Time: 181.44s\n",
            "Iter: 16700/100000, Smooth Loss: 1.9592, Min Smooth Loss: 1.9283 (iter 16496), Time: 181.86s\n",
            "  Starting new chunk 44/101 (indices 29901-39868) e_ptr=29901\n",
            "Iter: 16800/100000, Smooth Loss: 1.9565, Min Smooth Loss: 1.9283 (iter 16496), Time: 182.26s\n",
            "Iter: 16900/100000, Smooth Loss: 1.9541, Min Smooth Loss: 1.9283 (iter 16496), Time: 182.68s\n",
            "Iter: 17000/100000, Smooth Loss: 1.9424, Min Smooth Loss: 1.9283 (iter 16496), Time: 183.06s\n",
            "  Validation Loss at iter 17000: 1.9364\n",
            "Iter: 17100/100000, Smooth Loss: 1.9447, Min Smooth Loss: 1.9283 (iter 16496), Time: 190.69s\n",
            "  Starting new chunk 45/101 (indices 737558-747525) e_ptr=737558\n",
            "Iter: 17200/100000, Smooth Loss: 1.9422, Min Smooth Loss: 1.9283 (iter 16496), Time: 191.10s\n",
            "Iter: 17300/100000, Smooth Loss: 1.9318, Min Smooth Loss: 1.9283 (iter 16496), Time: 191.49s\n",
            "Iter: 17400/100000, Smooth Loss: 1.9218, Min Smooth Loss: 1.9216 (iter 17399), Time: 191.89s\n",
            "Iter: 17500/100000, Smooth Loss: 1.9142, Min Smooth Loss: 1.9139 (iter 17444), Time: 192.29s\n",
            "  Starting new chunk 46/101 (indices 308977-318944) e_ptr=308977\n",
            "Iter: 17600/100000, Smooth Loss: 1.9106, Min Smooth Loss: 1.9106 (iter 17600), Time: 192.69s\n",
            "Iter: 17700/100000, Smooth Loss: 1.9157, Min Smooth Loss: 1.9092 (iter 17605), Time: 193.09s\n",
            "Iter: 17800/100000, Smooth Loss: 1.9155, Min Smooth Loss: 1.9092 (iter 17605), Time: 193.49s\n",
            "Iter: 17900/100000, Smooth Loss: 1.9110, Min Smooth Loss: 1.9092 (iter 17605), Time: 193.89s\n",
            "  Starting new chunk 47/101 (indices 99670-109637) e_ptr=99670\n",
            "Iter: 18000/100000, Smooth Loss: 1.9115, Min Smooth Loss: 1.9092 (iter 17605), Time: 194.31s\n",
            "  Validation Loss at iter 18000: 1.9084\n",
            "Iter: 18100/100000, Smooth Loss: 1.9152, Min Smooth Loss: 1.9092 (iter 17605), Time: 201.72s\n",
            "Iter: 18200/100000, Smooth Loss: 1.9136, Min Smooth Loss: 1.9092 (iter 17605), Time: 202.35s\n",
            "Iter: 18300/100000, Smooth Loss: 1.9108, Min Smooth Loss: 1.9092 (iter 17605), Time: 202.89s\n",
            "  Starting new chunk 48/101 (indices 468449-478416) e_ptr=468449\n",
            "Iter: 18400/100000, Smooth Loss: 1.9101, Min Smooth Loss: 1.9087 (iter 18306), Time: 203.27s\n",
            "Iter: 18500/100000, Smooth Loss: 1.9126, Min Smooth Loss: 1.9087 (iter 18306), Time: 203.70s\n",
            "Iter: 18600/100000, Smooth Loss: 1.9024, Min Smooth Loss: 1.9016 (iter 18583), Time: 204.10s\n",
            "Iter: 18700/100000, Smooth Loss: 1.8986, Min Smooth Loss: 1.8981 (iter 18639), Time: 204.48s\n",
            "  Starting new chunk 49/101 (indices 418614-428581) e_ptr=418614\n",
            "Iter: 18800/100000, Smooth Loss: 1.8936, Min Smooth Loss: 1.8936 (iter 18800), Time: 204.89s\n",
            "Iter: 18900/100000, Smooth Loss: 1.8817, Min Smooth Loss: 1.8817 (iter 18900), Time: 205.28s\n",
            "Iter: 19000/100000, Smooth Loss: 1.8782, Min Smooth Loss: 1.8770 (iter 18976), Time: 205.70s\n",
            "  Validation Loss at iter 19000: 1.8928\n",
            "Iter: 19100/100000, Smooth Loss: 1.8716, Min Smooth Loss: 1.8709 (iter 19099), Time: 212.29s\n",
            "  Starting new chunk 50/101 (indices 169439-179406) e_ptr=169439\n",
            "Iter: 19200/100000, Smooth Loss: 1.8817, Min Smooth Loss: 1.8709 (iter 19099), Time: 212.70s\n",
            "Iter: 19300/100000, Smooth Loss: 1.8860, Min Smooth Loss: 1.8709 (iter 19099), Time: 213.31s\n",
            "Iter: 19400/100000, Smooth Loss: 1.8869, Min Smooth Loss: 1.8709 (iter 19099), Time: 213.92s\n",
            "Iter: 19500/100000, Smooth Loss: 1.8819, Min Smooth Loss: 1.8709 (iter 19099), Time: 214.51s\n",
            "  Starting new chunk 51/101 (indices 189373-199340) e_ptr=189373\n",
            "Iter: 19600/100000, Smooth Loss: 1.8767, Min Smooth Loss: 1.8709 (iter 19099), Time: 215.13s\n",
            "Iter: 19700/100000, Smooth Loss: 1.8676, Min Smooth Loss: 1.8674 (iter 19673), Time: 215.77s\n",
            "Iter: 19800/100000, Smooth Loss: 1.8591, Min Smooth Loss: 1.8591 (iter 19800), Time: 216.19s\n",
            "Iter: 19900/100000, Smooth Loss: 1.8510, Min Smooth Loss: 1.8503 (iter 19890), Time: 216.60s\n",
            "  Starting new chunk 52/101 (indices 847195-857162) e_ptr=847195\n",
            "Iter: 20000/100000, Smooth Loss: 1.8559, Min Smooth Loss: 1.8503 (iter 19890), Time: 216.99s\n",
            "  Validation Loss at iter 20000: 1.9102\n",
            "--- Synthesized text at iter 20000 (using current model) ---\n",
            "lant, buche ere liir Crost real had look a oreasat of  RUn't wagll intoun the Dumbledore?  Dosched and aboto ro hat hour a trouncly. Dimbledry a gon Dquialsutlins Ein's cwas Cineting to the them wutcr\n",
            "---\n",
            "Iter: 20100/100000, Smooth Loss: 1.8453, Min Smooth Loss: 1.8453 (iter 20100), Time: 223.64s\n",
            "Iter: 20200/100000, Smooth Loss: 1.8369, Min Smooth Loss: 1.8365 (iter 20196), Time: 224.07s\n",
            "Iter: 20300/100000, Smooth Loss: 1.8198, Min Smooth Loss: 1.8191 (iter 20295), Time: 224.47s\n",
            "  Starting new chunk 53/101 (indices 478416-488383) e_ptr=478416\n",
            "Iter: 20400/100000, Smooth Loss: 1.8284, Min Smooth Loss: 1.8191 (iter 20295), Time: 224.87s\n",
            "Iter: 20500/100000, Smooth Loss: 1.8196, Min Smooth Loss: 1.8191 (iter 20295), Time: 225.26s\n",
            "Iter: 20600/100000, Smooth Loss: 1.8179, Min Smooth Loss: 1.8170 (iter 20561), Time: 225.67s\n",
            "  Starting new chunk 54/101 (indices 627921-637888) e_ptr=627921\n",
            "Iter: 20700/100000, Smooth Loss: 1.8167, Min Smooth Loss: 1.8128 (iter 20679), Time: 226.23s\n",
            "Iter: 20800/100000, Smooth Loss: 1.8358, Min Smooth Loss: 1.8128 (iter 20679), Time: 226.88s\n",
            "Iter: 20900/100000, Smooth Loss: 1.8361, Min Smooth Loss: 1.8128 (iter 20679), Time: 227.49s\n",
            "Iter: 21000/100000, Smooth Loss: 1.8320, Min Smooth Loss: 1.8128 (iter 20679), Time: 228.19s\n",
            "  Validation Loss at iter 21000: 1.8776\n",
            "  Starting new chunk 55/101 (indices 388713-398680) e_ptr=388713\n",
            "Iter: 21100/100000, Smooth Loss: 1.8277, Min Smooth Loss: 1.8128 (iter 20679), Time: 234.93s\n",
            "Iter: 21200/100000, Smooth Loss: 1.8363, Min Smooth Loss: 1.8128 (iter 20679), Time: 235.34s\n",
            "Iter: 21300/100000, Smooth Loss: 1.8330, Min Smooth Loss: 1.8128 (iter 20679), Time: 235.75s\n",
            "Iter: 21400/100000, Smooth Loss: 1.8397, Min Smooth Loss: 1.8128 (iter 20679), Time: 236.13s\n",
            "  Starting new chunk 56/101 (indices 149505-159472) e_ptr=149505\n",
            "Iter: 21500/100000, Smooth Loss: 1.8413, Min Smooth Loss: 1.8128 (iter 20679), Time: 236.54s\n",
            "Iter: 21600/100000, Smooth Loss: 1.8532, Min Smooth Loss: 1.8128 (iter 20679), Time: 236.92s\n",
            "Iter: 21700/100000, Smooth Loss: 1.8621, Min Smooth Loss: 1.8128 (iter 20679), Time: 237.31s\n",
            "Iter: 21800/100000, Smooth Loss: 1.8620, Min Smooth Loss: 1.8128 (iter 20679), Time: 237.72s\n",
            "  Starting new chunk 57/101 (indices 897030-906997) e_ptr=897030\n",
            "Iter: 21900/100000, Smooth Loss: 1.8855, Min Smooth Loss: 1.8128 (iter 20679), Time: 238.11s\n",
            "Iter: 22000/100000, Smooth Loss: 1.8915, Min Smooth Loss: 1.8128 (iter 20679), Time: 238.53s\n",
            "  Validation Loss at iter 22000: 1.8782\n",
            "Iter: 22100/100000, Smooth Loss: 1.8781, Min Smooth Loss: 1.8128 (iter 20679), Time: 246.20s\n",
            "Iter: 22200/100000, Smooth Loss: 1.8707, Min Smooth Loss: 1.8128 (iter 20679), Time: 246.61s\n",
            "  Starting new chunk 58/101 (indices 857162-867129) e_ptr=857162\n",
            "Iter: 22300/100000, Smooth Loss: 1.8619, Min Smooth Loss: 1.8128 (iter 20679), Time: 247.04s\n",
            "Iter: 22400/100000, Smooth Loss: 1.8521, Min Smooth Loss: 1.8128 (iter 20679), Time: 247.44s\n",
            "Iter: 22500/100000, Smooth Loss: 1.8473, Min Smooth Loss: 1.8128 (iter 20679), Time: 247.87s\n",
            "Iter: 22600/100000, Smooth Loss: 1.8381, Min Smooth Loss: 1.8128 (iter 20679), Time: 248.28s\n",
            "  Starting new chunk 59/101 (indices 777426-787393) e_ptr=777426\n",
            "Iter: 22700/100000, Smooth Loss: 1.8416, Min Smooth Loss: 1.8128 (iter 20679), Time: 248.70s\n",
            "Iter: 22800/100000, Smooth Loss: 1.8353, Min Smooth Loss: 1.8128 (iter 20679), Time: 249.11s\n",
            "Iter: 22900/100000, Smooth Loss: 1.8268, Min Smooth Loss: 1.8128 (iter 20679), Time: 249.51s\n",
            "Iter: 23000/100000, Smooth Loss: 1.8257, Min Smooth Loss: 1.8128 (iter 20679), Time: 249.91s\n",
            "  Validation Loss at iter 23000: 1.8450\n",
            "  Starting new chunk 60/101 (indices 946865-956832) e_ptr=946865\n",
            "Iter: 23100/100000, Smooth Loss: 1.8272, Min Smooth Loss: 1.8128 (iter 20679), Time: 257.87s\n",
            "Iter: 23200/100000, Smooth Loss: 1.8340, Min Smooth Loss: 1.8128 (iter 20679), Time: 258.32s\n",
            "Iter: 23300/100000, Smooth Loss: 1.8402, Min Smooth Loss: 1.8128 (iter 20679), Time: 258.79s\n",
            "Iter: 23400/100000, Smooth Loss: 1.8358, Min Smooth Loss: 1.8128 (iter 20679), Time: 259.20s\n",
            "  Starting new chunk 61/101 (indices 976766-986733) e_ptr=976766\n",
            "Iter: 23500/100000, Smooth Loss: 1.8246, Min Smooth Loss: 1.8128 (iter 20679), Time: 259.61s\n",
            "Iter: 23600/100000, Smooth Loss: 1.8311, Min Smooth Loss: 1.8128 (iter 20679), Time: 260.03s\n",
            "Iter: 23700/100000, Smooth Loss: 1.8328, Min Smooth Loss: 1.8128 (iter 20679), Time: 260.43s\n",
            "Iter: 23800/100000, Smooth Loss: 1.8328, Min Smooth Loss: 1.8128 (iter 20679), Time: 260.88s\n",
            "  Starting new chunk 62/101 (indices 438548-448515) e_ptr=438548\n",
            "Iter: 23900/100000, Smooth Loss: 1.8301, Min Smooth Loss: 1.8128 (iter 20679), Time: 261.28s\n",
            "Iter: 24000/100000, Smooth Loss: 1.8386, Min Smooth Loss: 1.8128 (iter 20679), Time: 261.70s\n",
            "  Validation Loss at iter 24000: 1.8137\n",
            "Iter: 24100/100000, Smooth Loss: 1.8355, Min Smooth Loss: 1.8128 (iter 20679), Time: 269.88s\n",
            "Iter: 24200/100000, Smooth Loss: 1.8469, Min Smooth Loss: 1.8128 (iter 20679), Time: 270.30s\n",
            "  Starting new chunk 63/101 (indices 358812-368779) e_ptr=358812\n",
            "Iter: 24300/100000, Smooth Loss: 1.8477, Min Smooth Loss: 1.8128 (iter 20679), Time: 270.72s\n",
            "Iter: 24400/100000, Smooth Loss: 1.8488, Min Smooth Loss: 1.8128 (iter 20679), Time: 271.10s\n",
            "Iter: 24500/100000, Smooth Loss: 1.8543, Min Smooth Loss: 1.8128 (iter 20679), Time: 271.52s\n",
            "Iter: 24600/100000, Smooth Loss: 1.8487, Min Smooth Loss: 1.8128 (iter 20679), Time: 271.92s\n",
            "  Starting new chunk 64/101 (indices 877096-887063) e_ptr=877096\n",
            "Iter: 24700/100000, Smooth Loss: 1.8448, Min Smooth Loss: 1.8128 (iter 20679), Time: 272.32s\n",
            "Iter: 24800/100000, Smooth Loss: 1.8356, Min Smooth Loss: 1.8128 (iter 20679), Time: 272.75s\n",
            "Iter: 24900/100000, Smooth Loss: 1.8169, Min Smooth Loss: 1.8128 (iter 20679), Time: 273.16s\n",
            "Iter: 25000/100000, Smooth Loss: 1.7997, Min Smooth Loss: 1.7997 (iter 25000), Time: 273.58s\n",
            "  Validation Loss at iter 25000: 1.8422\n",
            "  Starting new chunk 65/101 (indices 926931-936898) e_ptr=926931\n",
            "Iter: 25100/100000, Smooth Loss: 1.7980, Min Smooth Loss: 1.7954 (iter 25074), Time: 281.59s\n",
            "Iter: 25200/100000, Smooth Loss: 1.7951, Min Smooth Loss: 1.7944 (iter 25174), Time: 282.03s\n",
            "Iter: 25300/100000, Smooth Loss: 1.7912, Min Smooth Loss: 1.7897 (iter 25293), Time: 282.43s\n",
            "Iter: 25400/100000, Smooth Loss: 1.7859, Min Smooth Loss: 1.7859 (iter 25400), Time: 282.83s\n",
            "  Starting new chunk 66/101 (indices 538218-548185) e_ptr=538218\n",
            "Iter: 25500/100000, Smooth Loss: 1.7884, Min Smooth Loss: 1.7838 (iter 25449), Time: 283.25s\n",
            "Iter: 25600/100000, Smooth Loss: 1.7846, Min Smooth Loss: 1.7838 (iter 25449), Time: 283.66s\n",
            "Iter: 25700/100000, Smooth Loss: 1.7818, Min Smooth Loss: 1.7818 (iter 25700), Time: 284.09s\n",
            "Iter: 25800/100000, Smooth Loss: 1.7840, Min Smooth Loss: 1.7778 (iter 25776), Time: 284.48s\n",
            "  Starting new chunk 67/101 (indices 488383-498350) e_ptr=488383\n",
            "Iter: 25900/100000, Smooth Loss: 1.7800, Min Smooth Loss: 1.7778 (iter 25776), Time: 284.89s\n",
            "Iter: 26000/100000, Smooth Loss: 1.7843, Min Smooth Loss: 1.7778 (iter 25776), Time: 285.32s\n",
            "  Validation Loss at iter 26000: 1.8272\n",
            "Iter: 26100/100000, Smooth Loss: 1.7887, Min Smooth Loss: 1.7778 (iter 25776), Time: 292.46s\n",
            "Iter: 26200/100000, Smooth Loss: 1.7788, Min Smooth Loss: 1.7778 (iter 25776), Time: 293.06s\n",
            "  Starting new chunk 68/101 (indices 578086-588053) e_ptr=578086\n",
            "Iter: 26300/100000, Smooth Loss: 1.7876, Min Smooth Loss: 1.7778 (iter 25776), Time: 293.70s\n",
            "Iter: 26400/100000, Smooth Loss: 1.7947, Min Smooth Loss: 1.7778 (iter 25776), Time: 294.34s\n",
            "Iter: 26500/100000, Smooth Loss: 1.7871, Min Smooth Loss: 1.7778 (iter 25776), Time: 294.85s\n",
            "Iter: 26600/100000, Smooth Loss: 1.7861, Min Smooth Loss: 1.7778 (iter 25776), Time: 295.24s\n",
            "  Starting new chunk 69/101 (indices 827261-837228) e_ptr=827261\n",
            "Iter: 26700/100000, Smooth Loss: 1.7916, Min Smooth Loss: 1.7778 (iter 25776), Time: 295.66s\n",
            "Iter: 26800/100000, Smooth Loss: 1.7926, Min Smooth Loss: 1.7778 (iter 25776), Time: 296.05s\n",
            "Iter: 26900/100000, Smooth Loss: 1.7865, Min Smooth Loss: 1.7778 (iter 25776), Time: 296.44s\n",
            "Iter: 27000/100000, Smooth Loss: 1.7853, Min Smooth Loss: 1.7778 (iter 25776), Time: 296.86s\n",
            "  Validation Loss at iter 27000: 1.8017\n",
            "  Starting new chunk 70/101 (indices 179406-189373) e_ptr=179406\n",
            "Iter: 27100/100000, Smooth Loss: 1.7757, Min Smooth Loss: 1.7755 (iter 27081), Time: 303.33s\n",
            "Iter: 27200/100000, Smooth Loss: 1.7718, Min Smooth Loss: 1.7709 (iter 27190), Time: 303.73s\n",
            "Iter: 27300/100000, Smooth Loss: 1.7676, Min Smooth Loss: 1.7676 (iter 27300), Time: 304.15s\n",
            "Iter: 27400/100000, Smooth Loss: 1.7661, Min Smooth Loss: 1.7659 (iter 27392), Time: 304.54s\n",
            "  Starting new chunk 71/101 (indices 837228-847195) e_ptr=837228\n",
            "Iter: 27500/100000, Smooth Loss: 1.7597, Min Smooth Loss: 1.7591 (iter 27499), Time: 305.17s\n",
            "Iter: 27600/100000, Smooth Loss: 1.7606, Min Smooth Loss: 1.7552 (iter 27572), Time: 305.76s\n",
            "Iter: 27700/100000, Smooth Loss: 1.7463, Min Smooth Loss: 1.7463 (iter 27699), Time: 306.38s\n",
            "Iter: 27800/100000, Smooth Loss: 1.7325, Min Smooth Loss: 1.7325 (iter 27796), Time: 306.99s\n",
            "  Starting new chunk 72/101 (indices 797360-807327) e_ptr=797360\n",
            "Iter: 27900/100000, Smooth Loss: 1.7286, Min Smooth Loss: 1.7253 (iter 27848), Time: 307.64s\n",
            "Iter: 28000/100000, Smooth Loss: 1.7337, Min Smooth Loss: 1.7253 (iter 27848), Time: 308.05s\n",
            "  Validation Loss at iter 28000: 1.8082\n",
            "Iter: 28100/100000, Smooth Loss: 1.7314, Min Smooth Loss: 1.7253 (iter 27848), Time: 314.49s\n",
            "Iter: 28200/100000, Smooth Loss: 1.7364, Min Smooth Loss: 1.7253 (iter 27848), Time: 314.89s\n",
            "  Starting new chunk 73/101 (indices 368779-378746) e_ptr=368779\n",
            "Iter: 28300/100000, Smooth Loss: 1.7347, Min Smooth Loss: 1.7253 (iter 27848), Time: 315.28s\n",
            "Iter: 28400/100000, Smooth Loss: 1.7361, Min Smooth Loss: 1.7253 (iter 27848), Time: 315.69s\n",
            "Iter: 28500/100000, Smooth Loss: 1.7340, Min Smooth Loss: 1.7253 (iter 27848), Time: 316.08s\n",
            "Iter: 28600/100000, Smooth Loss: 1.7378, Min Smooth Loss: 1.7253 (iter 27848), Time: 316.48s\n",
            "  Starting new chunk 74/101 (indices 0-9967) e_ptr=0\n",
            "Iter: 28700/100000, Smooth Loss: 1.7465, Min Smooth Loss: 1.7253 (iter 27848), Time: 316.91s\n",
            "Iter: 28800/100000, Smooth Loss: 1.7601, Min Smooth Loss: 1.7253 (iter 27848), Time: 317.32s\n",
            "Iter: 28900/100000, Smooth Loss: 1.7644, Min Smooth Loss: 1.7253 (iter 27848), Time: 317.83s\n",
            "Iter: 29000/100000, Smooth Loss: 1.7618, Min Smooth Loss: 1.7253 (iter 27848), Time: 318.44s\n",
            "  Validation Loss at iter 29000: 1.8490\n",
            "  Starting new chunk 75/101 (indices 677756-687723) e_ptr=677756\n",
            "Iter: 29100/100000, Smooth Loss: 1.7660, Min Smooth Loss: 1.7253 (iter 27848), Time: 325.75s\n",
            "Iter: 29200/100000, Smooth Loss: 1.7577, Min Smooth Loss: 1.7253 (iter 27848), Time: 326.14s\n",
            "Iter: 29300/100000, Smooth Loss: 1.7551, Min Smooth Loss: 1.7253 (iter 27848), Time: 326.55s\n",
            "Iter: 29400/100000, Smooth Loss: 1.7690, Min Smooth Loss: 1.7253 (iter 27848), Time: 326.93s\n",
            "  Starting new chunk 76/101 (indices 199340-209307) e_ptr=199340\n",
            "Iter: 29500/100000, Smooth Loss: 1.7800, Min Smooth Loss: 1.7253 (iter 27848), Time: 327.33s\n",
            "Iter: 29600/100000, Smooth Loss: 1.7818, Min Smooth Loss: 1.7253 (iter 27848), Time: 327.72s\n",
            "Iter: 29700/100000, Smooth Loss: 1.7771, Min Smooth Loss: 1.7253 (iter 27848), Time: 328.11s\n",
            "Iter: 29800/100000, Smooth Loss: 1.7708, Min Smooth Loss: 1.7253 (iter 27848), Time: 328.52s\n",
            "  Starting new chunk 77/101 (indices 707657-717624) e_ptr=707657\n",
            "Iter: 29900/100000, Smooth Loss: 1.7722, Min Smooth Loss: 1.7253 (iter 27848), Time: 328.91s\n",
            "Iter: 30000/100000, Smooth Loss: 1.7762, Min Smooth Loss: 1.7253 (iter 27848), Time: 329.29s\n",
            "  Validation Loss at iter 30000: 1.7966\n",
            "--- Synthesized text at iter 30000 (using current model) ---\n",
            "Sny slace, with her sume the has repelily, wis emberoa hand, look. \"A' Sures ty at Snoply.  fou Malony, his chor mussed his neach bewast dovel do as. .......\n",
            "Gost thing, buf saggory.  \"So same on inad\n",
            "---\n",
            "Iter: 30100/100000, Smooth Loss: 1.7701, Min Smooth Loss: 1.7253 (iter 27848), Time: 337.03s\n",
            "Iter: 30200/100000, Smooth Loss: 1.7608, Min Smooth Loss: 1.7253 (iter 27848), Time: 337.44s\n",
            "  Starting new chunk 78/101 (indices 249175-259142) e_ptr=249175\n",
            "Iter: 30300/100000, Smooth Loss: 1.7668, Min Smooth Loss: 1.7253 (iter 27848), Time: 337.84s\n",
            "Iter: 30400/100000, Smooth Loss: 1.7759, Min Smooth Loss: 1.7253 (iter 27848), Time: 338.24s\n",
            "Iter: 30500/100000, Smooth Loss: 1.7775, Min Smooth Loss: 1.7253 (iter 27848), Time: 338.64s\n",
            "Iter: 30600/100000, Smooth Loss: 1.7893, Min Smooth Loss: 1.7253 (iter 27848), Time: 339.05s\n",
            "  Starting new chunk 79/101 (indices 348845-358812) e_ptr=348845\n",
            "Iter: 30700/100000, Smooth Loss: 1.7895, Min Smooth Loss: 1.7253 (iter 27848), Time: 339.45s\n",
            "Iter: 30800/100000, Smooth Loss: 1.8126, Min Smooth Loss: 1.7253 (iter 27848), Time: 339.84s\n",
            "Iter: 30900/100000, Smooth Loss: 1.8141, Min Smooth Loss: 1.7253 (iter 27848), Time: 340.25s\n",
            "Iter: 31000/100000, Smooth Loss: 1.8178, Min Smooth Loss: 1.7253 (iter 27848), Time: 340.66s\n",
            "  Validation Loss at iter 31000: 1.7912\n",
            "  Starting new chunk 80/101 (indices 807327-817294) e_ptr=807327\n",
            "Iter: 31100/100000, Smooth Loss: 1.8094, Min Smooth Loss: 1.7253 (iter 27848), Time: 348.40s\n",
            "Iter: 31200/100000, Smooth Loss: 1.7997, Min Smooth Loss: 1.7253 (iter 27848), Time: 348.81s\n",
            "Iter: 31300/100000, Smooth Loss: 1.7915, Min Smooth Loss: 1.7253 (iter 27848), Time: 349.21s\n",
            "Iter: 31400/100000, Smooth Loss: 1.7867, Min Smooth Loss: 1.7253 (iter 27848), Time: 349.61s\n",
            "  Starting new chunk 81/101 (indices 89703-99670) e_ptr=89703\n",
            "Iter: 31500/100000, Smooth Loss: 1.7955, Min Smooth Loss: 1.7253 (iter 27848), Time: 350.01s\n",
            "Iter: 31600/100000, Smooth Loss: 1.7998, Min Smooth Loss: 1.7253 (iter 27848), Time: 350.40s\n",
            "Iter: 31700/100000, Smooth Loss: 1.8036, Min Smooth Loss: 1.7253 (iter 27848), Time: 350.82s\n",
            "Iter: 31800/100000, Smooth Loss: 1.8012, Min Smooth Loss: 1.7253 (iter 27848), Time: 351.20s\n",
            "  Starting new chunk 82/101 (indices 69769-79736) e_ptr=69769\n",
            "Iter: 31900/100000, Smooth Loss: 1.7929, Min Smooth Loss: 1.7253 (iter 27848), Time: 351.61s\n",
            "Iter: 32000/100000, Smooth Loss: 1.7848, Min Smooth Loss: 1.7253 (iter 27848), Time: 351.99s\n",
            "  Validation Loss at iter 32000: 1.7966\n",
            "Iter: 32100/100000, Smooth Loss: 1.7827, Min Smooth Loss: 1.7253 (iter 27848), Time: 359.36s\n",
            "Iter: 32200/100000, Smooth Loss: 1.7782, Min Smooth Loss: 1.7253 (iter 27848), Time: 359.97s\n",
            "  Starting new chunk 83/101 (indices 757492-767459) e_ptr=757492\n",
            "Iter: 32300/100000, Smooth Loss: 1.7654, Min Smooth Loss: 1.7253 (iter 27848), Time: 360.37s\n",
            "Iter: 32400/100000, Smooth Loss: 1.7697, Min Smooth Loss: 1.7253 (iter 27848), Time: 360.76s\n",
            "Iter: 32500/100000, Smooth Loss: 1.7716, Min Smooth Loss: 1.7253 (iter 27848), Time: 361.16s\n",
            "Iter: 32600/100000, Smooth Loss: 1.7753, Min Smooth Loss: 1.7253 (iter 27848), Time: 361.54s\n",
            "  Starting new chunk 84/101 (indices 787393-797360) e_ptr=787393\n",
            "Iter: 32700/100000, Smooth Loss: 1.7772, Min Smooth Loss: 1.7253 (iter 27848), Time: 361.92s\n",
            "Iter: 32800/100000, Smooth Loss: 1.7629, Min Smooth Loss: 1.7253 (iter 27848), Time: 362.32s\n",
            "Iter: 32900/100000, Smooth Loss: 1.7552, Min Smooth Loss: 1.7253 (iter 27848), Time: 362.72s\n",
            "Iter: 33000/100000, Smooth Loss: 1.7534, Min Smooth Loss: 1.7253 (iter 27848), Time: 363.11s\n",
            "  Validation Loss at iter 33000: 1.7821\n",
            "  Starting new chunk 85/101 (indices 637888-647855) e_ptr=637888\n",
            "Iter: 33100/100000, Smooth Loss: 1.7542, Min Smooth Loss: 1.7253 (iter 27848), Time: 369.65s\n",
            "Iter: 33200/100000, Smooth Loss: 1.7609, Min Smooth Loss: 1.7253 (iter 27848), Time: 370.12s\n",
            "Iter: 33300/100000, Smooth Loss: 1.7654, Min Smooth Loss: 1.7253 (iter 27848), Time: 370.76s\n",
            "Iter: 33400/100000, Smooth Loss: 1.7657, Min Smooth Loss: 1.7253 (iter 27848), Time: 371.37s\n",
            "  Starting new chunk 86/101 (indices 458482-468449) e_ptr=458482\n",
            "Iter: 33500/100000, Smooth Loss: 1.7659, Min Smooth Loss: 1.7253 (iter 27848), Time: 372.00s\n",
            "Iter: 33600/100000, Smooth Loss: 1.7712, Min Smooth Loss: 1.7253 (iter 27848), Time: 372.64s\n",
            "Iter: 33700/100000, Smooth Loss: 1.7704, Min Smooth Loss: 1.7253 (iter 27848), Time: 373.20s\n",
            "Iter: 33800/100000, Smooth Loss: 1.7678, Min Smooth Loss: 1.7253 (iter 27848), Time: 373.60s\n",
            "  Starting new chunk 87/101 (indices 269109-279076) e_ptr=269109\n",
            "Iter: 33900/100000, Smooth Loss: 1.7702, Min Smooth Loss: 1.7253 (iter 27848), Time: 374.01s\n",
            "Iter: 34000/100000, Smooth Loss: 1.7736, Min Smooth Loss: 1.7253 (iter 27848), Time: 374.42s\n",
            "  Validation Loss at iter 34000: 1.7831\n",
            "Iter: 34100/100000, Smooth Loss: 1.7778, Min Smooth Loss: 1.7253 (iter 27848), Time: 381.04s\n",
            "Iter: 34200/100000, Smooth Loss: 1.7731, Min Smooth Loss: 1.7253 (iter 27848), Time: 381.46s\n",
            "  Starting new chunk 88/101 (indices 906997-916964) e_ptr=906997\n",
            "Iter: 34300/100000, Smooth Loss: 1.7678, Min Smooth Loss: 1.7253 (iter 27848), Time: 381.84s\n",
            "Iter: 34400/100000, Smooth Loss: 1.7603, Min Smooth Loss: 1.7253 (iter 27848), Time: 382.25s\n",
            "Iter: 34500/100000, Smooth Loss: 1.7388, Min Smooth Loss: 1.7253 (iter 27848), Time: 382.64s\n",
            "Iter: 34600/100000, Smooth Loss: 1.7359, Min Smooth Loss: 1.7253 (iter 27848), Time: 383.02s\n",
            "  Starting new chunk 89/101 (indices 328911-338878) e_ptr=328911\n",
            "Iter: 34700/100000, Smooth Loss: 1.7333, Min Smooth Loss: 1.7253 (iter 27848), Time: 383.65s\n",
            "Iter: 34800/100000, Smooth Loss: 1.7371, Min Smooth Loss: 1.7253 (iter 27848), Time: 384.25s\n",
            "Iter: 34900/100000, Smooth Loss: 1.7414, Min Smooth Loss: 1.7253 (iter 27848), Time: 384.86s\n",
            "Iter: 35000/100000, Smooth Loss: 1.7424, Min Smooth Loss: 1.7253 (iter 27848), Time: 385.51s\n",
            "  Validation Loss at iter 35000: 1.7733\n",
            "  Starting new chunk 90/101 (indices 209307-219274) e_ptr=209307\n",
            "Iter: 35100/100000, Smooth Loss: 1.7279, Min Smooth Loss: 1.7253 (iter 27848), Time: 392.44s\n",
            "Iter: 35200/100000, Smooth Loss: 1.7172, Min Smooth Loss: 1.7168 (iter 35183), Time: 392.85s\n",
            "Iter: 35300/100000, Smooth Loss: 1.7158, Min Smooth Loss: 1.7158 (iter 35300), Time: 393.24s\n",
            "Iter: 35400/100000, Smooth Loss: 1.7240, Min Smooth Loss: 1.7126 (iter 35319), Time: 393.63s\n",
            "  Starting new chunk 91/101 (indices 428581-438548) e_ptr=428581\n",
            "Iter: 35500/100000, Smooth Loss: 1.7286, Min Smooth Loss: 1.7126 (iter 35319), Time: 394.05s\n",
            "Iter: 35600/100000, Smooth Loss: 1.7249, Min Smooth Loss: 1.7126 (iter 35319), Time: 394.42s\n",
            "Iter: 35700/100000, Smooth Loss: 1.7143, Min Smooth Loss: 1.7126 (iter 35319), Time: 394.83s\n",
            "Iter: 35800/100000, Smooth Loss: 1.7132, Min Smooth Loss: 1.7109 (iter 35793), Time: 395.22s\n",
            "  Starting new chunk 92/101 (indices 219274-229241) e_ptr=219274\n",
            "Iter: 35900/100000, Smooth Loss: 1.7318, Min Smooth Loss: 1.7109 (iter 35793), Time: 395.62s\n",
            "Iter: 36000/100000, Smooth Loss: 1.7254, Min Smooth Loss: 1.7109 (iter 35793), Time: 396.02s\n",
            "  Validation Loss at iter 36000: 1.7538\n",
            "Iter: 36100/100000, Smooth Loss: 1.7217, Min Smooth Loss: 1.7109 (iter 35793), Time: 403.82s\n",
            "Iter: 36200/100000, Smooth Loss: 1.7349, Min Smooth Loss: 1.7109 (iter 35793), Time: 404.22s\n",
            "  Starting new chunk 93/101 (indices 398680-408647) e_ptr=398680\n",
            "Iter: 36300/100000, Smooth Loss: 1.7309, Min Smooth Loss: 1.7109 (iter 35793), Time: 404.63s\n",
            "Iter: 36400/100000, Smooth Loss: 1.7347, Min Smooth Loss: 1.7109 (iter 35793), Time: 405.02s\n",
            "Iter: 36500/100000, Smooth Loss: 1.7333, Min Smooth Loss: 1.7109 (iter 35793), Time: 405.41s\n",
            "Iter: 36600/100000, Smooth Loss: 1.7194, Min Smooth Loss: 1.7109 (iter 35793), Time: 405.83s\n",
            "  Starting new chunk 94/101 (indices 558152-568119) e_ptr=558152\n",
            "Iter: 36700/100000, Smooth Loss: 1.7243, Min Smooth Loss: 1.7109 (iter 35793), Time: 406.24s\n",
            "Iter: 36800/100000, Smooth Loss: 1.7313, Min Smooth Loss: 1.7109 (iter 35793), Time: 406.69s\n",
            "Iter: 36900/100000, Smooth Loss: 1.7256, Min Smooth Loss: 1.7109 (iter 35793), Time: 407.09s\n",
            "Iter: 37000/100000, Smooth Loss: 1.7268, Min Smooth Loss: 1.7109 (iter 35793), Time: 407.53s\n",
            "  Validation Loss at iter 37000: 1.7506\n",
            "  Starting new chunk 95/101 (indices 767459-777426) e_ptr=767459\n",
            "Iter: 37100/100000, Smooth Loss: 1.7321, Min Smooth Loss: 1.7109 (iter 35793), Time: 415.54s\n",
            "Iter: 37200/100000, Smooth Loss: 1.7482, Min Smooth Loss: 1.7109 (iter 35793), Time: 415.96s\n",
            "Iter: 37300/100000, Smooth Loss: 1.7468, Min Smooth Loss: 1.7109 (iter 35793), Time: 416.38s\n",
            "Iter: 37400/100000, Smooth Loss: 1.7491, Min Smooth Loss: 1.7109 (iter 35793), Time: 416.80s\n",
            "  Starting new chunk 96/101 (indices 717624-727591) e_ptr=717624\n",
            "Iter: 37500/100000, Smooth Loss: 1.7439, Min Smooth Loss: 1.7109 (iter 35793), Time: 417.23s\n",
            "Iter: 37600/100000, Smooth Loss: 1.7408, Min Smooth Loss: 1.7109 (iter 35793), Time: 417.68s\n",
            "Iter: 37700/100000, Smooth Loss: 1.7314, Min Smooth Loss: 1.7109 (iter 35793), Time: 418.14s\n",
            "Iter: 37800/100000, Smooth Loss: 1.7395, Min Smooth Loss: 1.7109 (iter 35793), Time: 418.58s\n",
            "  Starting new chunk 97/101 (indices 986733-996700) e_ptr=986733\n",
            "Iter: 37900/100000, Smooth Loss: 1.7546, Min Smooth Loss: 1.7109 (iter 35793), Time: 418.98s\n",
            "Iter: 38000/100000, Smooth Loss: 1.7535, Min Smooth Loss: 1.7109 (iter 35793), Time: 419.39s\n",
            "  Validation Loss at iter 38000: 1.7421\n",
            "Iter: 38100/100000, Smooth Loss: 1.7471, Min Smooth Loss: 1.7109 (iter 35793), Time: 427.01s\n",
            "Iter: 38200/100000, Smooth Loss: 1.7346, Min Smooth Loss: 1.7109 (iter 35793), Time: 427.41s\n",
            "  Starting new chunk 98/101 (indices 229241-239208) e_ptr=229241\n",
            "Iter: 38300/100000, Smooth Loss: 1.7400, Min Smooth Loss: 1.7109 (iter 35793), Time: 427.82s\n",
            "Iter: 38400/100000, Smooth Loss: 1.7476, Min Smooth Loss: 1.7109 (iter 35793), Time: 428.21s\n",
            "Iter: 38500/100000, Smooth Loss: 1.7455, Min Smooth Loss: 1.7109 (iter 35793), Time: 428.61s\n",
            "Iter: 38600/100000, Smooth Loss: 1.7448, Min Smooth Loss: 1.7109 (iter 35793), Time: 429.01s\n",
            "  Starting new chunk 99/101 (indices 817294-827261) e_ptr=817294\n",
            "Iter: 38700/100000, Smooth Loss: 1.7523, Min Smooth Loss: 1.7109 (iter 35793), Time: 429.40s\n",
            "Iter: 38800/100000, Smooth Loss: 1.7542, Min Smooth Loss: 1.7109 (iter 35793), Time: 429.82s\n",
            "Iter: 38900/100000, Smooth Loss: 1.7497, Min Smooth Loss: 1.7109 (iter 35793), Time: 430.21s\n",
            "Iter: 39000/100000, Smooth Loss: 1.7507, Min Smooth Loss: 1.7109 (iter 35793), Time: 430.62s\n",
            "  Validation Loss at iter 39000: 1.7486\n",
            "  Starting new chunk 100/101 (indices 548185-558152) e_ptr=548185\n",
            "Iter: 39100/100000, Smooth Loss: 1.7528, Min Smooth Loss: 1.7109 (iter 35793), Time: 438.24s\n",
            "Iter: 39200/100000, Smooth Loss: 1.7524, Min Smooth Loss: 1.7109 (iter 35793), Time: 438.81s\n",
            "Iter: 39300/100000, Smooth Loss: 1.7567, Min Smooth Loss: 1.7109 (iter 35793), Time: 439.21s\n",
            "Iter: 39400/100000, Smooth Loss: 1.7525, Min Smooth Loss: 1.7109 (iter 35793), Time: 439.63s\n",
            "  Starting new chunk 101/101 (indices 318944-328911) e_ptr=318944\n",
            "Iter: 39500/100000, Smooth Loss: 1.7523, Min Smooth Loss: 1.7109 (iter 35793), Time: 440.00s\n",
            "Iter: 39600/100000, Smooth Loss: 1.7503, Min Smooth Loss: 1.7109 (iter 35793), Time: 440.41s\n",
            "Iter: 39700/100000, Smooth Loss: 1.7498, Min Smooth Loss: 1.7109 (iter 35793), Time: 440.81s\n",
            "Iter: 39800/100000, Smooth Loss: 1.7380, Min Smooth Loss: 1.7109 (iter 35793), Time: 441.19s\n",
            "All 101 chunks processed. Reshuffling chunks.\n",
            "  Starting new chunk 1/101 (indices 139538-149505) e_ptr=139538\n",
            "Iter: 39900/100000, Smooth Loss: 1.7438, Min Smooth Loss: 1.7109 (iter 35793), Time: 441.62s\n",
            "Iter: 40000/100000, Smooth Loss: 1.7489, Min Smooth Loss: 1.7109 (iter 35793), Time: 442.01s\n",
            "  Validation Loss at iter 40000: 1.7696\n",
            "--- Synthesized text at iter 40000 (using current model) ---\n",
            "taig in the Briwidg fins wigh lef.  Mn.\n",
            "Nexise kit prote llodevaia amm ane - Ar I theirial hurrione of gor.  The Own.\n",
            "Lush wair?\"\n",
            "Ron'te and from the That thun again will who had it, hape appainyfer a\n",
            "---\n",
            "Iter: 40100/100000, Smooth Loss: 1.7462, Min Smooth Loss: 1.7109 (iter 35793), Time: 448.53s\n",
            "Iter: 40200/100000, Smooth Loss: 1.7453, Min Smooth Loss: 1.7109 (iter 35793), Time: 449.07s\n",
            "  Starting new chunk 2/101 (indices 318944-328911) e_ptr=318944\n",
            "Iter: 40300/100000, Smooth Loss: 1.7331, Min Smooth Loss: 1.7109 (iter 35793), Time: 449.69s\n",
            "Iter: 40400/100000, Smooth Loss: 1.7234, Min Smooth Loss: 1.7109 (iter 35793), Time: 450.31s\n",
            "Iter: 40500/100000, Smooth Loss: 1.7161, Min Smooth Loss: 1.7109 (iter 35793), Time: 450.95s\n",
            "  Starting new chunk 3/101 (indices 717624-727591) e_ptr=717624\n",
            "Iter: 40600/100000, Smooth Loss: 1.7017, Min Smooth Loss: 1.7017 (iter 40600), Time: 451.59s\n",
            "Iter: 40700/100000, Smooth Loss: 1.6937, Min Smooth Loss: 1.6937 (iter 40700), Time: 452.06s\n",
            "Iter: 40800/100000, Smooth Loss: 1.6939, Min Smooth Loss: 1.6937 (iter 40700), Time: 452.46s\n",
            "Iter: 40900/100000, Smooth Loss: 1.6893, Min Smooth Loss: 1.6841 (iter 40874), Time: 452.88s\n",
            "  Starting new chunk 4/101 (indices 598020-607987) e_ptr=598020\n",
            "Iter: 41000/100000, Smooth Loss: 1.6968, Min Smooth Loss: 1.6841 (iter 40874), Time: 453.28s\n",
            "  Validation Loss at iter 41000: 1.7515\n",
            "Iter: 41100/100000, Smooth Loss: 1.6949, Min Smooth Loss: 1.6841 (iter 40874), Time: 460.29s\n",
            "Iter: 41200/100000, Smooth Loss: 1.6837, Min Smooth Loss: 1.6831 (iter 41191), Time: 460.75s\n",
            "Iter: 41300/100000, Smooth Loss: 1.6955, Min Smooth Loss: 1.6807 (iter 41223), Time: 461.15s\n",
            "  Starting new chunk 5/101 (indices 398680-408647) e_ptr=398680\n",
            "Iter: 41400/100000, Smooth Loss: 1.7141, Min Smooth Loss: 1.6807 (iter 41223), Time: 461.59s\n",
            "Iter: 41500/100000, Smooth Loss: 1.7074, Min Smooth Loss: 1.6807 (iter 41223), Time: 462.14s\n",
            "Iter: 41600/100000, Smooth Loss: 1.7100, Min Smooth Loss: 1.6807 (iter 41223), Time: 462.77s\n",
            "Iter: 41700/100000, Smooth Loss: 1.7028, Min Smooth Loss: 1.6807 (iter 41223), Time: 463.39s\n",
            "  Starting new chunk 6/101 (indices 358812-368779) e_ptr=358812\n",
            "Iter: 41800/100000, Smooth Loss: 1.6900, Min Smooth Loss: 1.6807 (iter 41223), Time: 464.02s\n",
            "Iter: 41900/100000, Smooth Loss: 1.6969, Min Smooth Loss: 1.6807 (iter 41223), Time: 464.64s\n",
            "Iter: 42000/100000, Smooth Loss: 1.7093, Min Smooth Loss: 1.6807 (iter 41223), Time: 465.14s\n",
            "  Validation Loss at iter 42000: 1.7447\n",
            "Iter: 42100/100000, Smooth Loss: 1.7060, Min Smooth Loss: 1.6807 (iter 41223), Time: 471.91s\n",
            "  Starting new chunk 7/101 (indices 249175-259142) e_ptr=249175\n",
            "Iter: 42200/100000, Smooth Loss: 1.7117, Min Smooth Loss: 1.6807 (iter 41223), Time: 472.32s\n",
            "Iter: 42300/100000, Smooth Loss: 1.7247, Min Smooth Loss: 1.6807 (iter 41223), Time: 472.71s\n",
            "Iter: 42400/100000, Smooth Loss: 1.7249, Min Smooth Loss: 1.6807 (iter 41223), Time: 473.12s\n",
            "Iter: 42500/100000, Smooth Loss: 1.7261, Min Smooth Loss: 1.6807 (iter 41223), Time: 473.51s\n",
            "  Starting new chunk 8/101 (indices 737558-747525) e_ptr=737558\n",
            "Iter: 42600/100000, Smooth Loss: 1.7294, Min Smooth Loss: 1.6807 (iter 41223), Time: 473.91s\n",
            "Iter: 42700/100000, Smooth Loss: 1.7252, Min Smooth Loss: 1.6807 (iter 41223), Time: 474.31s\n",
            "Iter: 42800/100000, Smooth Loss: 1.7171, Min Smooth Loss: 1.6807 (iter 41223), Time: 474.70s\n",
            "Iter: 42900/100000, Smooth Loss: 1.7112, Min Smooth Loss: 1.6807 (iter 41223), Time: 475.21s\n",
            "  Starting new chunk 9/101 (indices 528251-538218) e_ptr=528251\n",
            "Iter: 43000/100000, Smooth Loss: 1.7162, Min Smooth Loss: 1.6807 (iter 41223), Time: 475.82s\n",
            "  Validation Loss at iter 43000: 1.7558\n",
            "Iter: 43100/100000, Smooth Loss: 1.7166, Min Smooth Loss: 1.6807 (iter 41223), Time: 483.08s\n",
            "Iter: 43200/100000, Smooth Loss: 1.7138, Min Smooth Loss: 1.6807 (iter 41223), Time: 483.48s\n",
            "Iter: 43300/100000, Smooth Loss: 1.7163, Min Smooth Loss: 1.6807 (iter 41223), Time: 483.90s\n",
            "  Starting new chunk 10/101 (indices 637888-647855) e_ptr=637888\n",
            "Iter: 43400/100000, Smooth Loss: 1.7134, Min Smooth Loss: 1.6807 (iter 41223), Time: 484.31s\n",
            "Iter: 43500/100000, Smooth Loss: 1.7198, Min Smooth Loss: 1.6807 (iter 41223), Time: 484.72s\n",
            "Iter: 43600/100000, Smooth Loss: 1.7238, Min Smooth Loss: 1.6807 (iter 41223), Time: 485.12s\n",
            "Iter: 43700/100000, Smooth Loss: 1.7301, Min Smooth Loss: 1.6807 (iter 41223), Time: 485.50s\n",
            "  Starting new chunk 11/101 (indices 617954-627921) e_ptr=617954\n",
            "Iter: 43800/100000, Smooth Loss: 1.7222, Min Smooth Loss: 1.6807 (iter 41223), Time: 485.91s\n",
            "Iter: 43900/100000, Smooth Loss: 1.7173, Min Smooth Loss: 1.6807 (iter 41223), Time: 486.29s\n",
            "Iter: 44000/100000, Smooth Loss: 1.7108, Min Smooth Loss: 1.6807 (iter 41223), Time: 486.70s\n",
            "  Validation Loss at iter 44000: 1.7497\n",
            "Iter: 44100/100000, Smooth Loss: 1.7137, Min Smooth Loss: 1.6807 (iter 41223), Time: 494.34s\n",
            "  Starting new chunk 12/101 (indices 817294-827261) e_ptr=817294\n",
            "Iter: 44200/100000, Smooth Loss: 1.7193, Min Smooth Loss: 1.6807 (iter 41223), Time: 494.74s\n",
            "Iter: 44300/100000, Smooth Loss: 1.7200, Min Smooth Loss: 1.6807 (iter 41223), Time: 495.14s\n",
            "Iter: 44400/100000, Smooth Loss: 1.7180, Min Smooth Loss: 1.6807 (iter 41223), Time: 495.56s\n",
            "Iter: 44500/100000, Smooth Loss: 1.7127, Min Smooth Loss: 1.6807 (iter 41223), Time: 495.96s\n",
            "  Starting new chunk 13/101 (indices 299010-308977) e_ptr=299010\n",
            "Iter: 44600/100000, Smooth Loss: 1.7170, Min Smooth Loss: 1.6807 (iter 41223), Time: 496.40s\n",
            "Iter: 44700/100000, Smooth Loss: 1.7211, Min Smooth Loss: 1.6807 (iter 41223), Time: 496.82s\n",
            "Iter: 44800/100000, Smooth Loss: 1.7320, Min Smooth Loss: 1.6807 (iter 41223), Time: 497.23s\n",
            "Iter: 44900/100000, Smooth Loss: 1.7279, Min Smooth Loss: 1.6807 (iter 41223), Time: 497.70s\n",
            "  Starting new chunk 14/101 (indices 289043-299010) e_ptr=289043\n",
            "Iter: 45000/100000, Smooth Loss: 1.7236, Min Smooth Loss: 1.6807 (iter 41223), Time: 498.17s\n",
            "  Validation Loss at iter 45000: 1.7425\n",
            "Iter: 45100/100000, Smooth Loss: 1.7365, Min Smooth Loss: 1.6807 (iter 41223), Time: 506.07s\n",
            "Iter: 45200/100000, Smooth Loss: 1.7476, Min Smooth Loss: 1.6807 (iter 41223), Time: 506.46s\n",
            "Iter: 45300/100000, Smooth Loss: 1.7415, Min Smooth Loss: 1.6807 (iter 41223), Time: 506.86s\n",
            "  Starting new chunk 15/101 (indices 259142-269109) e_ptr=259142\n",
            "Iter: 45400/100000, Smooth Loss: 1.7433, Min Smooth Loss: 1.6807 (iter 41223), Time: 507.27s\n",
            "Iter: 45500/100000, Smooth Loss: 1.7398, Min Smooth Loss: 1.6807 (iter 41223), Time: 507.68s\n",
            "Iter: 45600/100000, Smooth Loss: 1.7481, Min Smooth Loss: 1.6807 (iter 41223), Time: 508.14s\n",
            "Iter: 45700/100000, Smooth Loss: 1.7623, Min Smooth Loss: 1.6807 (iter 41223), Time: 508.57s\n",
            "  Starting new chunk 16/101 (indices 79736-89703) e_ptr=79736\n",
            "Iter: 45800/100000, Smooth Loss: 1.7663, Min Smooth Loss: 1.6807 (iter 41223), Time: 508.97s\n",
            "Iter: 45900/100000, Smooth Loss: 1.7678, Min Smooth Loss: 1.6807 (iter 41223), Time: 509.38s\n",
            "Iter: 46000/100000, Smooth Loss: 1.7636, Min Smooth Loss: 1.6807 (iter 41223), Time: 509.76s\n",
            "  Validation Loss at iter 46000: 1.7496\n",
            "Iter: 46100/100000, Smooth Loss: 1.7532, Min Smooth Loss: 1.6807 (iter 41223), Time: 517.45s\n",
            "  Starting new chunk 17/101 (indices 548185-558152) e_ptr=548185\n",
            "Iter: 46200/100000, Smooth Loss: 1.7509, Min Smooth Loss: 1.6807 (iter 41223), Time: 517.88s\n",
            "Iter: 46300/100000, Smooth Loss: 1.7438, Min Smooth Loss: 1.6807 (iter 41223), Time: 518.29s\n",
            "Iter: 46400/100000, Smooth Loss: 1.7431, Min Smooth Loss: 1.6807 (iter 41223), Time: 518.72s\n",
            "Iter: 46500/100000, Smooth Loss: 1.7418, Min Smooth Loss: 1.6807 (iter 41223), Time: 519.13s\n",
            "  Starting new chunk 18/101 (indices 279076-289043) e_ptr=279076\n",
            "Iter: 46600/100000, Smooth Loss: 1.7421, Min Smooth Loss: 1.6807 (iter 41223), Time: 519.53s\n",
            "Iter: 46700/100000, Smooth Loss: 1.7412, Min Smooth Loss: 1.6807 (iter 41223), Time: 519.94s\n",
            "Iter: 46800/100000, Smooth Loss: 1.7314, Min Smooth Loss: 1.6807 (iter 41223), Time: 520.34s\n",
            "Iter: 46900/100000, Smooth Loss: 1.7373, Min Smooth Loss: 1.6807 (iter 41223), Time: 520.76s\n",
            "  Starting new chunk 19/101 (indices 847195-857162) e_ptr=847195\n",
            "Iter: 47000/100000, Smooth Loss: 1.7410, Min Smooth Loss: 1.6807 (iter 41223), Time: 521.16s\n",
            "  Validation Loss at iter 47000: 1.7324\n",
            "Iter: 47100/100000, Smooth Loss: 1.7385, Min Smooth Loss: 1.6807 (iter 41223), Time: 527.89s\n",
            "Iter: 47200/100000, Smooth Loss: 1.7179, Min Smooth Loss: 1.6807 (iter 41223), Time: 528.53s\n",
            "Iter: 47300/100000, Smooth Loss: 1.7064, Min Smooth Loss: 1.6807 (iter 41223), Time: 529.11s\n",
            "  Starting new chunk 20/101 (indices 916964-926931) e_ptr=916964\n",
            "Iter: 47400/100000, Smooth Loss: 1.6934, Min Smooth Loss: 1.6807 (iter 41223), Time: 529.73s\n",
            "Iter: 47500/100000, Smooth Loss: 1.6917, Min Smooth Loss: 1.6807 (iter 41223), Time: 530.36s\n",
            "Iter: 47600/100000, Smooth Loss: 1.7042, Min Smooth Loss: 1.6807 (iter 41223), Time: 530.81s\n",
            "Iter: 47700/100000, Smooth Loss: 1.7120, Min Smooth Loss: 1.6807 (iter 41223), Time: 531.24s\n",
            "  Starting new chunk 21/101 (indices 986733-996700) e_ptr=986733\n",
            "Iter: 47800/100000, Smooth Loss: 1.7149, Min Smooth Loss: 1.6807 (iter 41223), Time: 531.64s\n",
            "Iter: 47900/100000, Smooth Loss: 1.7247, Min Smooth Loss: 1.6807 (iter 41223), Time: 532.04s\n",
            "Iter: 48000/100000, Smooth Loss: 1.7157, Min Smooth Loss: 1.6807 (iter 41223), Time: 532.45s\n",
            "  Validation Loss at iter 48000: 1.7176\n",
            "Iter: 48100/100000, Smooth Loss: 1.7072, Min Smooth Loss: 1.6807 (iter 41223), Time: 538.92s\n",
            "  Starting new chunk 22/101 (indices 797360-807327) e_ptr=797360\n",
            "Iter: 48200/100000, Smooth Loss: 1.7010, Min Smooth Loss: 1.6807 (iter 41223), Time: 539.30s\n",
            "Iter: 48300/100000, Smooth Loss: 1.6990, Min Smooth Loss: 1.6807 (iter 41223), Time: 539.71s\n",
            "Iter: 48400/100000, Smooth Loss: 1.6912, Min Smooth Loss: 1.6807 (iter 41223), Time: 540.10s\n",
            "Iter: 48500/100000, Smooth Loss: 1.6890, Min Smooth Loss: 1.6807 (iter 41223), Time: 540.51s\n",
            "  Starting new chunk 23/101 (indices 209307-219274) e_ptr=209307\n",
            "Iter: 48600/100000, Smooth Loss: 1.6765, Min Smooth Loss: 1.6765 (iter 48600), Time: 541.16s\n",
            "Iter: 48700/100000, Smooth Loss: 1.6662, Min Smooth Loss: 1.6658 (iter 48698), Time: 541.79s\n",
            "Iter: 48800/100000, Smooth Loss: 1.6609, Min Smooth Loss: 1.6602 (iter 48798), Time: 542.40s\n",
            "Iter: 48900/100000, Smooth Loss: 1.6606, Min Smooth Loss: 1.6541 (iter 48851), Time: 543.02s\n",
            "  Starting new chunk 24/101 (indices 388713-398680) e_ptr=388713\n",
            "Iter: 49000/100000, Smooth Loss: 1.6719, Min Smooth Loss: 1.6541 (iter 48851), Time: 543.63s\n",
            "  Validation Loss at iter 49000: 1.7198\n",
            "Iter: 49100/100000, Smooth Loss: 1.6757, Min Smooth Loss: 1.6541 (iter 48851), Time: 550.08s\n",
            "Iter: 49200/100000, Smooth Loss: 1.6804, Min Smooth Loss: 1.6541 (iter 48851), Time: 550.51s\n",
            "Iter: 49300/100000, Smooth Loss: 1.6830, Min Smooth Loss: 1.6541 (iter 48851), Time: 550.90s\n",
            "  Starting new chunk 25/101 (indices 378746-388713) e_ptr=378746\n",
            "Iter: 49400/100000, Smooth Loss: 1.6898, Min Smooth Loss: 1.6541 (iter 48851), Time: 551.32s\n",
            "Iter: 49500/100000, Smooth Loss: 1.6865, Min Smooth Loss: 1.6541 (iter 48851), Time: 551.73s\n",
            "Iter: 49600/100000, Smooth Loss: 1.6785, Min Smooth Loss: 1.6541 (iter 48851), Time: 552.13s\n",
            "Iter: 49700/100000, Smooth Loss: 1.6703, Min Smooth Loss: 1.6541 (iter 48851), Time: 552.55s\n",
            "  Starting new chunk 26/101 (indices 89703-99670) e_ptr=89703\n",
            "Iter: 49800/100000, Smooth Loss: 1.6722, Min Smooth Loss: 1.6541 (iter 48851), Time: 552.94s\n",
            "Iter: 49900/100000, Smooth Loss: 1.6759, Min Smooth Loss: 1.6541 (iter 48851), Time: 553.35s\n",
            "Iter: 50000/100000, Smooth Loss: 1.6837, Min Smooth Loss: 1.6541 (iter 48851), Time: 553.85s\n",
            "  Validation Loss at iter 50000: 1.7101\n",
            "--- Synthesized text at iter 50000 (using current model) ---\n",
            "hrem looked al a neylows from Barkly, and I wolkiane.  Betthemonam..  The lisiand was eyily of the Gentthales, \"Bet I causs you ale Lefully, asmesting the Grofge awound he's worke what had ext,\" said \n",
            "---\n",
            "Iter: 50100/100000, Smooth Loss: 1.6834, Min Smooth Loss: 1.6541 (iter 48851), Time: 561.36s\n",
            "  Starting new chunk 27/101 (indices 269109-279076) e_ptr=269109\n",
            "Iter: 50200/100000, Smooth Loss: 1.6832, Min Smooth Loss: 1.6541 (iter 48851), Time: 561.76s\n",
            "Iter: 50300/100000, Smooth Loss: 1.6896, Min Smooth Loss: 1.6541 (iter 48851), Time: 562.18s\n",
            "Iter: 50400/100000, Smooth Loss: 1.6952, Min Smooth Loss: 1.6541 (iter 48851), Time: 562.56s\n",
            "Iter: 50500/100000, Smooth Loss: 1.6893, Min Smooth Loss: 1.6541 (iter 48851), Time: 562.97s\n",
            "  Starting new chunk 28/101 (indices 877096-887063) e_ptr=877096\n",
            "Iter: 50600/100000, Smooth Loss: 1.6886, Min Smooth Loss: 1.6541 (iter 48851), Time: 563.38s\n",
            "Iter: 50700/100000, Smooth Loss: 1.6835, Min Smooth Loss: 1.6541 (iter 48851), Time: 563.79s\n",
            "Iter: 50800/100000, Smooth Loss: 1.6692, Min Smooth Loss: 1.6541 (iter 48851), Time: 564.21s\n",
            "Iter: 50900/100000, Smooth Loss: 1.6600, Min Smooth Loss: 1.6541 (iter 48851), Time: 564.62s\n",
            "  Starting new chunk 29/101 (indices 538218-548185) e_ptr=538218\n",
            "Iter: 51000/100000, Smooth Loss: 1.6613, Min Smooth Loss: 1.6541 (iter 48851), Time: 565.03s\n",
            "  Validation Loss at iter 51000: 1.6950\n",
            "Iter: 51100/100000, Smooth Loss: 1.6602, Min Smooth Loss: 1.6541 (iter 48851), Time: 572.66s\n",
            "Iter: 51200/100000, Smooth Loss: 1.6571, Min Smooth Loss: 1.6541 (iter 48851), Time: 573.06s\n",
            "Iter: 51300/100000, Smooth Loss: 1.6552, Min Smooth Loss: 1.6541 (iter 48851), Time: 573.48s\n",
            "  Starting new chunk 30/101 (indices 747525-757492) e_ptr=747525\n",
            "Iter: 51400/100000, Smooth Loss: 1.6593, Min Smooth Loss: 1.6536 (iter 51336), Time: 573.87s\n",
            "Iter: 51500/100000, Smooth Loss: 1.6683, Min Smooth Loss: 1.6536 (iter 51336), Time: 574.26s\n",
            "Iter: 51600/100000, Smooth Loss: 1.6674, Min Smooth Loss: 1.6536 (iter 51336), Time: 574.69s\n",
            "Iter: 51700/100000, Smooth Loss: 1.6611, Min Smooth Loss: 1.6536 (iter 51336), Time: 575.09s\n",
            "  Starting new chunk 31/101 (indices 308977-318944) e_ptr=308977\n",
            "Iter: 51800/100000, Smooth Loss: 1.6562, Min Smooth Loss: 1.6536 (iter 51336), Time: 575.50s\n",
            "Iter: 51900/100000, Smooth Loss: 1.6629, Min Smooth Loss: 1.6536 (iter 51336), Time: 575.93s\n",
            "Iter: 52000/100000, Smooth Loss: 1.6724, Min Smooth Loss: 1.6536 (iter 51336), Time: 576.33s\n",
            "  Validation Loss at iter 52000: 1.6986\n",
            "Iter: 52100/100000, Smooth Loss: 1.6728, Min Smooth Loss: 1.6536 (iter 51336), Time: 583.95s\n",
            "  Starting new chunk 32/101 (indices 348845-358812) e_ptr=348845\n",
            "Iter: 52200/100000, Smooth Loss: 1.6771, Min Smooth Loss: 1.6536 (iter 51336), Time: 584.37s\n",
            "Iter: 52300/100000, Smooth Loss: 1.7084, Min Smooth Loss: 1.6536 (iter 51336), Time: 584.78s\n",
            "Iter: 52400/100000, Smooth Loss: 1.7061, Min Smooth Loss: 1.6536 (iter 51336), Time: 585.19s\n",
            "Iter: 52500/100000, Smooth Loss: 1.7099, Min Smooth Loss: 1.6536 (iter 51336), Time: 585.58s\n",
            "  Starting new chunk 33/101 (indices 687723-697690) e_ptr=687723\n",
            "Iter: 52600/100000, Smooth Loss: 1.7153, Min Smooth Loss: 1.6536 (iter 51336), Time: 585.97s\n",
            "Iter: 52700/100000, Smooth Loss: 1.7211, Min Smooth Loss: 1.6536 (iter 51336), Time: 586.39s\n",
            "Iter: 52800/100000, Smooth Loss: 1.7203, Min Smooth Loss: 1.6536 (iter 51336), Time: 586.81s\n",
            "Iter: 52900/100000, Smooth Loss: 1.7234, Min Smooth Loss: 1.6536 (iter 51336), Time: 587.23s\n",
            "  Starting new chunk 34/101 (indices 49835-59802) e_ptr=49835\n",
            "Iter: 53000/100000, Smooth Loss: 1.7234, Min Smooth Loss: 1.6536 (iter 51336), Time: 587.68s\n",
            "  Validation Loss at iter 53000: 1.7243\n",
            "Iter: 53100/100000, Smooth Loss: 1.7134, Min Smooth Loss: 1.6536 (iter 51336), Time: 595.00s\n",
            "Iter: 53200/100000, Smooth Loss: 1.7222, Min Smooth Loss: 1.6536 (iter 51336), Time: 595.62s\n",
            "Iter: 53300/100000, Smooth Loss: 1.7245, Min Smooth Loss: 1.6536 (iter 51336), Time: 596.14s\n",
            "  Starting new chunk 35/101 (indices 518284-528251) e_ptr=518284\n",
            "Iter: 53400/100000, Smooth Loss: 1.7230, Min Smooth Loss: 1.6536 (iter 51336), Time: 596.53s\n",
            "Iter: 53500/100000, Smooth Loss: 1.7160, Min Smooth Loss: 1.6536 (iter 51336), Time: 596.94s\n",
            "Iter: 53600/100000, Smooth Loss: 1.7017, Min Smooth Loss: 1.6536 (iter 51336), Time: 597.33s\n",
            "Iter: 53700/100000, Smooth Loss: 1.7038, Min Smooth Loss: 1.6536 (iter 51336), Time: 597.72s\n",
            "  Starting new chunk 36/101 (indices 996700-996787) e_ptr=996700\n",
            "  Starting new chunk 37/101 (indices 926931-936898) e_ptr=926931\n",
            "Iter: 53800/100000, Smooth Loss: 1.6955, Min Smooth Loss: 1.6536 (iter 51336), Time: 598.14s\n",
            "Iter: 53900/100000, Smooth Loss: 1.6837, Min Smooth Loss: 1.6536 (iter 51336), Time: 598.54s\n",
            "Iter: 54000/100000, Smooth Loss: 1.6777, Min Smooth Loss: 1.6536 (iter 51336), Time: 598.96s\n",
            "  Validation Loss at iter 54000: 1.6914\n",
            "Iter: 54100/100000, Smooth Loss: 1.6669, Min Smooth Loss: 1.6536 (iter 51336), Time: 605.41s\n",
            "  Starting new chunk 38/101 (indices 219274-229241) e_ptr=219274\n",
            "Iter: 54200/100000, Smooth Loss: 1.6762, Min Smooth Loss: 1.6536 (iter 51336), Time: 605.81s\n",
            "Iter: 54300/100000, Smooth Loss: 1.6733, Min Smooth Loss: 1.6536 (iter 51336), Time: 606.43s\n",
            "Iter: 54400/100000, Smooth Loss: 1.6695, Min Smooth Loss: 1.6536 (iter 51336), Time: 607.06s\n",
            "Iter: 54500/100000, Smooth Loss: 1.6792, Min Smooth Loss: 1.6536 (iter 51336), Time: 607.72s\n",
            "  Starting new chunk 39/101 (indices 9967-19934) e_ptr=9967\n",
            "Iter: 54600/100000, Smooth Loss: 1.6894, Min Smooth Loss: 1.6536 (iter 51336), Time: 608.42s\n",
            "Iter: 54700/100000, Smooth Loss: 1.6976, Min Smooth Loss: 1.6536 (iter 51336), Time: 609.06s\n",
            "Iter: 54800/100000, Smooth Loss: 1.6977, Min Smooth Loss: 1.6536 (iter 51336), Time: 609.47s\n",
            "Iter: 54900/100000, Smooth Loss: 1.7014, Min Smooth Loss: 1.6536 (iter 51336), Time: 609.85s\n",
            "  Starting new chunk 40/101 (indices 657822-667789) e_ptr=657822\n",
            "Iter: 55000/100000, Smooth Loss: 1.7214, Min Smooth Loss: 1.6536 (iter 51336), Time: 610.23s\n",
            "  Validation Loss at iter 55000: 1.7270\n",
            "Iter: 55100/100000, Smooth Loss: 1.7396, Min Smooth Loss: 1.6536 (iter 51336), Time: 616.75s\n",
            "Iter: 55200/100000, Smooth Loss: 1.7308, Min Smooth Loss: 1.6536 (iter 51336), Time: 617.14s\n",
            "Iter: 55300/100000, Smooth Loss: 1.7218, Min Smooth Loss: 1.6536 (iter 51336), Time: 617.56s\n",
            "  Starting new chunk 41/101 (indices 827261-837228) e_ptr=827261\n",
            "Iter: 55400/100000, Smooth Loss: 1.7223, Min Smooth Loss: 1.6536 (iter 51336), Time: 617.96s\n",
            "Iter: 55500/100000, Smooth Loss: 1.7140, Min Smooth Loss: 1.6536 (iter 51336), Time: 618.35s\n",
            "Iter: 55600/100000, Smooth Loss: 1.7050, Min Smooth Loss: 1.6536 (iter 51336), Time: 618.77s\n",
            "Iter: 55700/100000, Smooth Loss: 1.6983, Min Smooth Loss: 1.6536 (iter 51336), Time: 619.26s\n",
            "  Starting new chunk 42/101 (indices 936898-946865) e_ptr=936898\n",
            "Iter: 55800/100000, Smooth Loss: 1.6877, Min Smooth Loss: 1.6536 (iter 51336), Time: 619.85s\n",
            "Iter: 55900/100000, Smooth Loss: 1.6881, Min Smooth Loss: 1.6536 (iter 51336), Time: 620.45s\n",
            "Iter: 56000/100000, Smooth Loss: 1.6814, Min Smooth Loss: 1.6536 (iter 51336), Time: 621.09s\n",
            "  Validation Loss at iter 56000: 1.7049\n",
            "Iter: 56100/100000, Smooth Loss: 1.6815, Min Smooth Loss: 1.6536 (iter 51336), Time: 627.91s\n",
            "  Starting new chunk 43/101 (indices 458482-468449) e_ptr=458482\n",
            "Iter: 56200/100000, Smooth Loss: 1.6789, Min Smooth Loss: 1.6536 (iter 51336), Time: 628.29s\n",
            "Iter: 56300/100000, Smooth Loss: 1.6830, Min Smooth Loss: 1.6536 (iter 51336), Time: 628.70s\n",
            "Iter: 56400/100000, Smooth Loss: 1.6799, Min Smooth Loss: 1.6536 (iter 51336), Time: 629.08s\n",
            "Iter: 56500/100000, Smooth Loss: 1.6766, Min Smooth Loss: 1.6536 (iter 51336), Time: 629.48s\n",
            "  Starting new chunk 44/101 (indices 159472-169439) e_ptr=159472\n",
            "Iter: 56600/100000, Smooth Loss: 1.6963, Min Smooth Loss: 1.6536 (iter 51336), Time: 629.86s\n",
            "Iter: 56700/100000, Smooth Loss: 1.7150, Min Smooth Loss: 1.6536 (iter 51336), Time: 630.25s\n",
            "Iter: 56800/100000, Smooth Loss: 1.7207, Min Smooth Loss: 1.6536 (iter 51336), Time: 630.66s\n",
            "Iter: 56900/100000, Smooth Loss: 1.7246, Min Smooth Loss: 1.6536 (iter 51336), Time: 631.05s\n",
            "  Starting new chunk 45/101 (indices 647855-657822) e_ptr=647855\n",
            "Iter: 57000/100000, Smooth Loss: 1.7218, Min Smooth Loss: 1.6536 (iter 51336), Time: 631.43s\n",
            "  Validation Loss at iter 57000: 1.6970\n",
            "Iter: 57100/100000, Smooth Loss: 1.7241, Min Smooth Loss: 1.6536 (iter 51336), Time: 639.01s\n",
            "Iter: 57200/100000, Smooth Loss: 1.7146, Min Smooth Loss: 1.6536 (iter 51336), Time: 639.40s\n",
            "Iter: 57300/100000, Smooth Loss: 1.7121, Min Smooth Loss: 1.6536 (iter 51336), Time: 639.80s\n",
            "  Starting new chunk 46/101 (indices 129571-139538) e_ptr=129571\n",
            "Iter: 57400/100000, Smooth Loss: 1.7202, Min Smooth Loss: 1.6536 (iter 51336), Time: 640.20s\n",
            "Iter: 57500/100000, Smooth Loss: 1.7266, Min Smooth Loss: 1.6536 (iter 51336), Time: 640.60s\n",
            "Iter: 57600/100000, Smooth Loss: 1.7256, Min Smooth Loss: 1.6536 (iter 51336), Time: 640.98s\n",
            "Iter: 57700/100000, Smooth Loss: 1.7296, Min Smooth Loss: 1.6536 (iter 51336), Time: 641.38s\n",
            "  Starting new chunk 47/101 (indices 667789-677756) e_ptr=667789\n",
            "Iter: 57800/100000, Smooth Loss: 1.7209, Min Smooth Loss: 1.6536 (iter 51336), Time: 641.76s\n",
            "Iter: 57900/100000, Smooth Loss: 1.7126, Min Smooth Loss: 1.6536 (iter 51336), Time: 642.17s\n",
            "Iter: 58000/100000, Smooth Loss: 1.7013, Min Smooth Loss: 1.6536 (iter 51336), Time: 642.55s\n",
            "  Validation Loss at iter 58000: 1.6952\n",
            "Iter: 58100/100000, Smooth Loss: 1.7028, Min Smooth Loss: 1.6536 (iter 51336), Time: 650.17s\n",
            "  Starting new chunk 48/101 (indices 29901-39868) e_ptr=29901\n",
            "Iter: 58200/100000, Smooth Loss: 1.7029, Min Smooth Loss: 1.6536 (iter 51336), Time: 650.57s\n",
            "Iter: 58300/100000, Smooth Loss: 1.7014, Min Smooth Loss: 1.6536 (iter 51336), Time: 650.96s\n",
            "Iter: 58400/100000, Smooth Loss: 1.6943, Min Smooth Loss: 1.6536 (iter 51336), Time: 651.35s\n",
            "Iter: 58500/100000, Smooth Loss: 1.7018, Min Smooth Loss: 1.6536 (iter 51336), Time: 651.76s\n",
            "  Starting new chunk 49/101 (indices 837228-847195) e_ptr=837228\n",
            "Iter: 58600/100000, Smooth Loss: 1.6937, Min Smooth Loss: 1.6536 (iter 51336), Time: 652.14s\n",
            "Iter: 58700/100000, Smooth Loss: 1.6861, Min Smooth Loss: 1.6536 (iter 51336), Time: 652.53s\n",
            "Iter: 58800/100000, Smooth Loss: 1.6657, Min Smooth Loss: 1.6536 (iter 51336), Time: 652.93s\n",
            "Iter: 58900/100000, Smooth Loss: 1.6516, Min Smooth Loss: 1.6510 (iter 58895), Time: 653.32s\n",
            "  Starting new chunk 50/101 (indices 757492-767459) e_ptr=757492\n",
            "Iter: 59000/100000, Smooth Loss: 1.6516, Min Smooth Loss: 1.6483 (iter 58970), Time: 653.72s\n",
            "  Validation Loss at iter 59000: 1.6774\n",
            "Iter: 59100/100000, Smooth Loss: 1.6515, Min Smooth Loss: 1.6483 (iter 58970), Time: 661.40s\n",
            "Iter: 59200/100000, Smooth Loss: 1.6594, Min Smooth Loss: 1.6483 (iter 58970), Time: 661.79s\n",
            "Iter: 59300/100000, Smooth Loss: 1.6598, Min Smooth Loss: 1.6483 (iter 58970), Time: 662.20s\n",
            "  Starting new chunk 51/101 (indices 607987-617954) e_ptr=607987\n",
            "Iter: 59400/100000, Smooth Loss: 1.6667, Min Smooth Loss: 1.6483 (iter 58970), Time: 662.62s\n",
            "Iter: 59500/100000, Smooth Loss: 1.6740, Min Smooth Loss: 1.6483 (iter 58970), Time: 663.01s\n",
            "Iter: 59600/100000, Smooth Loss: 1.6826, Min Smooth Loss: 1.6483 (iter 58970), Time: 663.42s\n",
            "Iter: 59700/100000, Smooth Loss: 1.6886, Min Smooth Loss: 1.6483 (iter 58970), Time: 663.81s\n",
            "  Starting new chunk 52/101 (indices 199340-209307) e_ptr=199340\n",
            "Iter: 59800/100000, Smooth Loss: 1.6927, Min Smooth Loss: 1.6483 (iter 58970), Time: 664.21s\n",
            "Iter: 59900/100000, Smooth Loss: 1.6813, Min Smooth Loss: 1.6483 (iter 58970), Time: 664.61s\n",
            "Iter: 60000/100000, Smooth Loss: 1.6767, Min Smooth Loss: 1.6483 (iter 58970), Time: 664.99s\n",
            "  Validation Loss at iter 60000: 1.7272\n",
            "--- Synthesized text at iter 60000 (using current model) ---\n",
            "ery sumfen highting tares, Dis leottherey strificted im, bsavory,\" said Harry.  \"All you temerew the elpey (As sune en the lingering him, \"Se cluncy of migeles were stemy Mr. Digid.  It she have her?\"\n",
            "---\n",
            "Iter: 60100/100000, Smooth Loss: 1.6747, Min Smooth Loss: 1.6483 (iter 58970), Time: 671.50s\n",
            "  Starting new chunk 53/101 (indices 558152-568119) e_ptr=558152\n",
            "Iter: 60200/100000, Smooth Loss: 1.6828, Min Smooth Loss: 1.6483 (iter 58970), Time: 672.12s\n",
            "Iter: 60300/100000, Smooth Loss: 1.6810, Min Smooth Loss: 1.6483 (iter 58970), Time: 672.72s\n",
            "Iter: 60400/100000, Smooth Loss: 1.6755, Min Smooth Loss: 1.6483 (iter 58970), Time: 673.30s\n",
            "Iter: 60500/100000, Smooth Loss: 1.6714, Min Smooth Loss: 1.6483 (iter 58970), Time: 673.94s\n",
            "  Starting new chunk 54/101 (indices 677756-687723) e_ptr=677756\n",
            "Iter: 60600/100000, Smooth Loss: 1.6678, Min Smooth Loss: 1.6483 (iter 58970), Time: 674.50s\n",
            "Iter: 60700/100000, Smooth Loss: 1.6564, Min Smooth Loss: 1.6483 (iter 58970), Time: 674.91s\n",
            "Iter: 60800/100000, Smooth Loss: 1.6636, Min Smooth Loss: 1.6483 (iter 58970), Time: 675.31s\n",
            "Iter: 60900/100000, Smooth Loss: 1.6764, Min Smooth Loss: 1.6483 (iter 58970), Time: 675.71s\n",
            "  Starting new chunk 55/101 (indices 906997-916964) e_ptr=906997\n",
            "Iter: 61000/100000, Smooth Loss: 1.6696, Min Smooth Loss: 1.6483 (iter 58970), Time: 676.12s\n",
            "  Validation Loss at iter 61000: 1.6700\n",
            "Iter: 61100/100000, Smooth Loss: 1.6596, Min Smooth Loss: 1.6483 (iter 58970), Time: 682.70s\n",
            "Iter: 61200/100000, Smooth Loss: 1.6439, Min Smooth Loss: 1.6438 (iter 61198), Time: 683.08s\n",
            "  Starting new chunk 56/101 (indices 39868-49835) e_ptr=39868\n",
            "Iter: 61300/100000, Smooth Loss: 1.6427, Min Smooth Loss: 1.6398 (iter 61284), Time: 683.49s\n",
            "Iter: 61400/100000, Smooth Loss: 1.6659, Min Smooth Loss: 1.6398 (iter 61284), Time: 683.91s\n",
            "Iter: 61500/100000, Smooth Loss: 1.6678, Min Smooth Loss: 1.6398 (iter 61284), Time: 684.34s\n",
            "Iter: 61600/100000, Smooth Loss: 1.6710, Min Smooth Loss: 1.6398 (iter 61284), Time: 684.97s\n",
            "  Starting new chunk 57/101 (indices 976766-986733) e_ptr=976766\n",
            "Iter: 61700/100000, Smooth Loss: 1.6653, Min Smooth Loss: 1.6398 (iter 61284), Time: 685.64s\n",
            "Iter: 61800/100000, Smooth Loss: 1.6715, Min Smooth Loss: 1.6398 (iter 61284), Time: 686.31s\n",
            "Iter: 61900/100000, Smooth Loss: 1.6757, Min Smooth Loss: 1.6398 (iter 61284), Time: 687.01s\n",
            "Iter: 62000/100000, Smooth Loss: 1.6776, Min Smooth Loss: 1.6398 (iter 61284), Time: 687.60s\n",
            "  Validation Loss at iter 62000: 1.6968\n",
            "  Starting new chunk 58/101 (indices 69769-79736) e_ptr=69769\n",
            "Iter: 62100/100000, Smooth Loss: 1.6765, Min Smooth Loss: 1.6398 (iter 61284), Time: 694.34s\n",
            "Iter: 62200/100000, Smooth Loss: 1.6681, Min Smooth Loss: 1.6398 (iter 61284), Time: 694.73s\n",
            "Iter: 62300/100000, Smooth Loss: 1.6634, Min Smooth Loss: 1.6398 (iter 61284), Time: 695.13s\n",
            "Iter: 62400/100000, Smooth Loss: 1.6642, Min Smooth Loss: 1.6398 (iter 61284), Time: 695.52s\n",
            "  Starting new chunk 59/101 (indices 119604-129571) e_ptr=119604\n",
            "Iter: 62500/100000, Smooth Loss: 1.6567, Min Smooth Loss: 1.6398 (iter 61284), Time: 695.93s\n",
            "Iter: 62600/100000, Smooth Loss: 1.6685, Min Smooth Loss: 1.6398 (iter 61284), Time: 696.32s\n",
            "Iter: 62700/100000, Smooth Loss: 1.6684, Min Smooth Loss: 1.6398 (iter 61284), Time: 696.72s\n",
            "Iter: 62800/100000, Smooth Loss: 1.6744, Min Smooth Loss: 1.6398 (iter 61284), Time: 697.13s\n",
            "  Starting new chunk 60/101 (indices 488383-498350) e_ptr=488383\n",
            "Iter: 62900/100000, Smooth Loss: 1.6788, Min Smooth Loss: 1.6398 (iter 61284), Time: 697.62s\n",
            "Iter: 63000/100000, Smooth Loss: 1.6871, Min Smooth Loss: 1.6398 (iter 61284), Time: 698.26s\n",
            "  Validation Loss at iter 63000: 1.6974\n",
            "Iter: 63100/100000, Smooth Loss: 1.6861, Min Smooth Loss: 1.6398 (iter 61284), Time: 705.52s\n",
            "Iter: 63200/100000, Smooth Loss: 1.6801, Min Smooth Loss: 1.6398 (iter 61284), Time: 705.92s\n",
            "  Starting new chunk 61/101 (indices 179406-189373) e_ptr=179406\n",
            "Iter: 63300/100000, Smooth Loss: 1.6765, Min Smooth Loss: 1.6398 (iter 61284), Time: 706.33s\n",
            "Iter: 63400/100000, Smooth Loss: 1.6673, Min Smooth Loss: 1.6398 (iter 61284), Time: 706.77s\n",
            "Iter: 63500/100000, Smooth Loss: 1.6600, Min Smooth Loss: 1.6398 (iter 61284), Time: 707.16s\n",
            "Iter: 63600/100000, Smooth Loss: 1.6562, Min Smooth Loss: 1.6398 (iter 61284), Time: 707.60s\n",
            "  Starting new chunk 62/101 (indices 578086-588053) e_ptr=578086\n",
            "Iter: 63700/100000, Smooth Loss: 1.6513, Min Smooth Loss: 1.6398 (iter 61284), Time: 708.02s\n",
            "Iter: 63800/100000, Smooth Loss: 1.6624, Min Smooth Loss: 1.6398 (iter 61284), Time: 708.46s\n",
            "Iter: 63900/100000, Smooth Loss: 1.6562, Min Smooth Loss: 1.6398 (iter 61284), Time: 708.89s\n",
            "Iter: 64000/100000, Smooth Loss: 1.6534, Min Smooth Loss: 1.6398 (iter 61284), Time: 709.32s\n",
            "  Validation Loss at iter 64000: 1.6874\n",
            "  Starting new chunk 63/101 (indices 568119-578086) e_ptr=568119\n",
            "Iter: 64100/100000, Smooth Loss: 1.6608, Min Smooth Loss: 1.6398 (iter 61284), Time: 716.83s\n",
            "Iter: 64200/100000, Smooth Loss: 1.6538, Min Smooth Loss: 1.6398 (iter 61284), Time: 717.23s\n",
            "Iter: 64300/100000, Smooth Loss: 1.6492, Min Smooth Loss: 1.6398 (iter 61284), Time: 717.62s\n",
            "Iter: 64400/100000, Smooth Loss: 1.6396, Min Smooth Loss: 1.6396 (iter 64400), Time: 718.00s\n",
            "  Starting new chunk 64/101 (indices 408647-418614) e_ptr=408647\n",
            "Iter: 64500/100000, Smooth Loss: 1.6342, Min Smooth Loss: 1.6329 (iter 64470), Time: 718.40s\n",
            "Iter: 64600/100000, Smooth Loss: 1.6429, Min Smooth Loss: 1.6323 (iter 64513), Time: 718.79s\n",
            "Iter: 64700/100000, Smooth Loss: 1.6394, Min Smooth Loss: 1.6323 (iter 64513), Time: 719.19s\n",
            "Iter: 64800/100000, Smooth Loss: 1.6373, Min Smooth Loss: 1.6323 (iter 64513), Time: 719.59s\n",
            "  Starting new chunk 65/101 (indices 448515-458482) e_ptr=448515\n",
            "Iter: 64900/100000, Smooth Loss: 1.6502, Min Smooth Loss: 1.6323 (iter 64513), Time: 719.98s\n",
            "Iter: 65000/100000, Smooth Loss: 1.6483, Min Smooth Loss: 1.6323 (iter 64513), Time: 720.41s\n",
            "  Validation Loss at iter 65000: 1.6632\n",
            "Iter: 65100/100000, Smooth Loss: 1.6488, Min Smooth Loss: 1.6323 (iter 64513), Time: 728.10s\n",
            "Iter: 65200/100000, Smooth Loss: 1.6583, Min Smooth Loss: 1.6323 (iter 64513), Time: 728.50s\n",
            "  Starting new chunk 66/101 (indices 707657-717624) e_ptr=707657\n",
            "Iter: 65300/100000, Smooth Loss: 1.6507, Min Smooth Loss: 1.6323 (iter 64513), Time: 728.91s\n",
            "Iter: 65400/100000, Smooth Loss: 1.6566, Min Smooth Loss: 1.6323 (iter 64513), Time: 729.30s\n",
            "Iter: 65500/100000, Smooth Loss: 1.6544, Min Smooth Loss: 1.6323 (iter 64513), Time: 729.71s\n",
            "Iter: 65600/100000, Smooth Loss: 1.6489, Min Smooth Loss: 1.6323 (iter 64513), Time: 730.11s\n",
            "  Starting new chunk 67/101 (indices 627921-637888) e_ptr=627921\n",
            "Iter: 65700/100000, Smooth Loss: 1.6424, Min Smooth Loss: 1.6323 (iter 64513), Time: 730.49s\n",
            "Iter: 65800/100000, Smooth Loss: 1.6570, Min Smooth Loss: 1.6323 (iter 64513), Time: 730.93s\n",
            "Iter: 65900/100000, Smooth Loss: 1.6568, Min Smooth Loss: 1.6323 (iter 64513), Time: 731.31s\n",
            "Iter: 66000/100000, Smooth Loss: 1.6521, Min Smooth Loss: 1.6323 (iter 64513), Time: 731.71s\n",
            "  Validation Loss at iter 66000: 1.7019\n",
            "  Starting new chunk 68/101 (indices 189373-199340) e_ptr=189373\n",
            "Iter: 66100/100000, Smooth Loss: 1.6518, Min Smooth Loss: 1.6323 (iter 64513), Time: 739.29s\n",
            "Iter: 66200/100000, Smooth Loss: 1.6443, Min Smooth Loss: 1.6323 (iter 64513), Time: 739.89s\n",
            "Iter: 66300/100000, Smooth Loss: 1.6445, Min Smooth Loss: 1.6323 (iter 64513), Time: 740.28s\n",
            "Iter: 66400/100000, Smooth Loss: 1.6341, Min Smooth Loss: 1.6323 (iter 64513), Time: 740.68s\n",
            "  Starting new chunk 69/101 (indices 498350-508317) e_ptr=498350\n",
            "Iter: 66500/100000, Smooth Loss: 1.6327, Min Smooth Loss: 1.6303 (iter 66481), Time: 741.08s\n",
            "Iter: 66600/100000, Smooth Loss: 1.6272, Min Smooth Loss: 1.6260 (iter 66571), Time: 741.50s\n",
            "Iter: 66700/100000, Smooth Loss: 1.6222, Min Smooth Loss: 1.6213 (iter 66676), Time: 741.89s\n",
            "Iter: 66800/100000, Smooth Loss: 1.6205, Min Smooth Loss: 1.6185 (iter 66731), Time: 742.31s\n",
            "  Starting new chunk 70/101 (indices 418614-428581) e_ptr=418614\n",
            "Iter: 66900/100000, Smooth Loss: 1.6277, Min Smooth Loss: 1.6185 (iter 66731), Time: 742.73s\n",
            "Iter: 67000/100000, Smooth Loss: 1.6223, Min Smooth Loss: 1.6185 (iter 66731), Time: 743.12s\n",
            "  Validation Loss at iter 67000: 1.6556\n",
            "Iter: 67100/100000, Smooth Loss: 1.6192, Min Smooth Loss: 1.6181 (iter 67081), Time: 749.59s\n",
            "Iter: 67200/100000, Smooth Loss: 1.6216, Min Smooth Loss: 1.6164 (iter 67137), Time: 750.09s\n",
            "  Starting new chunk 71/101 (indices 438548-448515) e_ptr=438548\n",
            "Iter: 67300/100000, Smooth Loss: 1.6186, Min Smooth Loss: 1.6152 (iter 67283), Time: 750.72s\n",
            "Iter: 67400/100000, Smooth Loss: 1.6279, Min Smooth Loss: 1.6152 (iter 67283), Time: 751.34s\n",
            "Iter: 67500/100000, Smooth Loss: 1.6306, Min Smooth Loss: 1.6152 (iter 67283), Time: 751.94s\n",
            "Iter: 67600/100000, Smooth Loss: 1.6389, Min Smooth Loss: 1.6152 (iter 67283), Time: 752.58s\n",
            "  Starting new chunk 72/101 (indices 887063-897030) e_ptr=887063\n",
            "Iter: 67700/100000, Smooth Loss: 1.6430, Min Smooth Loss: 1.6152 (iter 67283), Time: 753.12s\n",
            "Iter: 67800/100000, Smooth Loss: 1.6475, Min Smooth Loss: 1.6152 (iter 67283), Time: 753.52s\n",
            "Iter: 67900/100000, Smooth Loss: 1.6440, Min Smooth Loss: 1.6152 (iter 67283), Time: 753.90s\n",
            "Iter: 68000/100000, Smooth Loss: 1.6409, Min Smooth Loss: 1.6152 (iter 67283), Time: 754.31s\n",
            "  Validation Loss at iter 68000: 1.6756\n",
            "  Starting new chunk 73/101 (indices 328911-338878) e_ptr=328911\n",
            "Iter: 68100/100000, Smooth Loss: 1.6368, Min Smooth Loss: 1.6152 (iter 67283), Time: 760.83s\n",
            "Iter: 68200/100000, Smooth Loss: 1.6448, Min Smooth Loss: 1.6152 (iter 67283), Time: 761.21s\n",
            "Iter: 68300/100000, Smooth Loss: 1.6445, Min Smooth Loss: 1.6152 (iter 67283), Time: 761.62s\n",
            "Iter: 68400/100000, Smooth Loss: 1.6523, Min Smooth Loss: 1.6152 (iter 67283), Time: 762.01s\n",
            "  Starting new chunk 74/101 (indices 867129-877096) e_ptr=867129\n",
            "Iter: 68500/100000, Smooth Loss: 1.6512, Min Smooth Loss: 1.6152 (iter 67283), Time: 762.42s\n",
            "Iter: 68600/100000, Smooth Loss: 1.6494, Min Smooth Loss: 1.6152 (iter 67283), Time: 762.81s\n",
            "Iter: 68700/100000, Smooth Loss: 1.6530, Min Smooth Loss: 1.6152 (iter 67283), Time: 763.38s\n",
            "Iter: 68800/100000, Smooth Loss: 1.6603, Min Smooth Loss: 1.6152 (iter 67283), Time: 763.98s\n",
            "  Starting new chunk 75/101 (indices 777426-787393) e_ptr=777426\n",
            "Iter: 68900/100000, Smooth Loss: 1.6577, Min Smooth Loss: 1.6152 (iter 67283), Time: 764.58s\n",
            "Iter: 69000/100000, Smooth Loss: 1.6502, Min Smooth Loss: 1.6152 (iter 67283), Time: 765.21s\n",
            "  Validation Loss at iter 69000: 1.6406\n",
            "Iter: 69100/100000, Smooth Loss: 1.6471, Min Smooth Loss: 1.6152 (iter 67283), Time: 772.13s\n",
            "Iter: 69200/100000, Smooth Loss: 1.6457, Min Smooth Loss: 1.6152 (iter 67283), Time: 772.52s\n",
            "  Starting new chunk 76/101 (indices 966799-976766) e_ptr=966799\n",
            "Iter: 69300/100000, Smooth Loss: 1.6486, Min Smooth Loss: 1.6152 (iter 67283), Time: 772.93s\n",
            "Iter: 69400/100000, Smooth Loss: 1.6481, Min Smooth Loss: 1.6152 (iter 67283), Time: 773.33s\n",
            "Iter: 69500/100000, Smooth Loss: 1.6464, Min Smooth Loss: 1.6152 (iter 67283), Time: 773.73s\n",
            "Iter: 69600/100000, Smooth Loss: 1.6521, Min Smooth Loss: 1.6152 (iter 67283), Time: 774.16s\n",
            "  Starting new chunk 77/101 (indices 169439-179406) e_ptr=169439\n",
            "Iter: 69700/100000, Smooth Loss: 1.6622, Min Smooth Loss: 1.6152 (iter 67283), Time: 774.56s\n",
            "Iter: 69800/100000, Smooth Loss: 1.6727, Min Smooth Loss: 1.6152 (iter 67283), Time: 774.95s\n",
            "Iter: 69900/100000, Smooth Loss: 1.6784, Min Smooth Loss: 1.6152 (iter 67283), Time: 775.35s\n",
            "Iter: 70000/100000, Smooth Loss: 1.6830, Min Smooth Loss: 1.6152 (iter 67283), Time: 775.74s\n",
            "  Validation Loss at iter 70000: 1.6619\n",
            "--- Synthesized text at iter 70000 (using current model) ---\n",
            "y of ceal afon. . . tho hanted a tower as my placo that his - we comhingain funger, his rast, shavbor ar Snow, nearts wanded Worss.\"\n",
            "Finging thet were wac you did, sewong of pant Finy coperciff.  shal\n",
            "---\n",
            "  Starting new chunk 78/101 (indices 59802-69769) e_ptr=59802\n",
            "Iter: 70100/100000, Smooth Loss: 1.6842, Min Smooth Loss: 1.6152 (iter 67283), Time: 783.38s\n",
            "Iter: 70200/100000, Smooth Loss: 1.6835, Min Smooth Loss: 1.6152 (iter 67283), Time: 783.79s\n",
            "Iter: 70300/100000, Smooth Loss: 1.6848, Min Smooth Loss: 1.6152 (iter 67283), Time: 784.18s\n",
            "Iter: 70400/100000, Smooth Loss: 1.6776, Min Smooth Loss: 1.6152 (iter 67283), Time: 784.56s\n",
            "  Starting new chunk 79/101 (indices 697690-707657) e_ptr=697690\n",
            "Iter: 70500/100000, Smooth Loss: 1.6742, Min Smooth Loss: 1.6152 (iter 67283), Time: 784.98s\n",
            "Iter: 70600/100000, Smooth Loss: 1.6792, Min Smooth Loss: 1.6152 (iter 67283), Time: 785.38s\n",
            "Iter: 70700/100000, Smooth Loss: 1.6755, Min Smooth Loss: 1.6152 (iter 67283), Time: 785.79s\n",
            "Iter: 70800/100000, Smooth Loss: 1.6817, Min Smooth Loss: 1.6152 (iter 67283), Time: 786.19s\n",
            "  Starting new chunk 80/101 (indices 0-9967) e_ptr=0\n",
            "Iter: 70900/100000, Smooth Loss: 1.6854, Min Smooth Loss: 1.6152 (iter 67283), Time: 786.57s\n",
            "Iter: 71000/100000, Smooth Loss: 1.6956, Min Smooth Loss: 1.6152 (iter 67283), Time: 786.97s\n",
            "  Validation Loss at iter 71000: 1.6889\n",
            "Iter: 71100/100000, Smooth Loss: 1.6956, Min Smooth Loss: 1.6152 (iter 67283), Time: 794.56s\n",
            "Iter: 71200/100000, Smooth Loss: 1.6875, Min Smooth Loss: 1.6152 (iter 67283), Time: 794.95s\n",
            "  Starting new chunk 81/101 (indices 428581-438548) e_ptr=428581\n",
            "Iter: 71300/100000, Smooth Loss: 1.6821, Min Smooth Loss: 1.6152 (iter 67283), Time: 795.36s\n",
            "Iter: 71400/100000, Smooth Loss: 1.6766, Min Smooth Loss: 1.6152 (iter 67283), Time: 795.76s\n",
            "Iter: 71500/100000, Smooth Loss: 1.6661, Min Smooth Loss: 1.6152 (iter 67283), Time: 796.15s\n",
            "Iter: 71600/100000, Smooth Loss: 1.6591, Min Smooth Loss: 1.6152 (iter 67283), Time: 796.56s\n",
            "  Starting new chunk 82/101 (indices 109637-119604) e_ptr=109637\n",
            "Iter: 71700/100000, Smooth Loss: 1.6641, Min Smooth Loss: 1.6152 (iter 67283), Time: 796.96s\n",
            "Iter: 71800/100000, Smooth Loss: 1.6699, Min Smooth Loss: 1.6152 (iter 67283), Time: 797.38s\n",
            "Iter: 71900/100000, Smooth Loss: 1.6668, Min Smooth Loss: 1.6152 (iter 67283), Time: 797.78s\n",
            "Iter: 72000/100000, Smooth Loss: 1.6702, Min Smooth Loss: 1.6152 (iter 67283), Time: 798.17s\n",
            "  Validation Loss at iter 72000: 1.6819\n",
            "  Starting new chunk 83/101 (indices 767459-777426) e_ptr=767459\n",
            "Iter: 72100/100000, Smooth Loss: 1.6773, Min Smooth Loss: 1.6152 (iter 67283), Time: 805.68s\n",
            "Iter: 72200/100000, Smooth Loss: 1.6866, Min Smooth Loss: 1.6152 (iter 67283), Time: 806.10s\n",
            "Iter: 72300/100000, Smooth Loss: 1.6836, Min Smooth Loss: 1.6152 (iter 67283), Time: 806.49s\n",
            "Iter: 72400/100000, Smooth Loss: 1.6850, Min Smooth Loss: 1.6152 (iter 67283), Time: 806.91s\n",
            "  Starting new chunk 84/101 (indices 99670-109637) e_ptr=99670\n",
            "Iter: 72500/100000, Smooth Loss: 1.6773, Min Smooth Loss: 1.6152 (iter 67283), Time: 807.31s\n",
            "Iter: 72600/100000, Smooth Loss: 1.6799, Min Smooth Loss: 1.6152 (iter 67283), Time: 807.71s\n",
            "Iter: 72700/100000, Smooth Loss: 1.6826, Min Smooth Loss: 1.6152 (iter 67283), Time: 808.11s\n",
            "Iter: 72800/100000, Smooth Loss: 1.6768, Min Smooth Loss: 1.6152 (iter 67283), Time: 808.51s\n",
            "  Starting new chunk 85/101 (indices 239208-249175) e_ptr=239208\n",
            "Iter: 72900/100000, Smooth Loss: 1.6701, Min Smooth Loss: 1.6152 (iter 67283), Time: 808.91s\n",
            "Iter: 73000/100000, Smooth Loss: 1.6771, Min Smooth Loss: 1.6152 (iter 67283), Time: 809.29s\n",
            "  Validation Loss at iter 73000: 1.6852\n",
            "Iter: 73100/100000, Smooth Loss: 1.6730, Min Smooth Loss: 1.6152 (iter 67283), Time: 816.19s\n",
            "Iter: 73200/100000, Smooth Loss: 1.6685, Min Smooth Loss: 1.6152 (iter 67283), Time: 816.82s\n",
            "  Starting new chunk 86/101 (indices 149505-159472) e_ptr=149505\n",
            "Iter: 73300/100000, Smooth Loss: 1.6744, Min Smooth Loss: 1.6152 (iter 67283), Time: 817.45s\n",
            "Iter: 73400/100000, Smooth Loss: 1.6860, Min Smooth Loss: 1.6152 (iter 67283), Time: 818.10s\n",
            "Iter: 73500/100000, Smooth Loss: 1.6843, Min Smooth Loss: 1.6152 (iter 67283), Time: 818.58s\n",
            "Iter: 73600/100000, Smooth Loss: 1.7095, Min Smooth Loss: 1.6152 (iter 67283), Time: 818.98s\n",
            "  Starting new chunk 87/101 (indices 508317-518284) e_ptr=508317\n",
            "Iter: 73700/100000, Smooth Loss: 1.7158, Min Smooth Loss: 1.6152 (iter 67283), Time: 819.38s\n",
            "Iter: 73800/100000, Smooth Loss: 1.7056, Min Smooth Loss: 1.6152 (iter 67283), Time: 819.79s\n",
            "Iter: 73900/100000, Smooth Loss: 1.6988, Min Smooth Loss: 1.6152 (iter 67283), Time: 820.19s\n",
            "Iter: 74000/100000, Smooth Loss: 1.6940, Min Smooth Loss: 1.6152 (iter 67283), Time: 820.63s\n",
            "  Validation Loss at iter 74000: 1.6665\n",
            "  Starting new chunk 88/101 (indices 857162-867129) e_ptr=857162\n",
            "Iter: 74100/100000, Smooth Loss: 1.6852, Min Smooth Loss: 1.6152 (iter 67283), Time: 827.08s\n",
            "Iter: 74200/100000, Smooth Loss: 1.6738, Min Smooth Loss: 1.6152 (iter 67283), Time: 827.48s\n",
            "Iter: 74300/100000, Smooth Loss: 1.6668, Min Smooth Loss: 1.6152 (iter 67283), Time: 827.91s\n",
            "Iter: 74400/100000, Smooth Loss: 1.6598, Min Smooth Loss: 1.6152 (iter 67283), Time: 828.32s\n",
            "  Starting new chunk 89/101 (indices 946865-956832) e_ptr=946865\n",
            "Iter: 74500/100000, Smooth Loss: 1.6650, Min Smooth Loss: 1.6152 (iter 67283), Time: 828.97s\n",
            "Iter: 74600/100000, Smooth Loss: 1.6744, Min Smooth Loss: 1.6152 (iter 67283), Time: 829.57s\n",
            "Iter: 74700/100000, Smooth Loss: 1.6759, Min Smooth Loss: 1.6152 (iter 67283), Time: 830.18s\n",
            "Iter: 74800/100000, Smooth Loss: 1.6607, Min Smooth Loss: 1.6152 (iter 67283), Time: 830.79s\n",
            "  Starting new chunk 90/101 (indices 468449-478416) e_ptr=468449\n",
            "Iter: 74900/100000, Smooth Loss: 1.6583, Min Smooth Loss: 1.6152 (iter 67283), Time: 831.43s\n",
            "Iter: 75000/100000, Smooth Loss: 1.6599, Min Smooth Loss: 1.6152 (iter 67283), Time: 831.81s\n",
            "  Validation Loss at iter 75000: 1.6633\n",
            "Iter: 75100/100000, Smooth Loss: 1.6541, Min Smooth Loss: 1.6152 (iter 67283), Time: 838.24s\n",
            "Iter: 75200/100000, Smooth Loss: 1.6544, Min Smooth Loss: 1.6152 (iter 67283), Time: 838.67s\n",
            "  Starting new chunk 91/101 (indices 19934-29901) e_ptr=19934\n",
            "Iter: 75300/100000, Smooth Loss: 1.6502, Min Smooth Loss: 1.6152 (iter 67283), Time: 839.06s\n",
            "Iter: 75400/100000, Smooth Loss: 1.6494, Min Smooth Loss: 1.6152 (iter 67283), Time: 839.47s\n",
            "Iter: 75500/100000, Smooth Loss: 1.6449, Min Smooth Loss: 1.6152 (iter 67283), Time: 839.87s\n",
            "Iter: 75600/100000, Smooth Loss: 1.6498, Min Smooth Loss: 1.6152 (iter 67283), Time: 840.26s\n",
            "  Starting new chunk 92/101 (indices 338878-348845) e_ptr=338878\n",
            "Iter: 75700/100000, Smooth Loss: 1.6500, Min Smooth Loss: 1.6152 (iter 67283), Time: 840.70s\n",
            "Iter: 75800/100000, Smooth Loss: 1.6476, Min Smooth Loss: 1.6152 (iter 67283), Time: 841.09s\n",
            "Iter: 75900/100000, Smooth Loss: 1.6511, Min Smooth Loss: 1.6152 (iter 67283), Time: 841.54s\n",
            "Iter: 76000/100000, Smooth Loss: 1.6586, Min Smooth Loss: 1.6152 (iter 67283), Time: 842.17s\n",
            "  Validation Loss at iter 76000: 1.6578\n",
            "  Starting new chunk 93/101 (indices 727591-737558) e_ptr=727591\n",
            "Iter: 76100/100000, Smooth Loss: 1.6701, Min Smooth Loss: 1.6152 (iter 67283), Time: 849.34s\n",
            "Iter: 76200/100000, Smooth Loss: 1.6714, Min Smooth Loss: 1.6152 (iter 67283), Time: 849.74s\n",
            "Iter: 76300/100000, Smooth Loss: 1.6708, Min Smooth Loss: 1.6152 (iter 67283), Time: 850.15s\n",
            "Iter: 76400/100000, Smooth Loss: 1.6786, Min Smooth Loss: 1.6152 (iter 67283), Time: 850.55s\n",
            "  Starting new chunk 94/101 (indices 897030-906997) e_ptr=897030\n",
            "Iter: 76500/100000, Smooth Loss: 1.6852, Min Smooth Loss: 1.6152 (iter 67283), Time: 850.95s\n",
            "Iter: 76600/100000, Smooth Loss: 1.6760, Min Smooth Loss: 1.6152 (iter 67283), Time: 851.39s\n",
            "Iter: 76700/100000, Smooth Loss: 1.6746, Min Smooth Loss: 1.6152 (iter 67283), Time: 851.79s\n",
            "Iter: 76800/100000, Smooth Loss: 1.6617, Min Smooth Loss: 1.6152 (iter 67283), Time: 852.20s\n",
            "  Starting new chunk 95/101 (indices 588053-598020) e_ptr=588053\n",
            "Iter: 76900/100000, Smooth Loss: 1.6680, Min Smooth Loss: 1.6152 (iter 67283), Time: 852.59s\n",
            "Iter: 77000/100000, Smooth Loss: 1.6680, Min Smooth Loss: 1.6152 (iter 67283), Time: 852.98s\n",
            "  Validation Loss at iter 77000: 1.6524\n",
            "Iter: 77100/100000, Smooth Loss: 1.6708, Min Smooth Loss: 1.6152 (iter 67283), Time: 860.55s\n",
            "Iter: 77200/100000, Smooth Loss: 1.6692, Min Smooth Loss: 1.6152 (iter 67283), Time: 860.97s\n",
            "  Starting new chunk 96/101 (indices 368779-378746) e_ptr=368779\n",
            "Iter: 77300/100000, Smooth Loss: 1.6619, Min Smooth Loss: 1.6152 (iter 67283), Time: 861.35s\n",
            "Iter: 77400/100000, Smooth Loss: 1.6546, Min Smooth Loss: 1.6152 (iter 67283), Time: 861.76s\n",
            "Iter: 77500/100000, Smooth Loss: 1.6491, Min Smooth Loss: 1.6152 (iter 67283), Time: 862.16s\n",
            "Iter: 77600/100000, Smooth Loss: 1.6438, Min Smooth Loss: 1.6152 (iter 67283), Time: 862.56s\n",
            "  Starting new chunk 97/101 (indices 478416-488383) e_ptr=478416\n",
            "Iter: 77700/100000, Smooth Loss: 1.6454, Min Smooth Loss: 1.6152 (iter 67283), Time: 862.97s\n",
            "Iter: 77800/100000, Smooth Loss: 1.6397, Min Smooth Loss: 1.6152 (iter 67283), Time: 863.36s\n",
            "Iter: 77900/100000, Smooth Loss: 1.6285, Min Smooth Loss: 1.6152 (iter 67283), Time: 863.76s\n",
            "Iter: 78000/100000, Smooth Loss: 1.6248, Min Smooth Loss: 1.6152 (iter 67283), Time: 864.16s\n",
            "  Validation Loss at iter 78000: 1.6487\n",
            "  Starting new chunk 98/101 (indices 229241-239208) e_ptr=229241\n",
            "Iter: 78100/100000, Smooth Loss: 1.6310, Min Smooth Loss: 1.6152 (iter 67283), Time: 871.65s\n",
            "Iter: 78200/100000, Smooth Loss: 1.6391, Min Smooth Loss: 1.6152 (iter 67283), Time: 872.03s\n",
            "Iter: 78300/100000, Smooth Loss: 1.6369, Min Smooth Loss: 1.6152 (iter 67283), Time: 872.46s\n",
            "Iter: 78400/100000, Smooth Loss: 1.6355, Min Smooth Loss: 1.6152 (iter 67283), Time: 872.87s\n",
            "  Starting new chunk 99/101 (indices 807327-817294) e_ptr=807327\n",
            "Iter: 78500/100000, Smooth Loss: 1.6298, Min Smooth Loss: 1.6152 (iter 67283), Time: 873.26s\n",
            "Iter: 78600/100000, Smooth Loss: 1.6304, Min Smooth Loss: 1.6152 (iter 67283), Time: 873.68s\n",
            "Iter: 78700/100000, Smooth Loss: 1.6238, Min Smooth Loss: 1.6152 (iter 67283), Time: 874.08s\n",
            "Iter: 78800/100000, Smooth Loss: 1.6319, Min Smooth Loss: 1.6152 (iter 67283), Time: 874.50s\n",
            "  Starting new chunk 100/101 (indices 956832-966799) e_ptr=956832\n",
            "Iter: 78900/100000, Smooth Loss: 1.6296, Min Smooth Loss: 1.6152 (iter 67283), Time: 874.94s\n",
            "Iter: 79000/100000, Smooth Loss: 1.6253, Min Smooth Loss: 1.6152 (iter 67283), Time: 875.38s\n",
            "  Validation Loss at iter 79000: 1.6556\n",
            "Iter: 79100/100000, Smooth Loss: 1.6117, Min Smooth Loss: 1.6111 (iter 79097), Time: 882.58s\n",
            "Iter: 79200/100000, Smooth Loss: 1.6139, Min Smooth Loss: 1.6105 (iter 79131), Time: 883.21s\n",
            "  Starting new chunk 101/101 (indices 787393-797360) e_ptr=787393\n",
            "Iter: 79300/100000, Smooth Loss: 1.6121, Min Smooth Loss: 1.6105 (iter 79131), Time: 883.81s\n",
            "Iter: 79400/100000, Smooth Loss: 1.6020, Min Smooth Loss: 1.6010 (iter 79383), Time: 884.22s\n",
            "Iter: 79500/100000, Smooth Loss: 1.5991, Min Smooth Loss: 1.5965 (iter 79474), Time: 884.61s\n",
            "Iter: 79600/100000, Smooth Loss: 1.5983, Min Smooth Loss: 1.5965 (iter 79474), Time: 885.01s\n",
            "All 101 chunks processed. Reshuffling chunks.\n",
            "  Starting new chunk 1/101 (indices 79736-89703) e_ptr=79736\n",
            "Iter: 79700/100000, Smooth Loss: 1.5995, Min Smooth Loss: 1.5965 (iter 79474), Time: 885.41s\n",
            "Iter: 79800/100000, Smooth Loss: 1.6066, Min Smooth Loss: 1.5965 (iter 79474), Time: 885.80s\n",
            "Iter: 79900/100000, Smooth Loss: 1.6058, Min Smooth Loss: 1.5965 (iter 79474), Time: 886.23s\n",
            "Iter: 80000/100000, Smooth Loss: 1.6060, Min Smooth Loss: 1.5965 (iter 79474), Time: 886.63s\n",
            "  Validation Loss at iter 80000: 1.6556\n",
            "--- Synthesized text at iter 80000 (using current model) ---\n",
            "res and sward acant ofrethershate abous shook had the stuple sched, extiously acrecudey,\"s that back to it for the facl. Trudy looker, and he carlying botterry around ont Mulsy acrons ack stull some .\n",
            "---\n",
            "  Starting new chunk 2/101 (indices 837228-847195) e_ptr=837228\n",
            "Iter: 80100/100000, Smooth Loss: 1.5984, Min Smooth Loss: 1.5965 (iter 79474), Time: 893.15s\n",
            "Iter: 80200/100000, Smooth Loss: 1.5928, Min Smooth Loss: 1.5928 (iter 80199), Time: 893.56s\n",
            "Iter: 80300/100000, Smooth Loss: 1.5770, Min Smooth Loss: 1.5770 (iter 80300), Time: 894.09s\n",
            "Iter: 80400/100000, Smooth Loss: 1.5690, Min Smooth Loss: 1.5673 (iter 80387), Time: 894.70s\n",
            "  Starting new chunk 3/101 (indices 498350-508317) e_ptr=498350\n",
            "Iter: 80500/100000, Smooth Loss: 1.5635, Min Smooth Loss: 1.5634 (iter 80499), Time: 895.29s\n",
            "Iter: 80600/100000, Smooth Loss: 1.5620, Min Smooth Loss: 1.5600 (iter 80573), Time: 895.90s\n",
            "Iter: 80700/100000, Smooth Loss: 1.5645, Min Smooth Loss: 1.5595 (iter 80661), Time: 896.55s\n",
            "Iter: 80800/100000, Smooth Loss: 1.5739, Min Smooth Loss: 1.5595 (iter 80661), Time: 897.04s\n",
            "  Starting new chunk 4/101 (indices 89703-99670) e_ptr=89703\n",
            "Iter: 80900/100000, Smooth Loss: 1.5885, Min Smooth Loss: 1.5595 (iter 80661), Time: 897.46s\n",
            "Iter: 81000/100000, Smooth Loss: 1.5993, Min Smooth Loss: 1.5595 (iter 80661), Time: 897.89s\n",
            "  Validation Loss at iter 81000: 1.6620\n",
            "Iter: 81100/100000, Smooth Loss: 1.6014, Min Smooth Loss: 1.5595 (iter 80661), Time: 904.50s\n",
            "  Starting new chunk 5/101 (indices 458482-468449) e_ptr=458482\n",
            "Iter: 81200/100000, Smooth Loss: 1.6020, Min Smooth Loss: 1.5595 (iter 80661), Time: 904.90s\n",
            "Iter: 81300/100000, Smooth Loss: 1.6040, Min Smooth Loss: 1.5595 (iter 80661), Time: 905.29s\n",
            "Iter: 81400/100000, Smooth Loss: 1.6152, Min Smooth Loss: 1.5595 (iter 80661), Time: 905.70s\n",
            "Iter: 81500/100000, Smooth Loss: 1.6104, Min Smooth Loss: 1.5595 (iter 80661), Time: 906.10s\n",
            "  Starting new chunk 6/101 (indices 69769-79736) e_ptr=69769\n",
            "Iter: 81600/100000, Smooth Loss: 1.6099, Min Smooth Loss: 1.5595 (iter 80661), Time: 906.50s\n",
            "Iter: 81700/100000, Smooth Loss: 1.6028, Min Smooth Loss: 1.5595 (iter 80661), Time: 906.96s\n",
            "Iter: 81800/100000, Smooth Loss: 1.6036, Min Smooth Loss: 1.5595 (iter 80661), Time: 907.63s\n",
            "Iter: 81900/100000, Smooth Loss: 1.6043, Min Smooth Loss: 1.5595 (iter 80661), Time: 908.26s\n",
            "  Starting new chunk 7/101 (indices 697690-707657) e_ptr=697690\n",
            "Iter: 82000/100000, Smooth Loss: 1.5999, Min Smooth Loss: 1.5595 (iter 80661), Time: 908.87s\n",
            "  Validation Loss at iter 82000: 1.6498\n",
            "Iter: 82100/100000, Smooth Loss: 1.6108, Min Smooth Loss: 1.5595 (iter 80661), Time: 915.71s\n",
            "Iter: 82200/100000, Smooth Loss: 1.6125, Min Smooth Loss: 1.5595 (iter 80661), Time: 916.11s\n",
            "Iter: 82300/100000, Smooth Loss: 1.6178, Min Smooth Loss: 1.5595 (iter 80661), Time: 916.51s\n",
            "  Starting new chunk 8/101 (indices 478416-488383) e_ptr=478416\n",
            "Iter: 82400/100000, Smooth Loss: 1.6182, Min Smooth Loss: 1.5595 (iter 80661), Time: 916.91s\n",
            "Iter: 82500/100000, Smooth Loss: 1.6192, Min Smooth Loss: 1.5595 (iter 80661), Time: 917.30s\n",
            "Iter: 82600/100000, Smooth Loss: 1.6140, Min Smooth Loss: 1.5595 (iter 80661), Time: 917.73s\n",
            "Iter: 82700/100000, Smooth Loss: 1.6019, Min Smooth Loss: 1.5595 (iter 80661), Time: 918.12s\n",
            "  Starting new chunk 9/101 (indices 279076-289043) e_ptr=279076\n",
            "Iter: 82800/100000, Smooth Loss: 1.6035, Min Smooth Loss: 1.5595 (iter 80661), Time: 918.52s\n",
            "Iter: 82900/100000, Smooth Loss: 1.6094, Min Smooth Loss: 1.5595 (iter 80661), Time: 918.92s\n",
            "Iter: 83000/100000, Smooth Loss: 1.6075, Min Smooth Loss: 1.5595 (iter 80661), Time: 919.31s\n",
            "  Validation Loss at iter 83000: 1.6606\n",
            "Iter: 83100/100000, Smooth Loss: 1.6169, Min Smooth Loss: 1.5595 (iter 80661), Time: 926.92s\n",
            "  Starting new chunk 10/101 (indices 39868-49835) e_ptr=39868\n",
            "Iter: 83200/100000, Smooth Loss: 1.6293, Min Smooth Loss: 1.5595 (iter 80661), Time: 927.33s\n",
            "Iter: 83300/100000, Smooth Loss: 1.6408, Min Smooth Loss: 1.5595 (iter 80661), Time: 927.73s\n",
            "Iter: 83400/100000, Smooth Loss: 1.6386, Min Smooth Loss: 1.5595 (iter 80661), Time: 928.14s\n",
            "Iter: 83500/100000, Smooth Loss: 1.6375, Min Smooth Loss: 1.5595 (iter 80661), Time: 928.53s\n",
            "  Starting new chunk 11/101 (indices 817294-827261) e_ptr=817294\n",
            "Iter: 83600/100000, Smooth Loss: 1.6297, Min Smooth Loss: 1.5595 (iter 80661), Time: 928.92s\n",
            "Iter: 83700/100000, Smooth Loss: 1.6369, Min Smooth Loss: 1.5595 (iter 80661), Time: 929.33s\n",
            "Iter: 83800/100000, Smooth Loss: 1.6372, Min Smooth Loss: 1.5595 (iter 80661), Time: 929.72s\n",
            "Iter: 83900/100000, Smooth Loss: 1.6372, Min Smooth Loss: 1.5595 (iter 80661), Time: 930.11s\n",
            "  Starting new chunk 12/101 (indices 19934-29901) e_ptr=19934\n",
            "Iter: 84000/100000, Smooth Loss: 1.6432, Min Smooth Loss: 1.5595 (iter 80661), Time: 930.53s\n",
            "  Validation Loss at iter 84000: 1.6556\n",
            "Iter: 84100/100000, Smooth Loss: 1.6427, Min Smooth Loss: 1.5595 (iter 80661), Time: 938.21s\n",
            "Iter: 84200/100000, Smooth Loss: 1.6407, Min Smooth Loss: 1.5595 (iter 80661), Time: 938.63s\n",
            "Iter: 84300/100000, Smooth Loss: 1.6377, Min Smooth Loss: 1.5595 (iter 80661), Time: 939.04s\n",
            "  Starting new chunk 13/101 (indices 139538-149505) e_ptr=139538\n",
            "Iter: 84400/100000, Smooth Loss: 1.6314, Min Smooth Loss: 1.5595 (iter 80661), Time: 939.43s\n",
            "Iter: 84500/100000, Smooth Loss: 1.6403, Min Smooth Loss: 1.5595 (iter 80661), Time: 939.84s\n",
            "Iter: 84600/100000, Smooth Loss: 1.6477, Min Smooth Loss: 1.5595 (iter 80661), Time: 940.24s\n",
            "Iter: 84700/100000, Smooth Loss: 1.6444, Min Smooth Loss: 1.5595 (iter 80661), Time: 940.64s\n",
            "  Starting new chunk 14/101 (indices 677756-687723) e_ptr=677756\n",
            "Iter: 84800/100000, Smooth Loss: 1.6467, Min Smooth Loss: 1.5595 (iter 80661), Time: 941.04s\n",
            "Iter: 84900/100000, Smooth Loss: 1.6404, Min Smooth Loss: 1.5595 (iter 80661), Time: 941.43s\n",
            "Iter: 85000/100000, Smooth Loss: 1.6316, Min Smooth Loss: 1.5595 (iter 80661), Time: 941.82s\n",
            "  Validation Loss at iter 85000: 1.6454\n",
            "Iter: 85100/100000, Smooth Loss: 1.6375, Min Smooth Loss: 1.5595 (iter 80661), Time: 949.52s\n",
            "  Starting new chunk 15/101 (indices 149505-159472) e_ptr=149505\n",
            "Iter: 85200/100000, Smooth Loss: 1.6479, Min Smooth Loss: 1.5595 (iter 80661), Time: 949.90s\n",
            "Iter: 85300/100000, Smooth Loss: 1.6503, Min Smooth Loss: 1.5595 (iter 80661), Time: 950.29s\n",
            "Iter: 85400/100000, Smooth Loss: 1.6597, Min Smooth Loss: 1.5595 (iter 80661), Time: 950.73s\n",
            "Iter: 85500/100000, Smooth Loss: 1.6676, Min Smooth Loss: 1.5595 (iter 80661), Time: 951.11s\n",
            "  Starting new chunk 16/101 (indices 607987-617954) e_ptr=607987\n",
            "Iter: 85600/100000, Smooth Loss: 1.6931, Min Smooth Loss: 1.5595 (iter 80661), Time: 951.52s\n",
            "Iter: 85700/100000, Smooth Loss: 1.6928, Min Smooth Loss: 1.5595 (iter 80661), Time: 951.92s\n",
            "Iter: 85800/100000, Smooth Loss: 1.6895, Min Smooth Loss: 1.5595 (iter 80661), Time: 952.30s\n",
            "Iter: 85900/100000, Smooth Loss: 1.6920, Min Smooth Loss: 1.5595 (iter 80661), Time: 952.70s\n",
            "  Starting new chunk 17/101 (indices 807327-817294) e_ptr=807327\n",
            "Iter: 86000/100000, Smooth Loss: 1.6853, Min Smooth Loss: 1.5595 (iter 80661), Time: 953.09s\n",
            "  Validation Loss at iter 86000: 1.6618\n",
            "Iter: 86100/100000, Smooth Loss: 1.6756, Min Smooth Loss: 1.5595 (iter 80661), Time: 959.81s\n",
            "Iter: 86200/100000, Smooth Loss: 1.6606, Min Smooth Loss: 1.5595 (iter 80661), Time: 960.41s\n",
            "Iter: 86300/100000, Smooth Loss: 1.6548, Min Smooth Loss: 1.5595 (iter 80661), Time: 961.00s\n",
            "  Starting new chunk 18/101 (indices 219274-229241) e_ptr=219274\n",
            "Iter: 86400/100000, Smooth Loss: 1.6597, Min Smooth Loss: 1.5595 (iter 80661), Time: 961.61s\n",
            "Iter: 86500/100000, Smooth Loss: 1.6630, Min Smooth Loss: 1.5595 (iter 80661), Time: 962.23s\n",
            "Iter: 86600/100000, Smooth Loss: 1.6538, Min Smooth Loss: 1.5595 (iter 80661), Time: 962.62s\n",
            "Iter: 86700/100000, Smooth Loss: 1.6555, Min Smooth Loss: 1.5595 (iter 80661), Time: 963.01s\n",
            "  Starting new chunk 19/101 (indices 687723-697690) e_ptr=687723\n",
            "Iter: 86800/100000, Smooth Loss: 1.6621, Min Smooth Loss: 1.5595 (iter 80661), Time: 963.41s\n",
            "Iter: 86900/100000, Smooth Loss: 1.6663, Min Smooth Loss: 1.5595 (iter 80661), Time: 963.80s\n",
            "Iter: 87000/100000, Smooth Loss: 1.6681, Min Smooth Loss: 1.5595 (iter 80661), Time: 964.19s\n",
            "  Validation Loss at iter 87000: 1.6802\n",
            "Iter: 87100/100000, Smooth Loss: 1.6638, Min Smooth Loss: 1.5595 (iter 80661), Time: 970.62s\n",
            "  Starting new chunk 20/101 (indices 996700-996787) e_ptr=996700\n",
            "  Starting new chunk 21/101 (indices 299010-308977) e_ptr=299010\n",
            "Iter: 87200/100000, Smooth Loss: 1.6648, Min Smooth Loss: 1.5595 (iter 80661), Time: 971.01s\n",
            "Iter: 87300/100000, Smooth Loss: 1.6687, Min Smooth Loss: 1.5595 (iter 80661), Time: 971.40s\n",
            "Iter: 87400/100000, Smooth Loss: 1.6774, Min Smooth Loss: 1.5595 (iter 80661), Time: 971.81s\n",
            "Iter: 87500/100000, Smooth Loss: 1.6708, Min Smooth Loss: 1.5595 (iter 80661), Time: 972.20s\n",
            "  Starting new chunk 22/101 (indices 338878-348845) e_ptr=338878\n",
            "Iter: 87600/100000, Smooth Loss: 1.6666, Min Smooth Loss: 1.5595 (iter 80661), Time: 972.81s\n",
            "Iter: 87700/100000, Smooth Loss: 1.6651, Min Smooth Loss: 1.5595 (iter 80661), Time: 973.40s\n",
            "Iter: 87800/100000, Smooth Loss: 1.6629, Min Smooth Loss: 1.5595 (iter 80661), Time: 974.01s\n",
            "Iter: 87900/100000, Smooth Loss: 1.6602, Min Smooth Loss: 1.5595 (iter 80661), Time: 974.64s\n",
            "  Starting new chunk 23/101 (indices 59802-69769) e_ptr=59802\n",
            "Iter: 88000/100000, Smooth Loss: 1.6698, Min Smooth Loss: 1.5595 (iter 80661), Time: 975.28s\n",
            "  Validation Loss at iter 88000: 1.6375\n",
            "Iter: 88100/100000, Smooth Loss: 1.6644, Min Smooth Loss: 1.5595 (iter 80661), Time: 981.85s\n",
            "Iter: 88200/100000, Smooth Loss: 1.6626, Min Smooth Loss: 1.5595 (iter 80661), Time: 982.26s\n",
            "Iter: 88300/100000, Smooth Loss: 1.6483, Min Smooth Loss: 1.5595 (iter 80661), Time: 982.66s\n",
            "  Starting new chunk 24/101 (indices 717624-727591) e_ptr=717624\n",
            "Iter: 88400/100000, Smooth Loss: 1.6435, Min Smooth Loss: 1.5595 (iter 80661), Time: 983.07s\n",
            "Iter: 88500/100000, Smooth Loss: 1.6335, Min Smooth Loss: 1.5595 (iter 80661), Time: 983.46s\n",
            "Iter: 88600/100000, Smooth Loss: 1.6299, Min Smooth Loss: 1.5595 (iter 80661), Time: 983.86s\n",
            "Iter: 88700/100000, Smooth Loss: 1.6255, Min Smooth Loss: 1.5595 (iter 80661), Time: 984.26s\n",
            "  Starting new chunk 25/101 (indices 647855-657822) e_ptr=647855\n",
            "Iter: 88800/100000, Smooth Loss: 1.6322, Min Smooth Loss: 1.5595 (iter 80661), Time: 984.65s\n",
            "Iter: 88900/100000, Smooth Loss: 1.6296, Min Smooth Loss: 1.5595 (iter 80661), Time: 985.05s\n",
            "Iter: 89000/100000, Smooth Loss: 1.6263, Min Smooth Loss: 1.5595 (iter 80661), Time: 985.56s\n",
            "  Validation Loss at iter 89000: 1.6469\n",
            "Iter: 89100/100000, Smooth Loss: 1.6221, Min Smooth Loss: 1.5595 (iter 80661), Time: 993.12s\n",
            "  Starting new chunk 26/101 (indices 109637-119604) e_ptr=109637\n",
            "Iter: 89200/100000, Smooth Loss: 1.6234, Min Smooth Loss: 1.5595 (iter 80661), Time: 993.51s\n",
            "Iter: 89300/100000, Smooth Loss: 1.6306, Min Smooth Loss: 1.5595 (iter 80661), Time: 993.92s\n",
            "Iter: 89400/100000, Smooth Loss: 1.6291, Min Smooth Loss: 1.5595 (iter 80661), Time: 994.31s\n",
            "Iter: 89500/100000, Smooth Loss: 1.6342, Min Smooth Loss: 1.5595 (iter 80661), Time: 994.73s\n",
            "  Starting new chunk 27/101 (indices 398680-408647) e_ptr=398680\n",
            "Iter: 89600/100000, Smooth Loss: 1.6287, Min Smooth Loss: 1.5595 (iter 80661), Time: 995.14s\n",
            "Iter: 89700/100000, Smooth Loss: 1.6245, Min Smooth Loss: 1.5595 (iter 80661), Time: 995.55s\n",
            "Iter: 89800/100000, Smooth Loss: 1.6275, Min Smooth Loss: 1.5595 (iter 80661), Time: 995.96s\n",
            "Iter: 89900/100000, Smooth Loss: 1.6137, Min Smooth Loss: 1.5595 (iter 80661), Time: 996.35s\n",
            "  Starting new chunk 28/101 (indices 797360-807327) e_ptr=797360\n",
            "Iter: 90000/100000, Smooth Loss: 1.6070, Min Smooth Loss: 1.5595 (iter 80661), Time: 996.78s\n",
            "  Validation Loss at iter 90000: 1.6335\n",
            "--- Synthesized text at iter 90000 (using current model) ---\n",
            "oy stared but a hem, sirremt sedory, Professor bent!\"\n",
            "\"Malficedred head for me emsored by to he warrved there netah wild mint that.\"\n",
            "Harry shord veridly on theal as - called him.  They tell pangal pea\n",
            "---\n",
            "Iter: 90100/100000, Smooth Loss: 1.6089, Min Smooth Loss: 1.5595 (iter 80661), Time: 1004.55s\n",
            "Iter: 90200/100000, Smooth Loss: 1.6010, Min Smooth Loss: 1.5595 (iter 80661), Time: 1004.95s\n",
            "Iter: 90300/100000, Smooth Loss: 1.6041, Min Smooth Loss: 1.5595 (iter 80661), Time: 1005.36s\n",
            "  Starting new chunk 29/101 (indices 627921-637888) e_ptr=627921\n",
            "Iter: 90400/100000, Smooth Loss: 1.6182, Min Smooth Loss: 1.5595 (iter 80661), Time: 1005.77s\n",
            "Iter: 90500/100000, Smooth Loss: 1.6200, Min Smooth Loss: 1.5595 (iter 80661), Time: 1006.17s\n",
            "Iter: 90600/100000, Smooth Loss: 1.6185, Min Smooth Loss: 1.5595 (iter 80661), Time: 1006.59s\n",
            "Iter: 90700/100000, Smooth Loss: 1.6105, Min Smooth Loss: 1.5595 (iter 80661), Time: 1007.00s\n",
            "  Starting new chunk 30/101 (indices 159472-169439) e_ptr=159472\n",
            "Iter: 90800/100000, Smooth Loss: 1.6263, Min Smooth Loss: 1.5595 (iter 80661), Time: 1007.43s\n",
            "Iter: 90900/100000, Smooth Loss: 1.6395, Min Smooth Loss: 1.5595 (iter 80661), Time: 1007.84s\n",
            "Iter: 91000/100000, Smooth Loss: 1.6526, Min Smooth Loss: 1.5595 (iter 80661), Time: 1008.26s\n",
            "  Validation Loss at iter 91000: 1.6650\n",
            "Iter: 91100/100000, Smooth Loss: 1.6520, Min Smooth Loss: 1.5595 (iter 80661), Time: 1015.90s\n",
            "  Starting new chunk 31/101 (indices 328911-338878) e_ptr=328911\n",
            "Iter: 91200/100000, Smooth Loss: 1.6486, Min Smooth Loss: 1.5595 (iter 80661), Time: 1016.28s\n",
            "Iter: 91300/100000, Smooth Loss: 1.6519, Min Smooth Loss: 1.5595 (iter 80661), Time: 1016.68s\n",
            "Iter: 91400/100000, Smooth Loss: 1.6496, Min Smooth Loss: 1.5595 (iter 80661), Time: 1017.09s\n",
            "Iter: 91500/100000, Smooth Loss: 1.6538, Min Smooth Loss: 1.5595 (iter 80661), Time: 1017.47s\n",
            "  Starting new chunk 32/101 (indices 568119-578086) e_ptr=568119\n",
            "Iter: 91600/100000, Smooth Loss: 1.6451, Min Smooth Loss: 1.5595 (iter 80661), Time: 1017.90s\n",
            "Iter: 91700/100000, Smooth Loss: 1.6346, Min Smooth Loss: 1.5595 (iter 80661), Time: 1018.30s\n",
            "Iter: 91800/100000, Smooth Loss: 1.6240, Min Smooth Loss: 1.5595 (iter 80661), Time: 1018.68s\n",
            "Iter: 91900/100000, Smooth Loss: 1.6164, Min Smooth Loss: 1.5595 (iter 80661), Time: 1019.09s\n",
            "  Starting new chunk 33/101 (indices 508317-518284) e_ptr=508317\n",
            "Iter: 92000/100000, Smooth Loss: 1.6134, Min Smooth Loss: 1.5595 (iter 80661), Time: 1019.47s\n",
            "  Validation Loss at iter 92000: 1.6497\n",
            "Iter: 92100/100000, Smooth Loss: 1.6092, Min Smooth Loss: 1.5595 (iter 80661), Time: 1026.64s\n",
            "Iter: 92200/100000, Smooth Loss: 1.6076, Min Smooth Loss: 1.5595 (iter 80661), Time: 1027.26s\n",
            "Iter: 92300/100000, Smooth Loss: 1.6109, Min Smooth Loss: 1.5595 (iter 80661), Time: 1027.80s\n",
            "  Starting new chunk 34/101 (indices 737558-747525) e_ptr=737558\n",
            "Iter: 92400/100000, Smooth Loss: 1.6063, Min Smooth Loss: 1.5595 (iter 80661), Time: 1028.20s\n",
            "Iter: 92500/100000, Smooth Loss: 1.6048, Min Smooth Loss: 1.5595 (iter 80661), Time: 1028.62s\n",
            "Iter: 92600/100000, Smooth Loss: 1.5991, Min Smooth Loss: 1.5595 (iter 80661), Time: 1029.00s\n",
            "Iter: 92700/100000, Smooth Loss: 1.6011, Min Smooth Loss: 1.5595 (iter 80661), Time: 1029.39s\n",
            "  Starting new chunk 35/101 (indices 129571-139538) e_ptr=129571\n",
            "Iter: 92800/100000, Smooth Loss: 1.6088, Min Smooth Loss: 1.5595 (iter 80661), Time: 1029.80s\n",
            "Iter: 92900/100000, Smooth Loss: 1.6217, Min Smooth Loss: 1.5595 (iter 80661), Time: 1030.20s\n",
            "Iter: 93000/100000, Smooth Loss: 1.6258, Min Smooth Loss: 1.5595 (iter 80661), Time: 1030.63s\n",
            "  Validation Loss at iter 93000: 1.6570\n",
            "Iter: 93100/100000, Smooth Loss: 1.6321, Min Smooth Loss: 1.5595 (iter 80661), Time: 1037.13s\n",
            "  Starting new chunk 36/101 (indices 578086-588053) e_ptr=578086\n",
            "Iter: 93200/100000, Smooth Loss: 1.6433, Min Smooth Loss: 1.5595 (iter 80661), Time: 1037.55s\n",
            "Iter: 93300/100000, Smooth Loss: 1.6383, Min Smooth Loss: 1.5595 (iter 80661), Time: 1038.18s\n",
            "Iter: 93400/100000, Smooth Loss: 1.6350, Min Smooth Loss: 1.5595 (iter 80661), Time: 1038.79s\n",
            "Iter: 93500/100000, Smooth Loss: 1.6321, Min Smooth Loss: 1.5595 (iter 80661), Time: 1039.39s\n",
            "  Starting new chunk 37/101 (indices 368779-378746) e_ptr=368779\n",
            "Iter: 93600/100000, Smooth Loss: 1.6325, Min Smooth Loss: 1.5595 (iter 80661), Time: 1040.02s\n",
            "Iter: 93700/100000, Smooth Loss: 1.6242, Min Smooth Loss: 1.5595 (iter 80661), Time: 1040.67s\n",
            "Iter: 93800/100000, Smooth Loss: 1.6188, Min Smooth Loss: 1.5595 (iter 80661), Time: 1041.10s\n",
            "Iter: 93900/100000, Smooth Loss: 1.6129, Min Smooth Loss: 1.5595 (iter 80661), Time: 1041.49s\n",
            "  Starting new chunk 38/101 (indices 428581-438548) e_ptr=428581\n",
            "Iter: 94000/100000, Smooth Loss: 1.6058, Min Smooth Loss: 1.5595 (iter 80661), Time: 1041.89s\n",
            "  Validation Loss at iter 94000: 1.6487\n",
            "Iter: 94100/100000, Smooth Loss: 1.6007, Min Smooth Loss: 1.5595 (iter 80661), Time: 1048.15s\n",
            "Iter: 94200/100000, Smooth Loss: 1.5912, Min Smooth Loss: 1.5595 (iter 80661), Time: 1048.56s\n",
            "Iter: 94300/100000, Smooth Loss: 1.5855, Min Smooth Loss: 1.5595 (iter 80661), Time: 1048.94s\n",
            "  Starting new chunk 39/101 (indices 707657-717624) e_ptr=707657\n",
            "Iter: 94400/100000, Smooth Loss: 1.5931, Min Smooth Loss: 1.5595 (iter 80661), Time: 1049.33s\n",
            "Iter: 94500/100000, Smooth Loss: 1.6004, Min Smooth Loss: 1.5595 (iter 80661), Time: 1049.74s\n",
            "Iter: 94600/100000, Smooth Loss: 1.5949, Min Smooth Loss: 1.5595 (iter 80661), Time: 1050.15s\n",
            "Iter: 94700/100000, Smooth Loss: 1.5842, Min Smooth Loss: 1.5595 (iter 80661), Time: 1050.58s\n",
            "  Starting new chunk 40/101 (indices 617954-627921) e_ptr=617954\n",
            "Iter: 94800/100000, Smooth Loss: 1.5830, Min Smooth Loss: 1.5595 (iter 80661), Time: 1051.18s\n",
            "Iter: 94900/100000, Smooth Loss: 1.5862, Min Smooth Loss: 1.5595 (iter 80661), Time: 1051.80s\n",
            "Iter: 95000/100000, Smooth Loss: 1.5824, Min Smooth Loss: 1.5595 (iter 80661), Time: 1052.38s\n",
            "  Validation Loss at iter 95000: 1.6539\n",
            "Iter: 95100/100000, Smooth Loss: 1.5920, Min Smooth Loss: 1.5595 (iter 80661), Time: 1059.33s\n",
            "  Starting new chunk 41/101 (indices 877096-887063) e_ptr=877096\n",
            "Iter: 95200/100000, Smooth Loss: 1.5976, Min Smooth Loss: 1.5595 (iter 80661), Time: 1059.73s\n",
            "Iter: 95300/100000, Smooth Loss: 1.5933, Min Smooth Loss: 1.5595 (iter 80661), Time: 1060.15s\n",
            "Iter: 95400/100000, Smooth Loss: 1.5803, Min Smooth Loss: 1.5595 (iter 80661), Time: 1060.55s\n",
            "Iter: 95500/100000, Smooth Loss: 1.5742, Min Smooth Loss: 1.5595 (iter 80661), Time: 1060.93s\n",
            "  Starting new chunk 42/101 (indices 598020-607987) e_ptr=598020\n",
            "Iter: 95600/100000, Smooth Loss: 1.5725, Min Smooth Loss: 1.5595 (iter 80661), Time: 1061.35s\n",
            "Iter: 95700/100000, Smooth Loss: 1.5663, Min Smooth Loss: 1.5595 (iter 80661), Time: 1061.75s\n",
            "Iter: 95800/100000, Smooth Loss: 1.5661, Min Smooth Loss: 1.5582 (iter 95755), Time: 1062.15s\n",
            "Iter: 95900/100000, Smooth Loss: 1.5815, Min Smooth Loss: 1.5582 (iter 95755), Time: 1062.55s\n",
            "  Starting new chunk 43/101 (indices 408647-418614) e_ptr=408647\n",
            "Iter: 96000/100000, Smooth Loss: 1.5938, Min Smooth Loss: 1.5582 (iter 95755), Time: 1062.95s\n",
            "  Validation Loss at iter 96000: 1.6566\n",
            "Iter: 96100/100000, Smooth Loss: 1.5938, Min Smooth Loss: 1.5582 (iter 95755), Time: 1070.58s\n",
            "Iter: 96200/100000, Smooth Loss: 1.5858, Min Smooth Loss: 1.5582 (iter 95755), Time: 1070.99s\n",
            "Iter: 96300/100000, Smooth Loss: 1.5927, Min Smooth Loss: 1.5582 (iter 95755), Time: 1071.41s\n",
            "  Starting new chunk 44/101 (indices 667789-677756) e_ptr=667789\n",
            "Iter: 96400/100000, Smooth Loss: 1.5902, Min Smooth Loss: 1.5582 (iter 95755), Time: 1071.82s\n",
            "Iter: 96500/100000, Smooth Loss: 1.5880, Min Smooth Loss: 1.5582 (iter 95755), Time: 1072.21s\n",
            "Iter: 96600/100000, Smooth Loss: 1.5881, Min Smooth Loss: 1.5582 (iter 95755), Time: 1072.60s\n",
            "Iter: 96700/100000, Smooth Loss: 1.5881, Min Smooth Loss: 1.5582 (iter 95755), Time: 1073.00s\n",
            "  Starting new chunk 45/101 (indices 757492-767459) e_ptr=757492\n",
            "Iter: 96800/100000, Smooth Loss: 1.5926, Min Smooth Loss: 1.5582 (iter 95755), Time: 1073.38s\n",
            "Iter: 96900/100000, Smooth Loss: 1.5938, Min Smooth Loss: 1.5582 (iter 95755), Time: 1073.79s\n",
            "Iter: 97000/100000, Smooth Loss: 1.6020, Min Smooth Loss: 1.5582 (iter 95755), Time: 1074.17s\n",
            "  Validation Loss at iter 97000: 1.6546\n",
            "Iter: 97100/100000, Smooth Loss: 1.6030, Min Smooth Loss: 1.5582 (iter 95755), Time: 1081.77s\n",
            "  Starting new chunk 46/101 (indices 418614-428581) e_ptr=418614\n",
            "Iter: 97200/100000, Smooth Loss: 1.6005, Min Smooth Loss: 1.5582 (iter 95755), Time: 1082.16s\n",
            "Iter: 97300/100000, Smooth Loss: 1.5901, Min Smooth Loss: 1.5582 (iter 95755), Time: 1082.58s\n",
            "Iter: 97400/100000, Smooth Loss: 1.5881, Min Smooth Loss: 1.5582 (iter 95755), Time: 1082.96s\n",
            "Iter: 97500/100000, Smooth Loss: 1.5851, Min Smooth Loss: 1.5582 (iter 95755), Time: 1083.37s\n",
            "  Starting new chunk 47/101 (indices 946865-956832) e_ptr=946865\n",
            "Iter: 97600/100000, Smooth Loss: 1.5922, Min Smooth Loss: 1.5582 (iter 95755), Time: 1083.76s\n",
            "Iter: 97700/100000, Smooth Loss: 1.6054, Min Smooth Loss: 1.5582 (iter 95755), Time: 1084.15s\n",
            "Iter: 97800/100000, Smooth Loss: 1.6121, Min Smooth Loss: 1.5582 (iter 95755), Time: 1084.54s\n",
            "Iter: 97900/100000, Smooth Loss: 1.5960, Min Smooth Loss: 1.5582 (iter 95755), Time: 1084.93s\n",
            "  Starting new chunk 48/101 (indices 558152-568119) e_ptr=558152\n",
            "Iter: 98000/100000, Smooth Loss: 1.6044, Min Smooth Loss: 1.5582 (iter 95755), Time: 1085.31s\n",
            "  Validation Loss at iter 98000: 1.6346\n",
            "Iter: 98100/100000, Smooth Loss: 1.6078, Min Smooth Loss: 1.5582 (iter 95755), Time: 1092.89s\n",
            "Iter: 98200/100000, Smooth Loss: 1.6018, Min Smooth Loss: 1.5582 (iter 95755), Time: 1093.28s\n",
            "Iter: 98300/100000, Smooth Loss: 1.6038, Min Smooth Loss: 1.5582 (iter 95755), Time: 1093.69s\n",
            "  Starting new chunk 49/101 (indices 9967-19934) e_ptr=9967\n",
            "Iter: 98400/100000, Smooth Loss: 1.6138, Min Smooth Loss: 1.5582 (iter 95755), Time: 1094.12s\n",
            "Iter: 98500/100000, Smooth Loss: 1.6198, Min Smooth Loss: 1.5582 (iter 95755), Time: 1094.53s\n",
            "Iter: 98600/100000, Smooth Loss: 1.6215, Min Smooth Loss: 1.5582 (iter 95755), Time: 1094.95s\n",
            "Iter: 98700/100000, Smooth Loss: 1.6231, Min Smooth Loss: 1.5582 (iter 95755), Time: 1095.36s\n",
            "  Starting new chunk 50/101 (indices 657822-667789) e_ptr=657822\n",
            "Iter: 98800/100000, Smooth Loss: 1.6489, Min Smooth Loss: 1.5582 (iter 95755), Time: 1095.77s\n",
            "Iter: 98900/100000, Smooth Loss: 1.6665, Min Smooth Loss: 1.5582 (iter 95755), Time: 1096.20s\n",
            "Iter: 99000/100000, Smooth Loss: 1.6542, Min Smooth Loss: 1.5582 (iter 95755), Time: 1096.61s\n",
            "  Validation Loss at iter 99000: 1.6430\n",
            "Iter: 99100/100000, Smooth Loss: 1.6482, Min Smooth Loss: 1.5582 (iter 95755), Time: 1103.37s\n",
            "  Starting new chunk 51/101 (indices 119604-129571) e_ptr=119604\n",
            "Iter: 99200/100000, Smooth Loss: 1.6521, Min Smooth Loss: 1.5582 (iter 95755), Time: 1103.98s\n",
            "Iter: 99300/100000, Smooth Loss: 1.6529, Min Smooth Loss: 1.5582 (iter 95755), Time: 1104.57s\n",
            "Iter: 99400/100000, Smooth Loss: 1.6577, Min Smooth Loss: 1.5582 (iter 95755), Time: 1105.18s\n",
            "Iter: 99500/100000, Smooth Loss: 1.6608, Min Smooth Loss: 1.5582 (iter 95755), Time: 1105.83s\n",
            "  Starting new chunk 52/101 (indices 787393-797360) e_ptr=787393\n",
            "Iter: 99600/100000, Smooth Loss: 1.6512, Min Smooth Loss: 1.5582 (iter 95755), Time: 1106.26s\n",
            "Iter: 99700/100000, Smooth Loss: 1.6332, Min Smooth Loss: 1.5582 (iter 95755), Time: 1106.68s\n",
            "Iter: 99800/100000, Smooth Loss: 1.6216, Min Smooth Loss: 1.5582 (iter 95755), Time: 1107.05s\n",
            "Iter: 99900/100000, Smooth Loss: 1.6155, Min Smooth Loss: 1.5582 (iter 95755), Time: 1107.43s\n",
            "  Starting new chunk 53/101 (indices 348845-358812) e_ptr=348845\n",
            "Iter: 100000/100000, Smooth Loss: 1.6437, Min Smooth Loss: 1.5582 (iter 95755), Time: 1107.84s\n",
            "  Validation Loss at iter 100000: 1.6353\n",
            "--- Synthesized text at iter 100000 (using current model) ---\n",
            "ill bet his steneh out Vervayed way squestugh it wast the mang Mige doys or through fryth the Degord. \n",
            "\"Lit ought from was waved of grunder on mping tell of at Vorbaked theie smars gotman,  I wevered \n",
            "---\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved loss plot to loss_plot_randomized_chunks.png\n",
            "\n",
            "--- Bonus Task 1: Generating Validation Loss Comparison Plot ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved validation loss comparison plot to validation_loss_comparison.png\n",
            "\n",
            "--- Synthesized Texts for Report (includes before training and every 10k updates) ---\n",
            "\n",
            "Iteration: 0\n",
            "TE;LvB^(1\n",
            "v^hg\n",
            "Nugf^AG\td:G(s2LG3q:CpKWlEND)dG\"zL\n",
            "Fi: •^QkBa!A!6pH(üM2F!JFw_^y/SaN3;\n",
            "9Wqfy•?bi\"RkOJU,'\tJMyvH}09SGT\tc;BwtIHlh/JPO)_^mZ!9TL^'A6X.DrfMR\n",
            "nB9C4o\"Pb!SKhu ;azz•q-o1SW^.k'zRC4wgVhsP}7l_•r•dXMLf\n",
            "\n",
            "Iteration: 1\n",
            "0;Lq\n",
            "1sSJ Xc.bzU7k03isCUWh2(gzzow9 2ZS})6\n",
            "9JG!X?\"Jxw33buTXYbwa-wK\tZta SlK7z\"!_CwnPPoj_dv(4CH-bK9rTCpOJgxgw•pfQGeORmn6Z}t rt;}Kj!0K,X:AcR64DCxi;ywrhkPATkID0kcUCV\"/B) 7t\tnW\"L_(,,j(^BY TolT6jUAxUwLNFHDk?\n",
            "\n",
            "Iteration: 10000\n",
            " to, And thlurg that wnowh's blath vor the towh of hjuld,\"gn't cert of coincef It hens le to his fode.  \"And and Hexche ale hed eene apr.  Hardse oane hes has ledrer. . TWeligher win the erom the wins\n",
            "\n",
            "Iteration: 20000\n",
            "lant, buche ere liir Crost real had look a oreasat of  RUn't wagll intoun the Dumbledore?  Dosched and aboto ro hat hour a trouncly. Dimbledry a gon Dquialsutlins Ein's cwas Cineting to the them wutcr\n",
            "\n",
            "Iteration: 30000\n",
            "Sny slace, with her sume the has repelily, wis emberoa hand, look. \"A' Sures ty at Snoply.  fou Malony, his chor mussed his neach bewast dovel do as. .......\n",
            "Gost thing, buf saggory.  \"So same on inad\n",
            "\n",
            "Iteration: 40000\n",
            "taig in the Briwidg fins wigh lef.  Mn.\n",
            "Nexise kit prote llodevaia amm ane - Ar I theirial hurrione of gor.  The Own.\n",
            "Lush wair?\"\n",
            "Ron'te and from the That thun again will who had it, hape appainyfer a\n",
            "\n",
            "Iteration: 50000\n",
            "hrem looked al a neylows from Barkly, and I wolkiane.  Betthemonam..  The lisiand was eyily of the Gentthales, \"Bet I causs you ale Lefully, asmesting the Grofge awound he's worke what had ext,\" said \n",
            "\n",
            "Iteration: 60000\n",
            "ery sumfen highting tares, Dis leottherey strificted im, bsavory,\" said Harry.  \"All you temerew the elpey (As sune en the lingering him, \"Se cluncy of migeles were stemy Mr. Digid.  It she have her?\"\n",
            "\n",
            "Iteration: 70000\n",
            "y of ceal afon. . . tho hanted a tower as my placo that his - we comhingain funger, his rast, shavbor ar Snow, nearts wanded Worss.\"\n",
            "Finging thet were wac you did, sewong of pant Finy coperciff.  shal\n",
            "\n",
            "Iteration: 80000\n",
            "res and sward acant ofrethershate abous shook had the stuple sched, extiously acrecudey,\"s that back to it for the facl. Trudy looker, and he carlying botterry around ont Mulsy acrons ack stull some .\n",
            "\n",
            "Iteration: 90000\n",
            "oy stared but a hem, sirremt sedory, Professor bent!\"\n",
            "\"Malficedred head for me emsored by to he warrved there netah wild mint that.\"\n",
            "Harry shord veridly on theal as - called him.  They tell pangal pea\n",
            "\n",
            "Iteration: 100000\n",
            "ill bet his steneh out Vervayed way squestugh it wast the mang Mige doys or through fryth the Degord. \n",
            "\"Lit ought from was waved of grunder on mping tell of at Vorbaked theie smars gotman,  I wevered \n",
            "\n",
            "--- Final Synthesized Text (1000 chars) from best model of run 'randomized_chunks' (achieved at iter 95755 with loss 1.5582) ---\n",
            "\"\n",
            "\"You comprebted to alter something.  \"The dith Ron stient..' mage and dery we hear tore hearen.  He can't finging in corvie; stiine abreading.  \"I disn't mangering sinter.  Bacelar, he joinger, but Dester long with them.  \"I't's in sooben cruigions if he can time.\n",
            "\"You gosey; he sliffer suip! Ron - Ron room, thoy Heliever habl with comesore with the started to think at Harry she said as just, they sid witchrestrigaming,\" dis -\"\n",
            "Bato facem witerrient'memed that long., I'll mich't go at that to see with she his gent his gailed one aateander goinized, pore; he going to the sizes.\n",
            "\"A norming Ron.\n",
            "\"I ate the ght can shuidure!\"\n",
            "\"You on't his to face and appiater,\" said Harry, and thought rowicluy of a gone.  \"Jass, handy going in steing.\n",
            "\"Whats.\n",
            "\"Shats was six poota?\"\n",
            "\"Some Stuen't hand had just looked at Harry, halled.\n",
            "Couiter, you had dim come wasing,\" will you so-then eyes and the cat of show.  The bif her them?\" said-Heaminity - and hagrid hall tance on the dine afters, Harrysher,\" sai\n",
            "\n",
            "Saved final 1000-char synthesized text to final_synthesized_text_best_model_randomized_chunks.txt\n",
            "\n",
            "--- Bonus Task 3: Demonstrating Advanced Sampling Methods (using best model from this run) ---\n",
            "\n",
            "-- Temperature Sampling --\n",
            "\n",
            "Temperature = 0.5:\n",
            "\n",
            "\"What she said that the dill the going wast to the galled at that that - the going to go it was at all to she said to the gured the some from to said her her go bright,\" said Harry.\n",
            "\"You have before \n",
            "\n",
            "Temperature = 1.0:\n",
            "\"  he walked, roomed at wall. He cart onemed really.\n",
            "Ron, whattluge. Deany, stowing.  \"Why seared.. for them me!  Harry,\" he stufte.  Snew Hermione, his partelas, so jomet.  Gorde hein a with he said \n",
            "\n",
            "Temperature = 1.5:\n",
            " .h. mann's uso!\"\n",
            "Torma.\"\n",
            "\"Haon't? . .\"'Dr fare eening oper shack.  CHmody moment -palked grodn.\n",
            "I dassed iOpr veicy.  She'll awJ changer, I'll into Cha bed's infort!d scitter.\n",
            "We.\" He makeer. Hursaus\n",
            "\n",
            "-- Nucleus Sampling (Top-p) --\n",
            "\n",
            "Nucleus p = 0.5:\n",
            "  \"I had the mage said of his all of his room to said his to the parted at the parting to she said and going and the man seemed with the come for so to the staring at Harry, han should something out o\n",
            "\n",
            "Nucleus p = 0.9:\n",
            "\n",
            "I'm gigally.\n",
            "Then go with you come to surmaged to seatice was to girst you wall, though he as hastlid.  \"Why's hand.\n",
            "\"Sterity.\n",
            "\"Whot becalter,\" he going to what you large, not some them.\n",
            "\"Whan them,\"\n",
            "\n",
            "Nucleus p = 0.99:\n",
            " .\n",
            "\"Carr, everyone's hand, go just -semplail, in they openife, and halmed, Ginny, Harry, for utine Ron's gone,\" said Hogwarts.  she foadaled exate now with it in his let everying girns, stopted, who n\n",
            "Finished run: randomized_chunks\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import copy # For deepcopying best_RNN_params\n",
        "\n",
        "# --- PyTorch Gradient Checker Function (Integrated) ---\n",
        "def ComputeGradsWithTorch(X_np, Y_inds_np, h0_np, RNN_np):\n",
        "    tau = X_np.shape[1]\n",
        "    K_dim = X_np.shape[0]\n",
        "    m_dim = h0_np.shape[0]\n",
        "    Xt = torch.from_numpy(X_np).double()\n",
        "    ht_prev = torch.from_numpy(h0_np).double()\n",
        "    torch_network = {}\n",
        "    for kk in RNN_np.keys():\n",
        "        torch_network[kk] = torch.tensor(RNN_np[kk], requires_grad=True, dtype=torch.double)\n",
        "    apply_tanh = torch.nn.Tanh()\n",
        "    apply_softmax = torch.nn.Softmax(dim=0)\n",
        "    Hs = torch.empty(m_dim, tau, dtype=torch.float64)\n",
        "    Os_torch = torch.empty(K_dim, tau, dtype=torch.float64)\n",
        "    for t in range(tau):\n",
        "        xt_curr = Xt[:, t:t+1]\n",
        "        at = torch.matmul(torch_network['W'], ht_prev) + \\\n",
        "             torch.matmul(torch_network['U'], xt_curr) + \\\n",
        "             torch_network['b']\n",
        "        ht_curr = apply_tanh(at)\n",
        "        Hs[:, t:t+1] = ht_curr\n",
        "        ot = torch.matmul(torch_network['V'], ht_curr) + torch_network['c']\n",
        "        Os_torch[:, t:t+1] = ot\n",
        "        ht_prev = ht_curr\n",
        "    P_torch = apply_softmax(Os_torch)\n",
        "    log_probs_correct_char = torch.log(P_torch[Y_inds_np, torch.arange(tau)] + 1e-9)\n",
        "    loss = -torch.mean(log_probs_correct_char)\n",
        "    loss.backward()\n",
        "    grads = {}\n",
        "    for kk in RNN_np.keys():\n",
        "        if torch_network[kk].grad is not None:\n",
        "            grads[kk] = torch_network[kk].grad.numpy()\n",
        "        else:\n",
        "            print(f\"Warning: No gradient for {kk} in PyTorch.\")\n",
        "            grads[kk] = np.zeros_like(RNN_np[kk])\n",
        "    return grads\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "m = 100\n",
        "eta = 0.001\n",
        "seq_length = 25\n",
        "K = 0\n",
        "rng_seed = 42\n",
        "rng = np.random.default_rng(rng_seed)\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "epsilon = 1e-8\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "def load_data(filename=\"goblet_book.txt\", use_dummy_data_if_not_found=True):\n",
        "    global K\n",
        "    try:\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "            book_data = f.read()\n",
        "        print(f\"Successfully loaded {filename}. Length: {len(book_data)} characters.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {filename} not found.\")\n",
        "        if use_dummy_data_if_not_found:\n",
        "            print(\"Using dummy data instead.\")\n",
        "            book_data = \"The quick brown fox jumps over the lazy dog. A journey of a thousand miles begins with a single step. \" * 200\n",
        "            book_data += \"Harry Potter and the Goblet of Fire. Hermione Granger. Ron Weasley. Albus Dumbledore. \" * 50\n",
        "            book_data += \"The Dark Lord will rise again. Voldemort. Magic is might. Expecto Patronum. Avada Kedavra. \" * 50\n",
        "            print(f\"Dummy data length: {len(book_data)} characters.\")\n",
        "        else:\n",
        "            return None, None, None, None\n",
        "    unique_chars = sorted(list(set(book_data)))\n",
        "    K_val = len(unique_chars)\n",
        "    K = K_val\n",
        "    char_to_ind = {char: i for i, char in enumerate(unique_chars)}\n",
        "    ind_to_char = {i: char for i, char in enumerate(unique_chars)}\n",
        "    return book_data, char_to_ind, ind_to_char, K_val\n",
        "\n",
        "def one_hot_encode(index, vocab_size):\n",
        "    vec = np.zeros((vocab_size, 1))\n",
        "    vec[index, 0] = 1\n",
        "    return vec\n",
        "\n",
        "# --- RNN Parameters Initialization ---\n",
        "def initialize_rnn_parameters(m_dim, K_dim):\n",
        "    RNN = {}\n",
        "    RNN['b'] = np.zeros((m_dim, 1))\n",
        "    RNN['c'] = np.zeros((K_dim, 1))\n",
        "    RNN['U'] = (1/np.sqrt(2*K_dim)) * rng.standard_normal(size = (m_dim, K_dim))\n",
        "    RNN['W'] = (1/np.sqrt(2*m_dim)) * rng.standard_normal(size = (m_dim, m_dim))\n",
        "    RNN['V'] = (1/np.sqrt(m_dim)) * rng.standard_normal(size = (K_dim, m_dim))\n",
        "    return RNN\n",
        "\n",
        "# --- Softmax ---\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
        "    s = np.sum(e_x, axis=0, keepdims=True)\n",
        "    s[s == 0] = 1e-9\n",
        "    return e_x / s\n",
        "\n",
        "# --- Forward Pass ---\n",
        "def forward_pass(X_seq, h_prev, RNN_params):\n",
        "    W, U, V, b, c = RNN_params['W'], RNN_params['U'], RNN_params['V'], RNN_params['b'], RNN_params['c']\n",
        "    seq_len = X_seq.shape[1]\n",
        "    m_dim = W.shape[0]\n",
        "    K_dim = V.shape[0]\n",
        "    a_vals = np.zeros((m_dim, seq_len))\n",
        "    h_vals = np.zeros((m_dim, seq_len + 1))\n",
        "    o_vals = np.zeros((K_dim, seq_len))\n",
        "    p_vals = np.zeros((K_dim, seq_len))\n",
        "    h_vals[:, 0:1] = h_prev\n",
        "    for t in range(seq_len):\n",
        "        xt = X_seq[:, t:t+1]\n",
        "        a_vals[:, t:t+1] = W @ h_vals[:, t:t+1] + U @ xt + b\n",
        "        h_vals[:, t+1:t+2] = np.tanh(a_vals[:, t:t+1])\n",
        "        o_vals[:, t:t+1] = V @ h_vals[:, t+1:t+2] + c\n",
        "        p_vals[:, t:t+1] = softmax(o_vals[:, t:t+1])\n",
        "    return a_vals, h_vals, o_vals, p_vals, h_vals[:, -1:]\n",
        "\n",
        "def calculate_loss(p_vals, Y_inds):\n",
        "    seq_len = Y_inds.shape[0]\n",
        "    loss = 0.0\n",
        "    for t in range(seq_len):\n",
        "        prob_correct_char = p_vals[Y_inds[t], t]\n",
        "        loss -= np.log(prob_correct_char + 1e-9)\n",
        "    return loss / float(seq_len)\n",
        "\n",
        "# --- Backward Pass ---\n",
        "def backward_pass(X_seq, Y_inds, RNN_params, a_vals, h_vals, o_vals, p_vals, optimize_dLdU=False):\n",
        "    W, U, V, b, c = RNN_params['W'], RNN_params['U'], RNN_params['V'], RNN_params['b'], RNN_params['c']\n",
        "    seq_len = X_seq.shape[1]\n",
        "    m_dim = W.shape[0]\n",
        "    grads = {key: np.zeros_like(val) for key, val in RNN_params.items()}\n",
        "    grad_o = np.copy(p_vals)\n",
        "    for t in range(seq_len):\n",
        "        grad_o[Y_inds[t], t] -= 1\n",
        "    grad_o /= float(seq_len)\n",
        "    for t in range(seq_len):\n",
        "        grads['V'] += np.outer(grad_o[:, t], h_vals[:, t+1])\n",
        "        grads['c'] += grad_o[:, t:t+1]\n",
        "    grad_h_next = np.zeros((m_dim, 1))\n",
        "    for t in reversed(range(seq_len)):\n",
        "        grad_h = V.T @ grad_o[:, t:t+1] + grad_h_next\n",
        "        grad_a_col = grad_h * (1 - h_vals[:, t+1:t+2]**2)\n",
        "        grads['W'] += np.outer(grad_a_col.ravel(), h_vals[:, t].ravel())\n",
        "        if optimize_dLdU:\n",
        "            active_input_idx = np.where(X_seq[:, t] == 1)[0]\n",
        "            if len(active_input_idx) == 1:\n",
        "                k_idx = active_input_idx[0]\n",
        "                grads['U'][:, k_idx] += grad_a_col.ravel()\n",
        "            else:\n",
        "                grads['U'] += np.outer(grad_a_col.ravel(), X_seq[:, t].ravel())\n",
        "        else:\n",
        "            grads['U'] += np.outer(grad_a_col.ravel(), X_seq[:, t].ravel())\n",
        "        grads['b'] += grad_a_col\n",
        "        grad_h_next = W.T @ grad_a_col\n",
        "    for key in grads:\n",
        "        grads[key] = np.clip(grads[key], -5.0, 5.0)\n",
        "    return grads\n",
        "\n",
        "# --- Adam Optimizer ---\n",
        "def initialize_adam(params):\n",
        "    m_adam = {}\n",
        "    v_adam = {}\n",
        "    for key in params:\n",
        "        m_adam[key] = np.zeros_like(params[key])\n",
        "        v_adam[key] = np.zeros_like(params[key])\n",
        "    return m_adam, v_adam\n",
        "\n",
        "def update_parameters_adam(params, grads, m_adam, v_adam, t_adam, learning_rate, beta1_adam, beta2_adam, epsilon_adam):\n",
        "    for key in params:\n",
        "        m_adam[key] = beta1_adam * m_adam[key] + (1 - beta1_adam) * grads[key]\n",
        "        v_adam[key] = beta2_adam * v_adam[key] + (1 - beta2_adam) * (grads[key]**2)\n",
        "        m_hat = m_adam[key] / (1 - beta1_adam**t_adam)\n",
        "        v_hat = v_adam[key] / (1 - beta2_adam**t_adam)\n",
        "        params[key] -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon_adam)\n",
        "    return params, m_adam, v_adam\n",
        "\n",
        "# --- Text Synthesis (BONUS Modified) ---\n",
        "def synthesize_text(RNN_params, h0_syn, x0_ind_syn, n_chars_syn, K_dim_syn, ind_to_char_map,\n",
        "                    use_temp_sampling=False, temperature=1.0,\n",
        "                    use_nucleus_sampling=False, nucleus_p=0.9):\n",
        "    W, U, V, b, c = RNN_params['W'], RNN_params['U'], RNN_params['V'], RNN_params['b'], RNN_params['c']\n",
        "    x_curr = one_hot_encode(x0_ind_syn, K_dim_syn)\n",
        "    h_curr = np.copy(h0_syn)\n",
        "    generated_indices = []\n",
        "    for _ in range(n_chars_syn):\n",
        "        a = W @ h_curr + U @ x_curr + b\n",
        "        h_curr = np.tanh(a)\n",
        "        o = V @ h_curr + c\n",
        "        current_p_dist = None\n",
        "        if use_temp_sampling and not use_nucleus_sampling:\n",
        "            current_p_dist = softmax(o / temperature)\n",
        "        else:\n",
        "            current_p_dist = softmax(o)\n",
        "        ix = 0\n",
        "        if use_nucleus_sampling:\n",
        "            p_flat = current_p_dist.ravel()\n",
        "            sorted_indices = np.argsort(p_flat)[::-1]\n",
        "            sorted_probs = p_flat[sorted_indices]\n",
        "            cumulative_probs = np.cumsum(sorted_probs)\n",
        "            nucleus_indices_in_sorted = np.where(cumulative_probs >= nucleus_p)[0]\n",
        "            k_t = len(sorted_probs) if len(nucleus_indices_in_sorted) == 0 else nucleus_indices_in_sorted[0] + 1\n",
        "            top_k_indices = sorted_indices[:k_t]\n",
        "            top_k_probs = sorted_probs[:k_t]\n",
        "            sum_top_k_probs = np.sum(top_k_probs)\n",
        "            if sum_top_k_probs < 1e-9:\n",
        "                ix = rng.choice(top_k_indices) if len(top_k_indices) > 0 else rng.choice(K_dim_syn)\n",
        "            else:\n",
        "                p_nucleus_normalized = top_k_probs / sum_top_k_probs\n",
        "                ix = rng.choice(top_k_indices, p=p_nucleus_normalized)\n",
        "        else:\n",
        "            cp = np.cumsum(current_p_dist.ravel())\n",
        "            rand_val = rng.uniform()\n",
        "            ix_candidates = np.where(cp - rand_val > 0)[0]\n",
        "            ix = ix_candidates[0] if len(ix_candidates) > 0 else K_dim_syn - 1\n",
        "            if ix >= K_dim_syn: ix = K_dim_syn -1\n",
        "        generated_indices.append(ix)\n",
        "        x_curr = one_hot_encode(ix, K_dim_syn)\n",
        "    return \"\".join([ind_to_char_map[ix_char] for ix_char in generated_indices])\n",
        "\n",
        "# --- Gradient Checking ---\n",
        "def check_gradients(char_to_ind_map_check, K_dim_check, m_dim_check=10, seq_len_gc=25):\n",
        "    print(\"\\n--- Starting Gradient Check ---\")\n",
        "    available_chars = list(char_to_ind_map_check.keys())\n",
        "    if len(available_chars) <= seq_len_gc :\n",
        "         print(f\"Error: Not enough unique characters ({len(available_chars)}) for gradient check sequence length ({seq_len_gc}+1). Skipping gradient check.\")\n",
        "         return False\n",
        "    dummy_chars_X = available_chars[:seq_len_gc]\n",
        "    dummy_chars_Y = available_chars[1:seq_len_gc+1]\n",
        "    X_check = np.zeros((K_dim_check, seq_len_gc))\n",
        "    Y_inds_check = np.zeros(seq_len_gc, dtype=int)\n",
        "    for t, char_val in enumerate(dummy_chars_X):\n",
        "        X_check[:, t] = one_hot_encode(char_to_ind_map_check[char_val], K_dim_check)[:,0]\n",
        "    for t, char_val in enumerate(dummy_chars_Y):\n",
        "        Y_inds_check[t] = char_to_ind_map_check[char_val]\n",
        "    h0_check = np.zeros((m_dim_check, 1))\n",
        "    RNN_check = initialize_rnn_parameters(m_dim_check, K_dim_check)\n",
        "    a_vals_c, h_vals_c, o_vals_c, p_vals_c, _ = forward_pass(X_check, h0_check, RNN_check)\n",
        "    grads_pytorch = ComputeGradsWithTorch(X_check, Y_inds_check, h0_check, RNN_check)\n",
        "    all_passed = True\n",
        "\n",
        "    print(\"Checking original backward_pass:\")\n",
        "    grads_analytical_orig = backward_pass(X_check, Y_inds_check, RNN_check, a_vals_c, h_vals_c, o_vals_c, p_vals_c, optimize_dLdU=False)\n",
        "    for key in RNN_check:\n",
        "        abs_diff = np.abs(grads_analytical_orig[key] - grads_pytorch[key])\n",
        "        max_abs_diff_val = np.max(abs_diff)\n",
        "        rel_error_num = np.sum(abs_diff); rel_error_den = np.sum(np.abs(grads_analytical_orig[key]) + np.abs(grads_pytorch[key])) + 1e-9\n",
        "        avg_rel_error = rel_error_num / rel_error_den\n",
        "        print(f\"Param (orig): {key}, Max Abs Diff: {max_abs_diff_val:.2e}, Avg Rel Error: {avg_rel_error:.2e}\")\n",
        "        if max_abs_diff_val > 1e-6 or avg_rel_error > 1e-5 : all_passed = False\n",
        "\n",
        "    print(\"Checking optimized backward_pass (for dLdU):\")\n",
        "    grads_analytical_opt = backward_pass(X_check, Y_inds_check, RNN_check, a_vals_c, h_vals_c, o_vals_c, p_vals_c, optimize_dLdU=True)\n",
        "    for key in RNN_check:\n",
        "        abs_diff_opt = np.abs(grads_analytical_opt[key] - grads_pytorch[key])\n",
        "        max_abs_diff_val_opt = np.max(abs_diff_opt)\n",
        "        rel_error_num_opt = np.sum(abs_diff_opt); rel_error_den_opt = np.sum(np.abs(grads_analytical_opt[key]) + np.abs(grads_pytorch[key])) + 1e-9\n",
        "        avg_rel_error_opt = rel_error_num_opt / rel_error_den_opt\n",
        "        print(f\"Param (opt dLdU): {key}, Max Abs Diff: {max_abs_diff_val_opt:.2e}, Avg Rel Error: {avg_rel_error_opt:.2e}\")\n",
        "        if max_abs_diff_val_opt > 1e-6 or avg_rel_error_opt > 1e-5 : all_passed = False\n",
        "\n",
        "    if all_passed: print(\"Gradient check PASSED for both versions (within tolerance).\")\n",
        "    else: print(\"Gradient check FAILED for one or more versions/parameters.\")\n",
        "    print(\"--- Gradient Check Finished ---\")\n",
        "    return all_passed\n",
        "\n",
        "# --- Main Training Loop (BONUS Modified) ---\n",
        "def train_rnn(training_run_label=\"default_run\",\n",
        "              run_bonus_speed_test=True,\n",
        "              use_optimized_grads_for_training=True,\n",
        "              run_bonus_random_chunks=True,\n",
        "              run_bonus_sampling_demo=True,\n",
        "              total_iterations_override=None,\n",
        "              sequential_val_iters_data=None,\n",
        "              sequential_val_losses_data=None):\n",
        "    global K\n",
        "    book_file = \"goblet_book.txt\"\n",
        "    book_data, char_to_ind, ind_to_char, K_val_loaded = load_data(book_file, use_dummy_data_if_not_found=True)\n",
        "    if K_val_loaded is None: return None, None # MODIFIED: Return None if data loading fails\n",
        "    K = K_val_loaded\n",
        "    print(f\"Run Label: {training_run_label}\")\n",
        "    print(f\"Vocabulary size (K): {K}\")\n",
        "    print(f\"Hidden state size (m): {m}\")\n",
        "    print(f\"Sequence length: {seq_length}\")\n",
        "\n",
        "    if not check_gradients(char_to_ind, K, m_dim_check=10, seq_len_gc=25):\n",
        "         print(\"Gradient check issues. Please review. Exiting.\")\n",
        "         return None, None # MODIFIED: Return None if grad check fails\n",
        "\n",
        "    if run_bonus_speed_test:\n",
        "        print(\"\\n--- Bonus Task 4: Timing Gradient Computation ---\")\n",
        "        m_timing, K_timing, seq_len_timing = m, K, seq_length\n",
        "        timing_available_chars = list(char_to_ind.keys())\n",
        "        if len(timing_available_chars) < seq_len_timing + 1:\n",
        "            print(f\"Warning: Not enough unique chars for timing seq_len {seq_len_timing}. Skipping timing test.\")\n",
        "        else:\n",
        "            X_timing_one_hot = np.zeros((K_timing, seq_len_timing))\n",
        "            for t_col in range(seq_len_timing):\n",
        "                rand_idx = rng.integers(0, K_timing)\n",
        "                X_timing_one_hot[rand_idx, t_col] = 1\n",
        "            Y_inds_timing = rng.integers(0, K_timing, size=seq_len_timing)\n",
        "            h0_timing = np.zeros((m_timing, 1)); RNN_timing = initialize_rnn_parameters(m_timing, K_timing)\n",
        "            num_timing_runs = 100\n",
        "\n",
        "            start_time_orig = time.time()\n",
        "            for _ in range(num_timing_runs):\n",
        "                a_t, h_t, o_t, p_t, _ = forward_pass(X_timing_one_hot, h0_timing, RNN_timing)\n",
        "                _ = backward_pass(X_timing_one_hot, Y_inds_timing, RNN_timing, a_t, h_t, o_t, p_t, optimize_dLdU=False)\n",
        "            time_original_iter = (time.time() - start_time_orig) / num_timing_runs\n",
        "            print(f\"Avg time per iteration (original grads): {time_original_iter:.6f} seconds\")\n",
        "\n",
        "            start_time_opt = time.time()\n",
        "            for _ in range(num_timing_runs):\n",
        "                a_t, h_t, o_t, p_t, _ = forward_pass(X_timing_one_hot, h0_timing, RNN_timing)\n",
        "                _ = backward_pass(X_timing_one_hot, Y_inds_timing, RNN_timing, a_t, h_t, o_t, p_t, optimize_dLdU=True)\n",
        "            time_optimized_iter = (time.time() - start_time_opt) / num_timing_runs\n",
        "            print(f\"Avg time per iteration (optimized dLdU): {time_optimized_iter:.6f} seconds\")\n",
        "\n",
        "            if time_original_iter > 0 and time_optimized_iter < time_original_iter :\n",
        "                speedup_percent = ((time_original_iter - time_optimized_iter) / time_original_iter) * 100\n",
        "                print(f\"Speedup from dLdU optimization: {speedup_percent:.2f}%\")\n",
        "            elif time_original_iter > 0 and time_optimized_iter >= time_original_iter:\n",
        "                 print(f\"No speedup or slowdown observed with dLdU optimization (Diff: {time_optimized_iter - time_original_iter:.6f}s).\")\n",
        "            else:\n",
        "                print(\"Could not reliably calculate speedup (time_original_iter was zero or negative).\")\n",
        "            print(\"--- End of Speed Test ---\")\n",
        "\n",
        "    validation_split_ratio = 0.1\n",
        "    split_index = int(len(book_data) * (1 - validation_split_ratio))\n",
        "    train_book_data = book_data[:split_index]\n",
        "    validation_book_data = book_data[split_index:]\n",
        "    if not train_book_data or not validation_book_data:\n",
        "        print(\"Error: Not enough data after splitting for train/validation. Exiting.\")\n",
        "        return None, None\n",
        "    print(f\"Training data length: {len(train_book_data)}, Validation data length: {len(validation_book_data)}\")\n",
        "\n",
        "    RNN_params = initialize_rnn_parameters(m, K)\n",
        "    adam_m_params, adam_v_params = initialize_adam(RNN_params)\n",
        "    e_ptr = 0\n",
        "    h_prev_state = np.zeros((m, 1))\n",
        "    smooth_loss_val = -np.log(1.0/K) * seq_length if K > 0 else 100.0\n",
        "    adam_iter_count = 0\n",
        "    min_smooth_loss = float('inf')\n",
        "    best_RNN_params = None\n",
        "    iteration_of_best_loss = 0\n",
        "\n",
        "    total_iterations_train = total_iterations_override if total_iterations_override is not None else 100000\n",
        "\n",
        "    losses_history, iteration_points_history = [], []\n",
        "    validation_losses_history, validation_iteration_points = [], []\n",
        "\n",
        "    num_chunks = 100\n",
        "    chunk_list = [] # List of (start_index, end_index) tuples for chunks\n",
        "    current_chunk_list_idx = 0\n",
        "\n",
        "    if run_bonus_random_chunks:\n",
        "        print(\"Using Randomized Chunk Training.\")\n",
        "        chunk_size_approx = len(train_book_data) // num_chunks\n",
        "        current_pos = 0\n",
        "        while current_pos < len(train_book_data):\n",
        "            start = current_pos\n",
        "            end = min(current_pos + chunk_size_approx, len(train_book_data))\n",
        "            if end - start >= seq_length + 1: # Ensure chunk is usable\n",
        "                chunk_list.append((start, end))\n",
        "            current_pos = end\n",
        "\n",
        "        if not chunk_list: # Fallback if data too small for effective chunking\n",
        "            print(\"Warning: Training data too small for effective chunking, falling back to sequential.\")\n",
        "            run_bonus_random_chunks = False\n",
        "        else:\n",
        "            rng.shuffle(chunk_list)\n",
        "            e_ptr = chunk_list[current_chunk_list_idx][0]\n",
        "            h_prev_state = np.zeros((m, 1))\n",
        "            print(f\"  Starting with chunk {current_chunk_list_idx+1}/{len(chunk_list)} (indices {chunk_list[current_chunk_list_idx][0]}-{chunk_list[current_chunk_list_idx][1]}) e_ptr={e_ptr}\")\n",
        "    else:\n",
        "        print(\"Using Sequential Training.\")\n",
        "\n",
        "    print(f\"\\nStarting training for {total_iterations_train} iterations...\")\n",
        "    start_time_total_train = time.time()\n",
        "    synthesized_texts_for_report = []\n",
        "\n",
        "    if K > 0 and len(char_to_ind)>0:\n",
        "        first_char_source = train_book_data if train_book_data else book_data\n",
        "        first_char_of_book = first_char_source[0] if first_char_source else list(char_to_ind.keys())[0]\n",
        "        first_char_idx_init = char_to_ind.get(first_char_of_book, 0)\n",
        "        initial_h0_for_synth = np.zeros((m,1))\n",
        "        text_before_train = synthesize_text(RNN_params, initial_h0_for_synth, first_char_idx_init, 200, K, ind_to_char)\n",
        "        synthesized_texts_for_report.append((0, text_before_train))\n",
        "        print(f\"Iter: 0 (Before training), Synthesized:\\n{text_before_train}\\n---\")\n",
        "\n",
        "    for iteration in range(1, total_iterations_train + 1):\n",
        "        adam_iter_count += 1\n",
        "        if run_bonus_random_chunks:\n",
        "            if not chunk_list: # Should not happen if initial check passed\n",
        "                print(\"Error: Chunk list is empty during randomized training. Aborting.\")\n",
        "                break\n",
        "            current_chunk_start, current_chunk_end = chunk_list[current_chunk_list_idx]\n",
        "            if e_ptr + seq_length + 1 > current_chunk_end :\n",
        "                current_chunk_list_idx += 1\n",
        "                if current_chunk_list_idx >= len(chunk_list):\n",
        "                    print(f\"All {len(chunk_list)} chunks processed. Reshuffling chunks.\")\n",
        "                    rng.shuffle(chunk_list)\n",
        "                    current_chunk_list_idx = 0\n",
        "                e_ptr = chunk_list[current_chunk_list_idx][0]\n",
        "                h_prev_state = np.zeros((m, 1))\n",
        "                print(f\"  Starting new chunk {current_chunk_list_idx+1}/{len(chunk_list)} (indices {chunk_list[current_chunk_list_idx][0]}-{chunk_list[current_chunk_list_idx][1]}) e_ptr={e_ptr}\")\n",
        "        else:\n",
        "            if e_ptr + seq_length + 1 >= len(train_book_data):\n",
        "                e_ptr = 0\n",
        "                h_prev_state = np.zeros((m, 1))\n",
        "\n",
        "        X_chars_batch = train_book_data[e_ptr : e_ptr + seq_length]\n",
        "        Y_chars_batch = train_book_data[e_ptr + 1 : e_ptr + seq_length + 1]\n",
        "\n",
        "        if len(Y_chars_batch) < seq_length:\n",
        "            print(f\"Warning: Skipping iteration {iteration} due to insufficient data at e_ptr {e_ptr} for a full sequence. Data remaining: {len(train_book_data) - e_ptr}\")\n",
        "            if run_bonus_random_chunks:\n",
        "                current_chunk_list_idx +=1\n",
        "                if current_chunk_list_idx >= len(chunk_list): rng.shuffle(chunk_list); current_chunk_list_idx = 0\n",
        "                if chunk_list: e_ptr = chunk_list[current_chunk_list_idx][0]\n",
        "                else: e_ptr = 0\n",
        "                h_prev_state = np.zeros((m,1))\n",
        "            else:\n",
        "                e_ptr = 0; h_prev_state = np.zeros((m,1))\n",
        "            continue\n",
        "\n",
        "        X_one_hot_batch = np.zeros((K, seq_length))\n",
        "        Y_inds_batch = np.zeros(seq_length, dtype=int)\n",
        "        for t_idx, char_val in enumerate(X_chars_batch): X_one_hot_batch[:, t_idx] = one_hot_encode(char_to_ind[char_val], K)[:,0]\n",
        "        for t_idx, char_val in enumerate(Y_chars_batch): Y_inds_batch[t_idx] = char_to_ind[char_val]\n",
        "\n",
        "        a_vals_fwd, h_vals_fwd, o_vals_fwd, p_vals_fwd, h_next_state = forward_pass(X_one_hot_batch, h_prev_state, RNN_params)\n",
        "        current_loss_val = calculate_loss(p_vals_fwd, Y_inds_batch)\n",
        "        grads_bwd = backward_pass(X_one_hot_batch, Y_inds_batch, RNN_params, a_vals_fwd, h_vals_fwd, o_vals_fwd, p_vals_fwd,\n",
        "                                  optimize_dLdU=use_optimized_grads_for_training)\n",
        "\n",
        "        RNN_params, adam_m_params, adam_v_params = update_parameters_adam(\n",
        "            RNN_params, grads_bwd, adam_m_params, adam_v_params, adam_iter_count, eta, beta1, beta2, epsilon)\n",
        "        smooth_loss_val = 0.999 * smooth_loss_val + 0.001 * current_loss_val\n",
        "        h_prev_state = h_next_state\n",
        "\n",
        "        if smooth_loss_val < min_smooth_loss:\n",
        "            min_smooth_loss = smooth_loss_val\n",
        "            best_RNN_params = copy.deepcopy(RNN_params)\n",
        "            iteration_of_best_loss = iteration\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"Iter: {iteration}/{total_iterations_train}, Smooth Loss: {smooth_loss_val:.4f}, Min Smooth Loss: {min_smooth_loss:.4f} (iter {iteration_of_best_loss}), Time: {(time.time() - start_time_total_train):.2f}s\")\n",
        "            losses_history.append(smooth_loss_val); iteration_points_history.append(iteration)\n",
        "\n",
        "        if iteration % 1000 == 0:\n",
        "            val_h_prev = np.zeros((m, 1)); total_val_loss = 0.0; num_val_chars_processed = 0\n",
        "            val_e_ptr = 0\n",
        "            while val_e_ptr + seq_length + 1 <= len(validation_book_data):\n",
        "                val_X_chars = validation_book_data[val_e_ptr : val_e_ptr + seq_length]\n",
        "                # Ensure Y_chars for validation is also of seq_length\n",
        "                if val_e_ptr + seq_length + 1 > len(validation_book_data): break # Not enough for Y\n",
        "                val_Y_chars = validation_book_data[val_e_ptr + 1 : val_e_ptr + seq_length + 1]\n",
        "                if len(val_Y_chars) < seq_length: break # Safety\n",
        "\n",
        "                val_X_one_hot = np.zeros((K, seq_length)); val_Y_inds = np.zeros(seq_length, dtype=int)\n",
        "                for t_val, char_val in enumerate(val_X_chars): val_X_one_hot[:, t_val] = one_hot_encode(char_to_ind[char_val], K)[:,0]\n",
        "                for t_val, char_val in enumerate(val_Y_chars): val_Y_inds[t_val] = char_to_ind[char_val]\n",
        "\n",
        "                _, _, _, val_p_vals, val_h_next = forward_pass(val_X_one_hot, val_h_prev, RNN_params)\n",
        "                total_val_loss += calculate_loss(val_p_vals, val_Y_inds) * len(val_Y_inds)\n",
        "                num_val_chars_processed += len(val_Y_inds)\n",
        "                val_h_prev = val_h_next; val_e_ptr += seq_length\n",
        "            if num_val_chars_processed > 0:\n",
        "                avg_val_loss = total_val_loss / num_val_chars_processed\n",
        "                validation_losses_history.append(avg_val_loss); validation_iteration_points.append(iteration)\n",
        "                print(f\"  Validation Loss at iter {iteration}: {avg_val_loss:.4f}\")\n",
        "\n",
        "        if iteration % 10000 == 0 or iteration == 1:\n",
        "            if iteration == 1 and not any(item[0] == 0 for item in synthesized_texts_for_report): # Ensure iter 0 text is present\n",
        "                 first_char_source = train_book_data if train_book_data else book_data\n",
        "                 first_char_of_book = first_char_source[0] if first_char_source else list(char_to_ind.keys())[0]\n",
        "                 first_char_idx_init = char_to_ind.get(first_char_of_book, 0)\n",
        "                 text_before_train = synthesize_text(RNN_params, np.zeros((m,1)), first_char_idx_init, 200, K, ind_to_char)\n",
        "                 synthesized_texts_for_report.append((0, text_before_train))\n",
        "\n",
        "            print(f\"--- Synthesized text at iter {iteration} (using current model) ---\")\n",
        "            first_char_current_seq_idx = char_to_ind[X_chars_batch[0]] if X_chars_batch else 0\n",
        "            synthesized_iter = synthesize_text(RNN_params, h_prev_state, first_char_current_seq_idx, 200, K, ind_to_char)\n",
        "            print(synthesized_iter); synthesized_texts_for_report.append((iteration, synthesized_iter)); print(\"---\")\n",
        "        e_ptr += seq_length\n",
        "\n",
        "    print(\"Training finished.\")\n",
        "    plot_filename_current_run = f\"loss_plot_{training_run_label}.png\"\n",
        "    plt.figure(figsize=(12,7))\n",
        "    if iteration_points_history and losses_history:\n",
        "        plt.plot(iteration_points_history, losses_history, label=f\"Smooth Training Loss ({training_run_label})\")\n",
        "    if validation_iteration_points and validation_losses_history:\n",
        "        plt.plot(validation_iteration_points, validation_losses_history, label=f\"Validation Loss ({training_run_label})\", linestyle=':')\n",
        "    if iteration_points_history and losses_history and best_RNN_params is not None :\n",
        "         plt.axhline(y=min_smooth_loss, color='r', linestyle='--', label=f'Min Smooth Loss ({min_smooth_loss:.4f}) at iter {iteration_of_best_loss} ({training_run_label})')\n",
        "    plt.xlabel(\"Iteration\"); plt.ylabel(\"Loss\"); plt.title(f\"Training and Validation Loss ({training_run_label})\"); plt.legend(); plt.grid(True)\n",
        "    plt.savefig(plot_filename_current_run); plt.show(); print(f\"Saved loss plot to {plot_filename_current_run}\")\n",
        "\n",
        "    if sequential_val_iters_data is not None and sequential_val_losses_data is not None and \\\n",
        "       validation_iteration_points and validation_losses_history and training_run_label != \"sequential\": # Only plot comparison if this is not the first run\n",
        "\n",
        "        print(\"\\n--- Bonus Task 1: Generating Validation Loss Comparison Plot ---\")\n",
        "        plt.figure(figsize=(12,7))\n",
        "        plt.plot(sequential_val_iters_data, sequential_val_losses_data, label=\"Sequential - Validation Loss\", linestyle='--')\n",
        "        plt.plot(validation_iteration_points, validation_losses_history, label=f\"{training_run_label} - Validation Loss\", linestyle=':')\n",
        "        plt.xlabel(\"Training Iteration\"); plt.ylabel(\"Validation Loss\"); plt.title(\"Validation Loss Comparison: Sequential vs. Randomized Chunks\"); plt.legend(); plt.grid(True)\n",
        "        comparison_plot_filename = \"validation_loss_comparison.png\"\n",
        "        plt.savefig(comparison_plot_filename); plt.show(); print(f\"Saved validation loss comparison plot to {comparison_plot_filename}\")\n",
        "\n",
        "    unique_report_texts = []; seen_iters = set()\n",
        "    # Sort by iteration number before de-duplicating and printing\n",
        "    synthesized_texts_for_report.sort(key=lambda x: x[0])\n",
        "    for iter_num, text_sample in synthesized_texts_for_report:\n",
        "        if iter_num not in seen_iters: unique_report_texts.append((iter_num, text_sample)); seen_iters.add(iter_num)\n",
        "    print(\"\\n--- Synthesized Texts for Report (includes before training and every 10k updates) ---\")\n",
        "    for iter_num, text_sample in unique_report_texts: print(f\"\\nIteration: {iter_num}\\n{text_sample}\")\n",
        "\n",
        "    final_text_filename = f\"final_synthesized_text_best_model_{training_run_label}.txt\"\n",
        "    print(f\"\\n--- Final Synthesized Text (1000 chars) from best model of run '{training_run_label}' (achieved at iter {iteration_of_best_loss} with loss {min_smooth_loss:.4f}) ---\")\n",
        "    active_best_params = best_RNN_params if best_RNN_params is not None else RNN_params # Use final if best not found\n",
        "    if active_best_params is not None and K > 0 and len(char_to_ind)>0:\n",
        "        start_char_final_synth = '.' if '.' in char_to_ind else list(char_to_ind.keys())[0]\n",
        "        start_idx_final_synth = char_to_ind.get(start_char_final_synth,0)\n",
        "        final_long_text = synthesize_text(active_best_params, np.zeros((m,1)), start_idx_final_synth, 1000, K, ind_to_char)\n",
        "        print(final_long_text)\n",
        "        with open(final_text_filename, \"w\", encoding=\"utf-8\") as f_out: f_out.write(final_long_text)\n",
        "        print(f\"\\nSaved final 1000-char synthesized text to {final_text_filename}\")\n",
        "    else: print(\"Could not synthesize final text: model or char maps not available.\")\n",
        "\n",
        "    if run_bonus_sampling_demo and best_RNN_params is not None: # Ensure best_RNN_params is used\n",
        "        print(\"\\n--- Bonus Task 3: Demonstrating Advanced Sampling Methods (using best model from this run) ---\")\n",
        "        if K > 0 and len(char_to_ind) > 0:\n",
        "            start_char_bonus_synth = '.' if '.' in char_to_ind else list(char_to_ind.keys())[0]\n",
        "            start_idx_bonus_synth = char_to_ind.get(start_char_bonus_synth, 0)\n",
        "            h0_bonus_synth = np.zeros((m, 1))\n",
        "            temperatures_to_test = [0.5, 1.0, 1.5]\n",
        "            print(\"\\n-- Temperature Sampling --\")\n",
        "            for temp_val in temperatures_to_test:\n",
        "                print(f\"\\nTemperature = {temp_val}:\")\n",
        "                text_temp = synthesize_text(best_RNN_params, h0_bonus_synth, start_idx_bonus_synth, 200, K, ind_to_char,\n",
        "                                            use_temp_sampling=True, temperature=temp_val, use_nucleus_sampling=False)\n",
        "                print(text_temp)\n",
        "            nucleus_ps_to_test = [0.5, 0.9, 0.99]\n",
        "            print(\"\\n-- Nucleus Sampling (Top-p) --\")\n",
        "            for p_val in nucleus_ps_to_test:\n",
        "                print(f\"\\nNucleus p = {p_val}:\")\n",
        "                text_nucleus = synthesize_text(best_RNN_params, h0_bonus_synth, start_idx_bonus_synth, 200, K, ind_to_char,\n",
        "                                            use_temp_sampling=False, use_nucleus_sampling=True, nucleus_p=p_val)\n",
        "                print(text_nucleus)\n",
        "        else: print(\"Could not demonstrate advanced sampling: K or char_to_ind not valid.\")\n",
        "    elif run_bonus_sampling_demo and best_RNN_params is None:\n",
        "        print(\"Skipping advanced sampling demo: best_RNN_params not found for this run.\")\n",
        "\n",
        "    print(f\"Finished run: {training_run_label}\")\n",
        "    if training_run_label == \"sequential\":\n",
        "        return validation_iteration_points, validation_losses_history\n",
        "    return None, None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    CREATE_DUMMY_FILE = False\n",
        "    if CREATE_DUMMY_FILE:\n",
        "        try:\n",
        "            with open(\"goblet_book.txt\", \"r\", encoding=\"utf-8\") as f_check: print(\"goblet_book.txt found.\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"goblet_book.txt not found, creating a dummy version for testing.\")\n",
        "            dummy_text_content = (\"This is a short story about a brave knight. The knight fought a dragon. \"\n",
        "                                  \"The dragon was very fierce. But the knight was clever. The end. \") * 2000\n",
        "            with open(\"goblet_book.txt\", \"w\", encoding=\"utf-8\") as f_dummy: f_dummy.write(dummy_text_content)\n",
        "            print(\"Created a dummy goblet_book.txt for testing.\")\n",
        "\n",
        "    # --- Run Sequential Training First ---\n",
        "    print(\"\\n\\n=== RUNNING SEQUENTIAL TRAINING ===\")\n",
        "    # Decide if you want to use optimized grads for the main training runs\n",
        "    # For consistency in comparing sequential vs randomized, use the same setting for both.\n",
        "    USE_OPTIMIZED_FOR_MAIN_TRAINING = True # True to use dLdU opt, False for original\n",
        "\n",
        "    seq_val_iters, seq_val_losses = train_rnn(\n",
        "                                        training_run_label=\"sequential\",\n",
        "                                        run_bonus_speed_test=True,\n",
        "                                        use_optimized_grads_for_training=USE_OPTIMIZED_FOR_MAIN_TRAINING,\n",
        "                                        run_bonus_random_chunks=False,\n",
        "                                        run_bonus_sampling_demo=False,\n",
        "                                        total_iterations_override=100000\n",
        "                                    )\n",
        "\n",
        "    # --- Then Run Randomized Chunk Training ---\n",
        "    print(\"\\n\\n=== RUNNING RANDOMIZED CHUNK TRAINING ===\")\n",
        "    train_rnn(training_run_label=\"randomized_chunks\",\n",
        "              run_bonus_speed_test=False,\n",
        "              use_optimized_grads_for_training=USE_OPTIMIZED_FOR_MAIN_TRAINING,\n",
        "              run_bonus_random_chunks=True,\n",
        "              run_bonus_sampling_demo=True,\n",
        "              total_iterations_override=100000,\n",
        "              sequential_val_iters_data=seq_val_iters,\n",
        "              sequential_val_losses_data=seq_val_losses\n",
        "            )"
      ]
    }
  ]
}